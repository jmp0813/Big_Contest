{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:30:20.151038Z",
     "start_time": "2020-09-02T07:29:18.486999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: jdcal in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n",
      "      T_ID   GDAY_DS  HEADER_NO   P_ID  START_CK  BAT_ORDER_NO   PA   AB  RBI  \\\n",
      "0       HH  20160401          0  60404         0             3    1    1    0   \n",
      "1       HH  20160401          0  62700         1             9    2    2    0   \n",
      "2       HH  20160401          0  64086         1             7    6    4    0   \n",
      "3       HH  20160401          0  66740         1             5    6    6    0   \n",
      "4       HH  20160401          0  71347         1             2    6    6    1   \n",
      "...    ...       ...        ...    ...       ...           ...  ...  ...  ...   \n",
      "18679   WO  20161009          0  74215        91           374  402  341   80   \n",
      "18680   WO  20161009          0  78168       139           177  646  560   63   \n",
      "18681   WO  20161009          0  79130        15           251   80   66    7   \n",
      "18682   WO  20161009          0  79300        13           429  106   91    9   \n",
      "18683   WO  20161009          0  79365       122           965  454  411   70   \n",
      "\n",
      "       RUN  ...  BB  IB  HP  KK  GD  ERR  LOB  P_AB_CN  P_HIT_CN  GAME_COUNT  \n",
      "0        0  ...   0   0   0   0   0    0    1        0         0           1  \n",
      "1        1  ...   0   0   0   0   0    1    0        0         0           1  \n",
      "2        0  ...   1   0   0   3   0    0    1        2         0           1  \n",
      "3        0  ...   0   0   0   0   0    0    1        1         1           1  \n",
      "4        1  ...   0   0   0   2   0    0    0        1         0           1  \n",
      "...    ...  ...  ..  ..  ..  ..  ..  ...  ...      ...       ...         ...  \n",
      "18679   72  ...  46   3   9  50  16    6   77      121        35          92  \n",
      "18680  111  ...  69   2  10  58   6   15  113      118        36         140  \n",
      "18681   10  ...  11   0   1  24   1    1   18       20         3          40  \n",
      "18682   16  ...  10   0   0  16   3    0   29       25         4          81  \n",
      "18683   44  ...  27   0   7  93  18    7   71      132        33         127  \n",
      "\n",
      "[18684 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "%run batter_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T13:05:08.382310Z",
     "start_time": "2020-09-02T13:05:08.376351Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from statsmodels import tsa\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from plotly.offline import plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "feature, target = batter_data(\"SS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature = feature.loc[0:feature.shape[0]-20]\n",
    "trainTarget = target.loc[0:feature.shape[0]-20]\n",
    "\n",
    "testFeature = feature.loc[feature.shape[0]-20:].reset_index(drop = True)\n",
    "testTarget = target[feature.shape[0]-20:].reset_index(drop = True)\n",
    "trainFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "res = scaler.fit(trainFeature)\n",
    "res = scaler.transform(trainFeature)\n",
    "trainFeature = pd.DataFrame(res, columns = trainFeature.columns, index = list(trainFeature.index.values))\n",
    "res = scaler.transform(testFeature)\n",
    "testFeature = pd.DataFrame(res, columns = testFeature.columns, index = list(testFeature.index.values))\n",
    "\n",
    "res = scaler.fit(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "trainTarget = scaler.transform(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "testTarget = scaler.transform(np.array(testTarget).reshape(testTarget.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(4, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation = None))\n",
    "model.compile(optimizer = \"Adam\", loss = \"mse\")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(min_delta = 0.0005, patience = 30, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 200, validation_split = 0.3, shuffle = True,\n",
    "          use_multiprocessing = True, callbacks = [early_stopping], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_700 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 4s - loss: 0.075 - 1s 1ms/sample - loss: 0.0778 - val_loss: 0.0553\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.070 - ETA: 0s - loss: 0.065 - 0s 155us/sample - loss: 0.0654 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.056 - 0s 135us/sample - loss: 0.0545 - val_loss: 0.0369\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.053 - ETA: 0s - loss: 0.045 - 0s 162us/sample - loss: 0.0451 - val_loss: 0.0297\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.033 - ETA: 0s - loss: 0.037 - 0s 162us/sample - loss: 0.0374 - val_loss: 0.0241\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.046 - 0s 126us/sample - loss: 0.0308 - val_loss: 0.0194\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.033 - 0s 122us/sample - loss: 0.0254 - val_loss: 0.0157\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 114us/sample - loss: 0.0211 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - 0s 154us/sample - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.014 - 0s 152us/sample - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 125us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 116us/sample - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.009 - 0s 147us/sample - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 135us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 107us/sample - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 117us/sample - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 122us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 144us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 213us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 226us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 201us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 166us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 203us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 218us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 238us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 191us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 245us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 219us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 211us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 215us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 173us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 155us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 180us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 185us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 180us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 164us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 161us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 150us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 185us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 193us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_707 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_708 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_710 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_711 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.058 - 0s 748us/sample - loss: 0.0218 - val_loss: 0.0113\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 134us/sample - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 124us/sample - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 135us/sample - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 141us/sample - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0069 - val_loss: 0.0084\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 121us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0060 - val_loss: 0.0104\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 118us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 103us/sample - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 113us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 123us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 114us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0056 - val_loss: 0.0083\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 114us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 131us/sample - loss: 0.0054 - val_loss: 0.0093\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 168us/sample - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 128us/sample - loss: 0.0054 - val_loss: 0.0084\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0054 - val_loss: 0.0084\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 133us/sample - loss: 0.0054 - val_loss: 0.0082\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 167us/sample - loss: 0.0054 - val_loss: 0.0089\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 147us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0054 - val_loss: 0.0073\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_714 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_717 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_718 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_720 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.090 - 0s 823us/sample - loss: 0.0699 - val_loss: 0.0415\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.056 - 0s 116us/sample - loss: 0.0442 - val_loss: 0.0239\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.032 - 0s 116us/sample - loss: 0.0269 - val_loss: 0.0138\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.028 - 0s 106us/sample - loss: 0.0164 - val_loss: 0.0087\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 114us/sample - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_721 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_722 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_723 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_725 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_726 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.081 - 1s 1ms/sample - loss: 0.0788 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.072 - 0s 126us/sample - loss: 0.0654 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.063 - 0s 112us/sample - loss: 0.0545 - val_loss: 0.0369\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.055 - 0s 102us/sample - loss: 0.0452 - val_loss: 0.0298\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.043 - 0s 107us/sample - loss: 0.0374 - val_loss: 0.0241\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.036 - 0s 102us/sample - loss: 0.0310 - val_loss: 0.0196\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0256 - val_loss: 0.0158\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 89us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 129us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 155us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 149us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 128us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_728 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_729 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_731 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_732 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 5s - loss: 0.075 - 1s 1ms/sample - loss: 0.0435 - val_loss: 0.0084\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 122us/sample - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 121us/sample - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 125us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 121us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 149us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 128us/sample - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 111us/sample - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 127us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 119us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 127us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 129us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 128us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 115us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 129us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 155us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_735 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_736 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_738 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_741 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.099 - ETA: 0s - loss: 0.032 - 0s 1ms/sample - loss: 0.0326 - val_loss: 0.0094\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.009 - 0s 166us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 129us/sample - loss: 0.0074 - val_loss: 0.0086\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 0s 159us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 135us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 124us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 148us/sample - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 122us/sample - loss: 0.0057 - val_loss: 0.0089\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 145us/sample - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 119us/sample - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0053 - val_loss: 0.0088\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0053 - val_loss: 0.0078\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_742 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_744 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_745 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_746 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_747 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.108 - 0s 955us/sample - loss: 0.0784 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.071 - ETA: 0s - loss: 0.064 - 0s 180us/sample - loss: 0.0652 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.058 - ETA: 0s - loss: 0.055 - 0s 168us/sample - loss: 0.0546 - val_loss: 0.0370\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.042 - ETA: 0s - loss: 0.046 - 0s 176us/sample - loss: 0.0455 - val_loss: 0.0301\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.030 - 0s 131us/sample - loss: 0.0376 - val_loss: 0.0242\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.042 - ETA: 0s - loss: 0.031 - 0s 149us/sample - loss: 0.0310 - val_loss: 0.0195\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.029 - 0s 120us/sample - loss: 0.0256 - val_loss: 0.0159\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 123us/sample - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.019 - 0s 116us/sample - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 114us/sample - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 116us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 117us/sample - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 129us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 121us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 163us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 121us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 199us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 172us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 174us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 191us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 167us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 167us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 191us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 193us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 172us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 157us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_749 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_750 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_751 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_752 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_753 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_754 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.090 - 1s 1ms/sample - loss: 0.0690 - val_loss: 0.0377\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.040 - ETA: 0s - loss: 0.036 - 0s 164us/sample - loss: 0.0344 - val_loss: 0.0118\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - ETA: 0s - loss: 0.010 - 0s 168us/sample - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.007 - 0s 160us/sample - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 123us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 123us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 121us/sample - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 178us/sample - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 174us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 166us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 179us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 143us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 155us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 133us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 134us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 157us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 174us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 160us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 160us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 133us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 158us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 160us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 125us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 168us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 75/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 76/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 77/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 78/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 79/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 80/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 81/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 82/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 83/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 129us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 84/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 125us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 85/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 86/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 191us/sample - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 87/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.005 - 0s 162us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 88/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 89/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 143us/sample - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 90/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 145us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 91/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 172us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 92/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 93/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 94/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 95/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 159us/sample - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 96/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 157us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 97/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 146us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 98/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 99/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 166us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 100/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 154us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 101/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 102/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 168us/sample - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 103/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 166us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 104/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 189us/sample - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 105/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 106/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 107/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 108/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 109/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 182us/sample - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 110/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0052 - val_loss: 0.0082\n",
      "Epoch 111/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 112/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 125us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 113/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 156us/sample - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 114/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 150us/sample - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 115/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.005 - 0s 174us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 116/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 127us/sample - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 117/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 149us/sample - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 118/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 156us/sample - loss: 0.0051 - val_loss: 0.0072\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_756 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_757 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_758 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_759 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_760 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_761 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_762 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.078 - ETA: 0s - loss: 0.063 - 1s 1ms/sample - loss: 0.0633 - val_loss: 0.0316\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.047 - 0s 104us/sample - loss: 0.0235 - val_loss: 0.0080\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.007 - 0s 153us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 133us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 133us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 125us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 158us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 166us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 166us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 129us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 129us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 125us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 122us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 124us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.001 - 0s 111us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 75/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 76/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 77/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 78/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 79/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 80/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 109us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 81/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 128us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 82/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 83/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 84/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 85/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 141us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 86/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 158us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 87/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 88/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_763 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_764 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_765 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_766 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_767 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_768 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_769 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.114 - 0s 858us/sample - loss: 0.0813 - val_loss: 0.0555\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.081 - 0s 129us/sample - loss: 0.0657 - val_loss: 0.0457\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.063 - 0s 124us/sample - loss: 0.0550 - val_loss: 0.0373\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.049 - 0s 122us/sample - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.027 - 0s 132us/sample - loss: 0.0379 - val_loss: 0.0245\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.032 - 0s 159us/sample - loss: 0.0314 - val_loss: 0.0198\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.026 - 0s 148us/sample - loss: 0.0259 - val_loss: 0.0161\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.019 - 0s 124us/sample - loss: 0.0216 - val_loss: 0.0133\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 114us/sample - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.021 - 0s 109us/sample - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0130 - val_loss: 0.0084\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.018 - 0s 104us/sample - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 99us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 121us/sample - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 96us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 131us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 168us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 135us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_770 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_771 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_772 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_773 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_774 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_775 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_776 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.070 - 0s 958us/sample - loss: 0.0397 - val_loss: 0.0086\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 122us/sample - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 123us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 126us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 122us/sample - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0085\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_777 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_778 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_779 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_780 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_781 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_782 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_783 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.079 - 0s 937us/sample - loss: 0.0674 - val_loss: 0.0285\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.035 - 0s 106us/sample - loss: 0.0163 - val_loss: 0.0081\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 162us/sample - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 126us/sample - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 151us/sample - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 143us/sample - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 123us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 133us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 125us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 115us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 132us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 101us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 130us/sample - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 156us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 150us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 130us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 127us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 127us/sample - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 149us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 146us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_784 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_785 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_786 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_787 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_788 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_789 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_790 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.116 - 1s 1ms/sample - loss: 0.0805 - val_loss: 0.0492\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.077 - 0s 132us/sample - loss: 0.0511 - val_loss: 0.0255\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.035 - 0s 122us/sample - loss: 0.0193 - val_loss: 0.0071\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 119us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 119us/sample - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_791 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_792 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_793 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_794 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_795 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_796 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_797 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.098 - 0s 906us/sample - loss: 0.0789 - val_loss: 0.0555\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.078 - 0s 124us/sample - loss: 0.0656 - val_loss: 0.0456\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.065 - 0s 108us/sample - loss: 0.0548 - val_loss: 0.0372\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.052 - 0s 112us/sample - loss: 0.0455 - val_loss: 0.0301\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.036 - 0s 112us/sample - loss: 0.0377 - val_loss: 0.0243\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.034 - 0s 101us/sample - loss: 0.0310 - val_loss: 0.0195\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.038 - 0s 104us/sample - loss: 0.0255 - val_loss: 0.0158\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0211 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.025 - 0s 108us/sample - loss: 0.0177 - val_loss: 0.0109\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 104us/sample - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 109us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_798 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_799 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_800 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_801 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_802 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_803 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_804 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.197 - 0s 693us/sample - loss: 0.0930 - val_loss: 0.0526\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.072 - 0s 121us/sample - loss: 0.0567 - val_loss: 0.0334\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0354 - val_loss: 0.0173\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0169 - val_loss: 0.0072\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 109us/sample - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 182us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 130us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 141us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 170us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 116us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 96us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 96us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_805 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_806 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_807 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_808 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_809 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_810 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.091 - 0s 738us/sample - loss: 0.0459 - val_loss: 0.0088\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 119us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 124us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 152us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 129us/sample - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 129us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 131us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 193us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 145us/sample - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 154us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 143us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0088\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 107us/sample - loss: 0.0056 - val_loss: 0.0085\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_812 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_813 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_814 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_815 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_816 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_817 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_818 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.083 - 0s 890us/sample - loss: 0.0225 - val_loss: 0.0101\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - ETA: 0s - loss: 0.008 - 0s 151us/sample - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 135us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 128us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 107us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0067 - val_loss: 0.0082\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 138us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 123us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0099\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0099\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 130us/sample - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0052 - val_loss: 0.0080\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_819 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_821 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_822 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_823 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_824 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_825 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.071 - 0s 834us/sample - loss: 0.0515 - val_loss: 0.0154\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 118us/sample - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 118us/sample - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0082\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 94us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 211us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 134us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 129us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 152us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_826 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_827 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_828 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.154 - 0s 771us/sample - loss: 0.0863 - val_loss: 0.0557\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.054 - 0s 133us/sample - loss: 0.0658 - val_loss: 0.0459\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.052 - 0s 124us/sample - loss: 0.0552 - val_loss: 0.0375\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.046 - 0s 113us/sample - loss: 0.0462 - val_loss: 0.0307\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.041 - 0s 125us/sample - loss: 0.0385 - val_loss: 0.0249\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.036 - 0s 126us/sample - loss: 0.0319 - val_loss: 0.0203\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.032 - 0s 129us/sample - loss: 0.0264 - val_loss: 0.0164\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 120us/sample - loss: 0.0219 - val_loss: 0.0135\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 122us/sample - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 129us/sample - loss: 0.0154 - val_loss: 0.0096\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 132us/sample - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.011 - 0s 199us/sample - loss: 0.0114 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.010 - 0s 146us/sample - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 131us/sample - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.008 - 0s 143us/sample - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 0s 149us/sample - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 126us/sample - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 149us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_833 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_837 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.075 - 0s 703us/sample - loss: 0.0535 - val_loss: 0.0222\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0146 - val_loss: 0.0082\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 129us/sample - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 127us/sample - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 109us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 125us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 131us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 122us/sample - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_840 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_841 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_842 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_843 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_844 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_845 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_846 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.090 - 0s 943us/sample - loss: 0.0259 - val_loss: 0.0105\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 114us/sample - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 104us/sample - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0090\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0088\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0054 - val_loss: 0.0082\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0111\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0059 - val_loss: 0.0098\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0053 - val_loss: 0.0084\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 176us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 160us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 162us/sample - loss: 0.0052 - val_loss: 0.0082\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 144us/sample - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 113us/sample - loss: 0.0049 - val_loss: 0.0069\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0051 - val_loss: 0.0079\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 113us/sample - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0051 - val_loss: 0.0078\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0047 - val_loss: 0.0088\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0048 - val_loss: 0.0086\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 95us/sample - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 121us/sample - loss: 0.0048 - val_loss: 0.0094\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 112us/sample - loss: 0.0047 - val_loss: 0.0096\n",
      "Epoch 75/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 76/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 77/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 78/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 79/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0052 - val_loss: 0.0092\n",
      "Epoch 80/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 114us/sample - loss: 0.0048 - val_loss: 0.0076\n",
      "Epoch 81/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 131us/sample - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 82/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 125us/sample - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 83/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 113us/sample - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 84/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0047 - val_loss: 0.0076\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_847 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_848 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_849 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_852 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.084 - 1s 1ms/sample - loss: 0.0585 - val_loss: 0.0159\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.011 - 0s 174us/sample - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.007 - 0s 160us/sample - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 168us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 124us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 176us/sample - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 127us/sample - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0088\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0102\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 141us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 130us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_854 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_855 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_858 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_859 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_860 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.031 - 0s 960us/sample - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 108us/sample - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0060 - val_loss: 0.0100\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0113\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0114\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0139\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_861 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_862 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_863 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_864 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_865 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_866 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_867 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.061 - 0s 818us/sample - loss: 0.0226 - val_loss: 0.0147\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 145us/sample - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 113us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 114us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 99us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_868 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_869 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_870 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_873 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.070 - 0s 902us/sample - loss: 0.0596 - val_loss: 0.0172\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.027 - 0s 120us/sample - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 126us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 137us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0084\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 91us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 113us/sample - loss: 0.0057 - val_loss: 0.0101\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_875 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_876 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_877 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_878 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_879 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.076 - 0s 915us/sample - loss: 0.0778 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.084 - 0s 108us/sample - loss: 0.0653 - val_loss: 0.0453\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.058 - 0s 102us/sample - loss: 0.0546 - val_loss: 0.0369\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.052 - 0s 99us/sample - loss: 0.0452 - val_loss: 0.0298\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.051 - 0s 108us/sample - loss: 0.0374 - val_loss: 0.0240\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0309 - val_loss: 0.0194\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.018 - 0s 128us/sample - loss: 0.0255 - val_loss: 0.0158\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 120us/sample - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 114us/sample - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 113us/sample - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 133us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 113us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 126us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_882 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_885 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_886 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_887 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_888 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.081 - 0s 786us/sample - loss: 0.0717 - val_loss: 0.0280\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.029 - 0s 101us/sample - loss: 0.0152 - val_loss: 0.0101\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.014 - 0s 101us/sample - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 122us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 133us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 125us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 116us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 164us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0099\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_889 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_890 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_891 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_892 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_893 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_894 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_895 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.075 - 0s 937us/sample - loss: 0.0531 - val_loss: 0.0124\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 106us/sample - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.007 - 0s 151us/sample - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_896 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_897 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_898 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_899 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_900 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_901 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_902 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 4s - loss: 0.096 - 1s 1ms/sample - loss: 0.0779 - val_loss: 0.0530\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.063 - 0s 115us/sample - loss: 0.0593 - val_loss: 0.0360\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.039 - 0s 104us/sample - loss: 0.0368 - val_loss: 0.0144\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 104us/sample - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.001 - 0s 102us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 75/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 76/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 77/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 78/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0078\n",
      "Epoch 79/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 80/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 81/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 82/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 83/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 114us/sample - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 84/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/sample - loss: 0.0056 - val_loss: 0.0086\n",
      "Epoch 85/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 86/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 87/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 88/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 89/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 90/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 91/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 92/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0053 - val_loss: 0.0080\n",
      "Epoch 93/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 94/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 95/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 108us/sample - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 96/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 101us/sample - loss: 0.0051 - val_loss: 0.0087\n",
      "Epoch 97/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 98/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 99/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 100/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 101/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 102/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 103/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 104/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 106us/sample - loss: 0.0050 - val_loss: 0.0088\n",
      "Epoch 105/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.005 - 0s 149us/sample - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 106/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 107/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 108/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 106us/sample - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 109/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0050 - val_loss: 0.0087\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_903 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_904 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_905 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_906 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_907 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_909 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.084 - 0s 894us/sample - loss: 0.0319 - val_loss: 0.0135\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 141us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0052 - val_loss: 0.0082\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 117us/sample - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0051 - val_loss: 0.0091\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0052 - val_loss: 0.0100\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0053 - val_loss: 0.0092\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0051 - val_loss: 0.0094\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0053 - val_loss: 0.0088\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0050 - val_loss: 0.0094\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0052 - val_loss: 0.0081\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0052 - val_loss: 0.0081\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_910 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_912 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.059 - 0s 844us/sample - loss: 0.0219 - val_loss: 0.0097\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 128us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 123us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 124us/sample - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 124us/sample - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 149us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 153us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 174us/sample - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 144us/sample - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_917 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.018 - 0s 960us/sample - loss: 0.0102 - val_loss: 0.0076\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 124us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 113us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 141us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0101\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 124us/sample - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0056 - val_loss: 0.0084\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/sample - loss: 0.0055 - val_loss: 0.0083\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_924 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_927 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_928 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_929 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_930 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.119 - 1s 1ms/sample - loss: 0.0793 - val_loss: 0.0555\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.087 - 0s 120us/sample - loss: 0.0657 - val_loss: 0.0456\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.069 - 0s 112us/sample - loss: 0.0548 - val_loss: 0.0371\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.063 - 0s 106us/sample - loss: 0.0455 - val_loss: 0.0300\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.041 - 0s 112us/sample - loss: 0.0377 - val_loss: 0.0244\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.038 - 0s 108us/sample - loss: 0.0312 - val_loss: 0.0197\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 109us/sample - loss: 0.0257 - val_loss: 0.0159\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.025 - 0s 107us/sample - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.019 - 0s 104us/sample - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 121us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.014 - 0s 120us/sample - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 114us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_931 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_932 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_933 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_937 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 4s - loss: 0.064 - 1s 1ms/sample - loss: 0.0322 - val_loss: 0.0081\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 0s 144us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.007 - 0s 149us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 122us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 121us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.006 - 0s 144us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 127us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 123us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 126us/sample - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 129us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.006 - 0s 180us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 128us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 131us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 165us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 168us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 159us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 151us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 152us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 125us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 134us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_938 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_939 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_940 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_941 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_942 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_943 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_944 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.092 - 0s 894us/sample - loss: 0.0716 - val_loss: 0.0392\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.059 - 0s 106us/sample - loss: 0.0271 - val_loss: 0.0081\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 176us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0094\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_945 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_946 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_947 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_948 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_949 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_950 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_951 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.096 - 0s 869us/sample - loss: 0.0710 - val_loss: 0.0387\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.057 - 0s 103us/sample - loss: 0.0308 - val_loss: 0.0088\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 170us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.001 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 126us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 115us/sample - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_952 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_953 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_954 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_955 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_956 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_957 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_958 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.060 - 0s 838us/sample - loss: 0.0528 - val_loss: 0.0187\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 101us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 114us/sample - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 124us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 127us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 121us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 172us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 122us/sample - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 127us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 129us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 131us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 131us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 131us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 123us/sample - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 116us/sample - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0054 - val_loss: 0.0078\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0088\n",
      "Epoch 75/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 76/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 77/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 78/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 79/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 80/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 81/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 82/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 83/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 121us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 84/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 85/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_959 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_960 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_961 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_962 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_963 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_964 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_965 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.096 - 0s 958us/sample - loss: 0.0779 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.047 - 0s 129us/sample - loss: 0.0653 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.052 - 0s 128us/sample - loss: 0.0547 - val_loss: 0.0371\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.046 - 0s 124us/sample - loss: 0.0454 - val_loss: 0.0300\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.037 - 0s 120us/sample - loss: 0.0375 - val_loss: 0.0242\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.036 - 0s 125us/sample - loss: 0.0309 - val_loss: 0.0194\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 126us/sample - loss: 0.0255 - val_loss: 0.0158\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 125us/sample - loss: 0.0211 - val_loss: 0.0129\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.017 - 0s 150us/sample - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 129us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.012 - 0s 139us/sample - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0107 - val_loss: 0.0073\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 128us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 170us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 144us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 130us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_966 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_967 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_968 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_969 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_970 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_971 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_972 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.068 - 0s 839us/sample - loss: 0.0409 - val_loss: 0.0089\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.007 - 0s 193us/sample - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 114us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 94us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 126us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 131us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.005 - 0s 149us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 135us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 139us/sample - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 104us/sample - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 113us/sample - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 156us/sample - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 101us/sample - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 96us/sample - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0051 - val_loss: 0.0079\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0051 - val_loss: 0.0077\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0050 - val_loss: 0.0075\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_973 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_974 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_975 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_976 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_977 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_978 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_979 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 4s - loss: 0.067 - 0s 985us/sample - loss: 0.0778 - val_loss: 0.0553\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.074 - 0s 102us/sample - loss: 0.0653 - val_loss: 0.0453\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.053 - 0s 105us/sample - loss: 0.0545 - val_loss: 0.0369\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.055 - ETA: 0s - loss: 0.045 - 0s 151us/sample - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 110us/sample - loss: 0.0375 - val_loss: 0.0241\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 112us/sample - loss: 0.0310 - val_loss: 0.0195\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.023 - 0s 114us/sample - loss: 0.0256 - val_loss: 0.0158\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 112us/sample - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 119us/sample - loss: 0.0177 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 114us/sample - loss: 0.0149 - val_loss: 0.0093\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 129us/sample - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 115us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 121us/sample - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 111us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 126us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 135us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 145us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 141us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_980 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_981 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_982 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_983 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_984 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_985 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_986 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.095 - 0s 871us/sample - loss: 0.0783 - val_loss: 0.0555\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.077 - 0s 99us/sample - loss: 0.0654 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.050 - 0s 97us/sample - loss: 0.0545 - val_loss: 0.0369\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.041 - 0s 100us/sample - loss: 0.0453 - val_loss: 0.0300\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.044 - 0s 100us/sample - loss: 0.0376 - val_loss: 0.0243\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.028 - 0s 97us/sample - loss: 0.0312 - val_loss: 0.0197\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 106us/sample - loss: 0.0258 - val_loss: 0.0160\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 101us/sample - loss: 0.0152 - val_loss: 0.0095\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 104us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 116us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.007 - 0s 144us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 130us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 121us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 158us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 154us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_987 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_988 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_989 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_990 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_991 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_992 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_993 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.052 - 0s 919us/sample - loss: 0.0185 - val_loss: 0.0115\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 144us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 109us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0059 - val_loss: 0.0096\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 104us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0056 - val_loss: 0.0086\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0096\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_994 (Dense)            (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_995 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_996 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_997 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_998 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_999 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1000 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.147 - 0s 935us/sample - loss: 0.0905 - val_loss: 0.0560\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.065 - 0s 102us/sample - loss: 0.0660 - val_loss: 0.0461\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.064 - 0s 102us/sample - loss: 0.0555 - val_loss: 0.0378\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.043 - 0s 108us/sample - loss: 0.0464 - val_loss: 0.0309\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.045 - 0s 99us/sample - loss: 0.0387 - val_loss: 0.0251\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0321 - val_loss: 0.0203\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0265 - val_loss: 0.0165\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0184 - val_loss: 0.0113\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0154 - val_loss: 0.0096\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0113 - val_loss: 0.0076\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 180us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1001 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1002 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1003 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1004 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1005 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1006 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1007 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.042 - 0s 1ms/sample - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 113us/sample - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 101us/sample - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 109us/sample - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 122us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1008 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1009 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1010 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1011 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1012 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1013 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1014 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.094 - 0s 919us/sample - loss: 0.0778 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.072 - 0s 120us/sample - loss: 0.0654 - val_loss: 0.0453\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.056 - 0s 118us/sample - loss: 0.0544 - val_loss: 0.0368\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.058 - 0s 107us/sample - loss: 0.0452 - val_loss: 0.0298\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.042 - 0s 110us/sample - loss: 0.0374 - val_loss: 0.0241\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.039 - 0s 131us/sample - loss: 0.0309 - val_loss: 0.0195\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 112us/sample - loss: 0.0255 - val_loss: 0.0157\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.021 - 0s 112us/sample - loss: 0.0210 - val_loss: 0.0129\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.027 - 0s 114us/sample - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 106us/sample - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.018 - 0s 108us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 118us/sample - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - 0s 161us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 114us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 113us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 101us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1015 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1016 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1017 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1018 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1019 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1020 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1021 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.132 - 1s 3ms/sample - loss: 0.0811 - val_loss: 0.0555\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.076 - 0s 102us/sample - loss: 0.0655 - val_loss: 0.0456\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.056 - 0s 95us/sample - loss: 0.0548 - val_loss: 0.0372\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.039 - 0s 104us/sample - loss: 0.0456 - val_loss: 0.0302\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.035 - 0s 104us/sample - loss: 0.0379 - val_loss: 0.0245\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.022 - 0s 110us/sample - loss: 0.0315 - val_loss: 0.0199\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0261 - val_loss: 0.0162\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.021 - 0s 118us/sample - loss: 0.0216 - val_loss: 0.0133\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.017 - 0s 122us/sample - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - 0s 122us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.011 - 0s 199us/sample - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 104us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 122us/sample - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 118us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 123us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 128us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 131us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 152us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 109us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1022 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1023 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1024 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1025 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1026 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1027 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1028 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.081 - 0s 903us/sample - loss: 0.0778 - val_loss: 0.0554\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.087 - 0s 133us/sample - loss: 0.0653 - val_loss: 0.0453\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.061 - ETA: 0s - loss: 0.054 - 0s 151us/sample - loss: 0.0545 - val_loss: 0.0368\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.054 - ETA: 0s - loss: 0.045 - 0s 160us/sample - loss: 0.0451 - val_loss: 0.0297\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.037 - 0s 158us/sample - loss: 0.0372 - val_loss: 0.0240\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.031 - ETA: 0s - loss: 0.030 - 0s 147us/sample - loss: 0.0308 - val_loss: 0.0194\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.026 - 0s 163us/sample - loss: 0.0254 - val_loss: 0.0157\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.021 - 0s 168us/sample - loss: 0.0211 - val_loss: 0.0129\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.019 - 0s 118us/sample - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.016 - 0s 129us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.012 - 0s 156us/sample - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - ETA: 0s - loss: 0.011 - 0s 159us/sample - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 133us/sample - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 124us/sample - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 124us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 138us/sample - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 0s 174us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 156us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 149us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 164us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.006 - 0s 143us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 117us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 114us/sample - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - 0s 143us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.006 - 0s 153us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 160us/sample - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 122us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1029 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1030 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1031 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1032 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1033 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1034 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1035 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 3s - loss: 0.023 - 0s 924us/sample - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 0s 176us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0070 - val_loss: 0.0108\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0070 - val_loss: 0.0101\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0061 - val_loss: 0.0108\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0064 - val_loss: 0.0095\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 151us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 20/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 21/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0087\n",
      "Epoch 22/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 23/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0058 - val_loss: 0.0091\n",
      "Epoch 24/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 25/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 26/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0097\n",
      "Epoch 27/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 124us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 28/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 29/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 113us/sample - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 30/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 117us/sample - loss: 0.0058 - val_loss: 0.0098\n",
      "Epoch 31/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 32/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 33/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 34/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 35/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 36/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 37/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 38/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0055 - val_loss: 0.0085\n",
      "Epoch 39/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 40/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 41/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 42/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 43/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 44/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 45/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 46/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 47/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 48/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 49/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 50/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0054 - val_loss: 0.0084\n",
      "Epoch 51/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 106us/sample - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 52/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 121us/sample - loss: 0.0053 - val_loss: 0.0096\n",
      "Epoch 53/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 125us/sample - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 54/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 55/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.005 - 0s 176us/sample - loss: 0.0055 - val_loss: 0.0089\n",
      "Epoch 56/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 57/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 58/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 59/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 60/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 123us/sample - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 61/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 62/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 63/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 64/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0051 - val_loss: 0.0116\n",
      "Epoch 65/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 116us/sample - loss: 0.0054 - val_loss: 0.0089\n",
      "Epoch 66/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 67/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.002 - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 68/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 69/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0089\n",
      "Epoch 70/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0052 - val_loss: 0.0087\n",
      "Epoch 71/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 72/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 73/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0055 - val_loss: 0.0117\n",
      "Epoch 74/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0109\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1036 (Dense)           (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1037 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_1038 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1039 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1040 (Dense)           (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_1041 (Dense)           (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1042 (Dense)           (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 481 samples, validate on 101 samples\n",
      "Epoch 1/150\n",
      "481/481 [==============================] - ETA: 2s - loss: 0.091 - 0s 964us/sample - loss: 0.0786 - val_loss: 0.0553\n",
      "Epoch 2/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.061 - 0s 106us/sample - loss: 0.0653 - val_loss: 0.0454\n",
      "Epoch 3/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.052 - 0s 112us/sample - loss: 0.0546 - val_loss: 0.0370\n",
      "Epoch 4/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.054 - 0s 110us/sample - loss: 0.0454 - val_loss: 0.0301\n",
      "Epoch 5/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.036 - 0s 108us/sample - loss: 0.0377 - val_loss: 0.0243\n",
      "Epoch 6/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.031 - 0s 118us/sample - loss: 0.0311 - val_loss: 0.0197\n",
      "Epoch 7/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.027 - 0s 112us/sample - loss: 0.0258 - val_loss: 0.0160\n",
      "Epoch 8/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.026 - 0s 104us/sample - loss: 0.0214 - val_loss: 0.0131\n",
      "Epoch 9/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0178 - val_loss: 0.0109\n",
      "Epoch 10/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.024 - 0s 131us/sample - loss: 0.0150 - val_loss: 0.0093\n",
      "Epoch 11/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 130us/sample - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 12/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.013 - ETA: 0s - loss: 0.011 - 0s 153us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 13/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.014 - 0s 122us/sample - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 14/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 124us/sample - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 15/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.011 - 0s 126us/sample - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 131us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 17/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 133us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 18/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.010 - 0s 124us/sample - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 19/150\n",
      "481/481 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0066 - val_loss: 0.0068\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(testFeature).reshape(testTarget.shape[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result)\n",
    "plt.plot(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
