{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:30:20.151038Z",
     "start_time": "2020-09-02T07:29:18.486999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: jdcal in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n",
      "      T_ID   GDAY_DS  HEADER_NO   P_ID  START_CK  BAT_ORDER_NO   PA   AB  RBI  \\\n",
      "0       HH  20160401          0  60404         0             3    1    1    0   \n",
      "1       HH  20160401          0  62700         1             9    2    2    0   \n",
      "2       HH  20160401          0  64086         1             7    6    4    0   \n",
      "3       HH  20160401          0  66740         1             5    6    6    0   \n",
      "4       HH  20160401          0  71347         1             2    6    6    1   \n",
      "...    ...       ...        ...    ...       ...           ...  ...  ...  ...   \n",
      "18679   WO  20161009          0  74215        91           374  402  341   80   \n",
      "18680   WO  20161009          0  78168       139           177  646  560   63   \n",
      "18681   WO  20161009          0  79130        15           251   80   66    7   \n",
      "18682   WO  20161009          0  79300        13           429  106   91    9   \n",
      "18683   WO  20161009          0  79365       122           965  454  411   70   \n",
      "\n",
      "       RUN  ...  BB  IB  HP  KK  GD  ERR  LOB  P_AB_CN  P_HIT_CN  GAME_COUNT  \n",
      "0        0  ...   0   0   0   0   0    0    1        0         0           1  \n",
      "1        1  ...   0   0   0   0   0    1    0        0         0           1  \n",
      "2        0  ...   1   0   0   3   0    0    1        2         0           1  \n",
      "3        0  ...   0   0   0   0   0    0    1        1         1           1  \n",
      "4        1  ...   0   0   0   2   0    0    0        1         0           1  \n",
      "...    ...  ...  ..  ..  ..  ..  ..  ...  ...      ...       ...         ...  \n",
      "18679   72  ...  46   3   9  50  16    6   77      121        35          92  \n",
      "18680  111  ...  69   2  10  58   6   15  113      118        36         140  \n",
      "18681   10  ...  11   0   1  24   1    1   18       20         3          40  \n",
      "18682   16  ...  10   0   0  16   3    0   29       25         4          81  \n",
      "18683   44  ...  27   0   7  93  18    7   71      132        33         127  \n",
      "\n",
      "[18684 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "%run batter_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T13:05:08.382310Z",
     "start_time": "2020-09-02T13:05:08.376351Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from statsmodels import tsa\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from plotly.offline import plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "feature, target = batter_data(\"NC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature = feature.loc[0:feature.shape[0]-20]\n",
    "trainTarget = target.loc[0:feature.shape[0]-20]\n",
    "\n",
    "testFeature = feature.loc[feature.shape[0]-20:].reset_index(drop = True)\n",
    "testTarget = target[feature.shape[0]-20:].reset_index(drop = True)\n",
    "trainFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "res = scaler.fit(trainFeature)\n",
    "res = scaler.transform(trainFeature)\n",
    "trainFeature = pd.DataFrame(res, columns = trainFeature.columns, index = list(trainFeature.index.values))\n",
    "res = scaler.transform(testFeature)\n",
    "testFeature = pd.DataFrame(res, columns = testFeature.columns, index = list(testFeature.index.values))\n",
    "\n",
    "res = scaler.fit(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "trainTarget = scaler.transform(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "testTarget = scaler.transform(np.array(testTarget).reshape(testTarget.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(4, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation = None))\n",
    "model.compile(optimizer = \"Adam\", loss = \"mse\")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(min_delta = 0.0005, patience = 30, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 200, validation_split = 0.3, shuffle = True,\n",
    "          use_multiprocessing = True, callbacks = [early_stopping], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 3s - loss: 0.585 - 0s 855us/sample - loss: 0.5102 - val_loss: 0.0634\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.618 - 0s 152us/sample - loss: 0.4814 - val_loss: 0.0582\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.519 - 0s 119us/sample - loss: 0.4660 - val_loss: 0.0542\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.653 - 0s 113us/sample - loss: 0.4208 - val_loss: 0.0511\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.442 - 0s 110us/sample - loss: 0.4649 - val_loss: 0.0487\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.351 - 0s 125us/sample - loss: 0.4282 - val_loss: 0.0470\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.340 - 0s 119us/sample - loss: 0.4098 - val_loss: 0.0457\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.535 - 0s 119us/sample - loss: 0.3700 - val_loss: 0.0446\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.293 - 0s 120us/sample - loss: 0.3967 - val_loss: 0.0438\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.413 - 0s 125us/sample - loss: 0.3633 - val_loss: 0.0429\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.417 - 0s 122us/sample - loss: 0.3887 - val_loss: 0.0425\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.533 - 0s 114us/sample - loss: 0.3831 - val_loss: 0.0421\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.236 - 0s 120us/sample - loss: 0.3582 - val_loss: 0.0417\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.455 - 0s 113us/sample - loss: 0.3258 - val_loss: 0.0413\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.281 - 0s 117us/sample - loss: 0.3182 - val_loss: 0.0410\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.433 - 0s 110us/sample - loss: 0.3615 - val_loss: 0.0408\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.479 - 0s 127us/sample - loss: 0.3040 - val_loss: 0.0406\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.414 - 0s 121us/sample - loss: 0.3201 - val_loss: 0.0404\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.288 - 0s 119us/sample - loss: 0.2970 - val_loss: 0.0402\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.273 - 0s 120us/sample - loss: 0.2943 - val_loss: 0.0402\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.392 - 0s 96us/sample - loss: 0.2861 - val_loss: 0.0402\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.211 - 0s 110us/sample - loss: 0.2847 - val_loss: 0.0401\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.199 - 0s 102us/sample - loss: 0.2663 - val_loss: 0.0400\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.357 - 0s 98us/sample - loss: 0.2610 - val_loss: 0.0399\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.389 - 0s 115us/sample - loss: 0.2514 - val_loss: 0.0400\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.265 - 0s 121us/sample - loss: 0.2553 - val_loss: 0.0399\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 116us/sample - loss: 0.2444 - val_loss: 0.0399\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.273 - 0s 104us/sample - loss: 0.2424 - val_loss: 0.0398\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.320 - 0s 113us/sample - loss: 0.2367 - val_loss: 0.0397\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.287 - 0s 110us/sample - loss: 0.2393 - val_loss: 0.0396\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 105us/sample - loss: 0.2386 - val_loss: 0.0394\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.249 - 0s 109us/sample - loss: 0.2390 - val_loss: 0.0395\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.200 - 0s 113us/sample - loss: 0.2054 - val_loss: 0.0395\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.237 - 0s 127us/sample - loss: 0.2309 - val_loss: 0.0395\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.221 - 0s 125us/sample - loss: 0.2064 - val_loss: 0.0393\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.242 - 0s 123us/sample - loss: 0.1996 - val_loss: 0.0393\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.182 - 0s 128us/sample - loss: 0.2134 - val_loss: 0.0391\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.283 - 0s 113us/sample - loss: 0.2001 - val_loss: 0.0389\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.247 - 0s 127us/sample - loss: 0.1913 - val_loss: 0.0387\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.150 - 0s 154us/sample - loss: 0.1739 - val_loss: 0.0388\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.271 - 0s 158us/sample - loss: 0.1811 - val_loss: 0.0388\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.192 - 0s 156us/sample - loss: 0.2012 - val_loss: 0.0383\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.235 - 0s 154us/sample - loss: 0.1831 - val_loss: 0.0382\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.259 - 0s 137us/sample - loss: 0.1635 - val_loss: 0.0382\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.168 - 0s 118us/sample - loss: 0.1570 - val_loss: 0.0383\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.160 - 0s 115us/sample - loss: 0.1785 - val_loss: 0.0381\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.202 - 0s 125us/sample - loss: 0.1633 - val_loss: 0.0379\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 115us/sample - loss: 0.1471 - val_loss: 0.0378\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.182 - 0s 123us/sample - loss: 0.1603 - val_loss: 0.0378\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 132us/sample - loss: 0.1597 - val_loss: 0.0379\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 135us/sample - loss: 0.1501 - val_loss: 0.0379\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.200 - 0s 127us/sample - loss: 0.1382 - val_loss: 0.0382\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.117 - 0s 113us/sample - loss: 0.1164 - val_loss: 0.0381\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.153 - 0s 113us/sample - loss: 0.1433 - val_loss: 0.0380\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.139 - 0s 105us/sample - loss: 0.1474 - val_loss: 0.0376\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.160 - 0s 110us/sample - loss: 0.1342 - val_loss: 0.0378\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 111us/sample - loss: 0.1118 - val_loss: 0.0378\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 94us/sample - loss: 0.1261 - val_loss: 0.0380\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 93us/sample - loss: 0.1170 - val_loss: 0.0383\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 92us/sample - loss: 0.1199 - val_loss: 0.0382\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.152 - 0s 91us/sample - loss: 0.1264 - val_loss: 0.0377\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 93us/sample - loss: 0.1201 - val_loss: 0.0374\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 103us/sample - loss: 0.1007 - val_loss: 0.0370\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 113us/sample - loss: 0.1022 - val_loss: 0.0373\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 123us/sample - loss: 0.1130 - val_loss: 0.0373\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 108us/sample - loss: 0.1109 - val_loss: 0.0373\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 85us/sample - loss: 0.0988 - val_loss: 0.0374\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 92us/sample - loss: 0.0949 - val_loss: 0.0379\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 100us/sample - loss: 0.1083 - val_loss: 0.0381\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.117 - 0s 93us/sample - loss: 0.0907 - val_loss: 0.0379\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 94us/sample - loss: 0.1033 - val_loss: 0.0379\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.124 - 0s 90us/sample - loss: 0.0945 - val_loss: 0.0380\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 94us/sample - loss: 0.0967 - val_loss: 0.0378\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 92us/sample - loss: 0.0910 - val_loss: 0.0381\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 89us/sample - loss: 0.0904 - val_loss: 0.0382\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 91us/sample - loss: 0.0928 - val_loss: 0.0381\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 87us/sample - loss: 0.0882 - val_loss: 0.0378\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 88us/sample - loss: 0.0826 - val_loss: 0.0378\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 86us/sample - loss: 0.0769 - val_loss: 0.0377\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 103us/sample - loss: 0.0878 - val_loss: 0.0374\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 120us/sample - loss: 0.0791 - val_loss: 0.0374\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 135us/sample - loss: 0.0776 - val_loss: 0.0376\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 111us/sample - loss: 0.0775 - val_loss: 0.0375\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 103us/sample - loss: 0.0795 - val_loss: 0.0373\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 113us/sample - loss: 0.0725 - val_loss: 0.0370\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 102us/sample - loss: 0.0723 - val_loss: 0.0369\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 105us/sample - loss: 0.0681 - val_loss: 0.0370\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 101us/sample - loss: 0.0726 - val_loss: 0.0371\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 91us/sample - loss: 0.0710 - val_loss: 0.0370\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 92us/sample - loss: 0.0673 - val_loss: 0.0369\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 99us/sample - loss: 0.0751 - val_loss: 0.0369\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 88us/sample - loss: 0.0684 - val_loss: 0.0365\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 100us/sample - loss: 0.0627 - val_loss: 0.0365\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 90us/sample - loss: 0.0586 - val_loss: 0.0364\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 95us/sample - loss: 0.0639 - val_loss: 0.0361\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 105us/sample - loss: 0.0589 - val_loss: 0.0358\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 100us/sample - loss: 0.0620 - val_loss: 0.0360\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 100us/sample - loss: 0.0613 - val_loss: 0.0360\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 100us/sample - loss: 0.0621 - val_loss: 0.0360\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 98us/sample - loss: 0.0564 - val_loss: 0.0361\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 118us/sample - loss: 0.0603 - val_loss: 0.0363\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 110us/sample - loss: 0.0591 - val_loss: 0.0362\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 112us/sample - loss: 0.0560 - val_loss: 0.0362\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 164us/sample - loss: 0.0492 - val_loss: 0.0361\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 149us/sample - loss: 0.0524 - val_loss: 0.0360\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 142us/sample - loss: 0.0546 - val_loss: 0.0360\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 103us/sample - loss: 0.0486 - val_loss: 0.0356\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.0578 - val_loss: 0.0356\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 99us/sample - loss: 0.0507 - val_loss: 0.0358\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0470 - val_loss: 0.0356\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 145us/sample - loss: 0.0498 - val_loss: 0.0354\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 115us/sample - loss: 0.0494 - val_loss: 0.0354\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 113us/sample - loss: 0.0488 - val_loss: 0.0352\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 101us/sample - loss: 0.0476 - val_loss: 0.0351\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 140us/sample - loss: 0.0445 - val_loss: 0.0350\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 91us/sample - loss: 0.0435 - val_loss: 0.0347\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 98us/sample - loss: 0.0427 - val_loss: 0.0342\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0428 - val_loss: 0.0338\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 119us/sample - loss: 0.0461 - val_loss: 0.0335\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 130us/sample - loss: 0.0394 - val_loss: 0.0334\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 141us/sample - loss: 0.0418 - val_loss: 0.0331\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 107us/sample - loss: 0.0419 - val_loss: 0.0331\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 104us/sample - loss: 0.0401 - val_loss: 0.0330\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 96us/sample - loss: 0.0407 - val_loss: 0.0328\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 121us/sample - loss: 0.0416 - val_loss: 0.0326\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 147us/sample - loss: 0.0420 - val_loss: 0.0323\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 125us/sample - loss: 0.0417 - val_loss: 0.0321\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 114us/sample - loss: 0.0367 - val_loss: 0.0318\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 103us/sample - loss: 0.0344 - val_loss: 0.0317\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 96us/sample - loss: 0.0365 - val_loss: 0.0314\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 112us/sample - loss: 0.0353 - val_loss: 0.0309\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 96us/sample - loss: 0.0361 - val_loss: 0.0308\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 108us/sample - loss: 0.0374 - val_loss: 0.0303\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 108us/sample - loss: 0.0370 - val_loss: 0.0300\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 100us/sample - loss: 0.0365 - val_loss: 0.0299\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 107us/sample - loss: 0.0335 - val_loss: 0.0295\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/sample - loss: 0.0343 - val_loss: 0.0290\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0354 - val_loss: 0.0289\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 92us/sample - loss: 0.0313 - val_loss: 0.0286\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 91us/sample - loss: 0.0346 - val_loss: 0.0282\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0336 - val_loss: 0.0280\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 98us/sample - loss: 0.0306 - val_loss: 0.0276\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0312 - val_loss: 0.0272\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 94us/sample - loss: 0.0328 - val_loss: 0.0270\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 101us/sample - loss: 0.0339 - val_loss: 0.0267\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 107us/sample - loss: 0.0298 - val_loss: 0.0267\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 120us/sample - loss: 0.0322 - val_loss: 0.0266\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 91us/sample - loss: 0.0330 - val_loss: 0.0267\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0317 - val_loss: 0.0266\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 107us/sample - loss: 0.0278 - val_loss: 0.0263\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.138 - 0s 757us/sample - loss: 0.1611 - val_loss: 0.1116\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.127 - 0s 123us/sample - loss: 0.1393 - val_loss: 0.0996\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 103us/sample - loss: 0.1390 - val_loss: 0.0885\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 103us/sample - loss: 0.1190 - val_loss: 0.0793\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 103us/sample - loss: 0.1116 - val_loss: 0.0713\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 98us/sample - loss: 0.1042 - val_loss: 0.0641\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 98us/sample - loss: 0.0939 - val_loss: 0.0579\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 98us/sample - loss: 0.0836 - val_loss: 0.0527\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.165 - 0s 106us/sample - loss: 0.0707 - val_loss: 0.0485\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 98us/sample - loss: 0.0761 - val_loss: 0.0446\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 103us/sample - loss: 0.0693 - val_loss: 0.0414\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 100us/sample - loss: 0.0674 - val_loss: 0.0385\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 100us/sample - loss: 0.0614 - val_loss: 0.0362\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 105us/sample - loss: 0.0592 - val_loss: 0.0343\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 89us/sample - loss: 0.0572 - val_loss: 0.0328\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 86us/sample - loss: 0.0576 - val_loss: 0.0313\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 82us/sample - loss: 0.0524 - val_loss: 0.0300\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 85us/sample - loss: 0.0534 - val_loss: 0.0288\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 88us/sample - loss: 0.0502 - val_loss: 0.0276\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0492 - val_loss: 0.0268\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0455 - val_loss: 0.0261\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 85us/sample - loss: 0.0493 - val_loss: 0.0255\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 86us/sample - loss: 0.0505 - val_loss: 0.0250\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 90us/sample - loss: 0.0447 - val_loss: 0.0246\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0440 - val_loss: 0.0243\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 86us/sample - loss: 0.0503 - val_loss: 0.0240\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 85us/sample - loss: 0.0431 - val_loss: 0.0237\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 89us/sample - loss: 0.0434 - val_loss: 0.0235\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 85us/sample - loss: 0.0405 - val_loss: 0.0234\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 83us/sample - loss: 0.0432 - val_loss: 0.0232\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 87us/sample - loss: 0.0413 - val_loss: 0.0231\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 88us/sample - loss: 0.0418 - val_loss: 0.0229\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0418 - val_loss: 0.0228\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 101us/sample - loss: 0.0439 - val_loss: 0.0227\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0409 - val_loss: 0.0226\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 82us/sample - loss: 0.0414 - val_loss: 0.0224\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0397 - val_loss: 0.0223\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 87us/sample - loss: 0.0412 - val_loss: 0.0222\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 82us/sample - loss: 0.0398 - val_loss: 0.0221\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 106us/sample - loss: 0.0404 - val_loss: 0.0220\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0416 - val_loss: 0.0219\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 108us/sample - loss: 0.0396 - val_loss: 0.0218\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 110us/sample - loss: 0.0374 - val_loss: 0.0217\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0423 - val_loss: 0.0216\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0355 - val_loss: 0.0215\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0365 - val_loss: 0.0214\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 98us/sample - loss: 0.0387 - val_loss: 0.0213\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 96us/sample - loss: 0.0356 - val_loss: 0.0213\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 102us/sample - loss: 0.0399 - val_loss: 0.0212\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 101us/sample - loss: 0.0380 - val_loss: 0.0211\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 96us/sample - loss: 0.0374 - val_loss: 0.0210\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 94us/sample - loss: 0.0341 - val_loss: 0.0209\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 92us/sample - loss: 0.0390 - val_loss: 0.0208\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 91us/sample - loss: 0.0331 - val_loss: 0.0207\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0350 - val_loss: 0.0206\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0349 - val_loss: 0.0205\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.0403 - val_loss: 0.0204\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 96us/sample - loss: 0.0353 - val_loss: 0.0203\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 102us/sample - loss: 0.0338 - val_loss: 0.0202\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 92us/sample - loss: 0.0357 - val_loss: 0.0201\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 86us/sample - loss: 0.0358 - val_loss: 0.0200\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 84us/sample - loss: 0.0314 - val_loss: 0.0200\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 85us/sample - loss: 0.0355 - val_loss: 0.0199\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0324 - val_loss: 0.0198\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 88us/sample - loss: 0.0344 - val_loss: 0.0197\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 92us/sample - loss: 0.0317 - val_loss: 0.0196\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0345 - val_loss: 0.0195\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 97us/sample - loss: 0.0317 - val_loss: 0.0194\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0319 - val_loss: 0.0193\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0325 - val_loss: 0.0192\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0318 - val_loss: 0.0192\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 89us/sample - loss: 0.0324 - val_loss: 0.0191\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0283 - val_loss: 0.0190\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0313 - val_loss: 0.0189\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 87us/sample - loss: 0.0299 - val_loss: 0.0188\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 90us/sample - loss: 0.0300 - val_loss: 0.0187\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0287 - val_loss: 0.0186\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0285 - val_loss: 0.0185\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0295 - val_loss: 0.0184\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 90us/sample - loss: 0.0303 - val_loss: 0.0184\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0292 - val_loss: 0.0183\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0290 - val_loss: 0.0182\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0252 - val_loss: 0.0181\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 100us/sample - loss: 0.0331 - val_loss: 0.0180\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 108us/sample - loss: 0.0290 - val_loss: 0.0179\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 102us/sample - loss: 0.0285 - val_loss: 0.0179\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0265 - val_loss: 0.0178\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0288 - val_loss: 0.0177\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 110us/sample - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0281 - val_loss: 0.0175\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 96us/sample - loss: 0.0258 - val_loss: 0.0175\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0265 - val_loss: 0.0174\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0282 - val_loss: 0.0173\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 104us/sample - loss: 0.0248 - val_loss: 0.0172\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0246 - val_loss: 0.0172\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0233 - val_loss: 0.0171\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0260 - val_loss: 0.0170\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 87us/sample - loss: 0.0270 - val_loss: 0.0169\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0254 - val_loss: 0.0169\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 105us/sample - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 91us/sample - loss: 0.0248 - val_loss: 0.0167\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0230 - val_loss: 0.0167\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0250 - val_loss: 0.0166\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 112us/sample - loss: 0.0249 - val_loss: 0.0166\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 91us/sample - loss: 0.0245 - val_loss: 0.0165\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0233 - val_loss: 0.0164\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 89us/sample - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0244 - val_loss: 0.0163\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 105us/sample - loss: 0.0234 - val_loss: 0.0162\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 87us/sample - loss: 0.0240 - val_loss: 0.0161\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0237 - val_loss: 0.0160\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0217 - val_loss: 0.0160\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0230 - val_loss: 0.0159\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0230 - val_loss: 0.0159\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0238 - val_loss: 0.0158\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0157\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 94us/sample - loss: 0.0238 - val_loss: 0.0156\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 89us/sample - loss: 0.0224 - val_loss: 0.0156\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 92us/sample - loss: 0.0225 - val_loss: 0.0155\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0214 - val_loss: 0.0154\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0220 - val_loss: 0.0154\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0199 - val_loss: 0.0153\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0153\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0224 - val_loss: 0.0152\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0210 - val_loss: 0.0151\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0151\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 93us/sample - loss: 0.0215 - val_loss: 0.0150\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 115us/sample - loss: 0.0207 - val_loss: 0.0150\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0207 - val_loss: 0.0149\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0202 - val_loss: 0.0149\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0207 - val_loss: 0.0148\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0219 - val_loss: 0.0147\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0212 - val_loss: 0.0147\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 105us/sample - loss: 0.0197 - val_loss: 0.0146\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0209 - val_loss: 0.0145\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0194 - val_loss: 0.0145\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0199 - val_loss: 0.0144\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 103us/sample - loss: 0.0209 - val_loss: 0.0143\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 104us/sample - loss: 0.0188 - val_loss: 0.0143\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0192 - val_loss: 0.0142\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0197 - val_loss: 0.0142\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0177 - val_loss: 0.0141\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0174 - val_loss: 0.0141\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0174 - val_loss: 0.0140\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0183 - val_loss: 0.0139\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0176 - val_loss: 0.0139\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0178 - val_loss: 0.0138\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0178 - val_loss: 0.0137\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0195 - val_loss: 0.0137\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.071 - 0s 594us/sample - loss: 0.1318 - val_loss: 0.0556\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 101us/sample - loss: 0.1142 - val_loss: 0.0478\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 105us/sample - loss: 0.1020 - val_loss: 0.0414\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 103us/sample - loss: 0.0975 - val_loss: 0.0360\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 97us/sample - loss: 0.0927 - val_loss: 0.0315\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 97us/sample - loss: 0.0912 - val_loss: 0.0276\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 88us/sample - loss: 0.0885 - val_loss: 0.0246\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 91us/sample - loss: 0.0903 - val_loss: 0.0223\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 95us/sample - loss: 0.0774 - val_loss: 0.0206\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 107us/sample - loss: 0.0781 - val_loss: 0.0192\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 113us/sample - loss: 0.0748 - val_loss: 0.0179\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 100us/sample - loss: 0.0642 - val_loss: 0.0171\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 91us/sample - loss: 0.0638 - val_loss: 0.0164\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 93us/sample - loss: 0.0668 - val_loss: 0.0158\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 94us/sample - loss: 0.0627 - val_loss: 0.0154\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 97us/sample - loss: 0.0621 - val_loss: 0.0151\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 113us/sample - loss: 0.0584 - val_loss: 0.0148\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 90us/sample - loss: 0.0546 - val_loss: 0.0146\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 97us/sample - loss: 0.0563 - val_loss: 0.0145\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 98us/sample - loss: 0.0560 - val_loss: 0.0144\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 95us/sample - loss: 0.0513 - val_loss: 0.0143\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 98us/sample - loss: 0.0495 - val_loss: 0.0142\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0528 - val_loss: 0.0142\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 87us/sample - loss: 0.0530 - val_loss: 0.0142\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 99us/sample - loss: 0.0532 - val_loss: 0.0142\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 115us/sample - loss: 0.0466 - val_loss: 0.0141\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 98us/sample - loss: 0.0500 - val_loss: 0.0140\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 93us/sample - loss: 0.0470 - val_loss: 0.0140\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 83us/sample - loss: 0.0440 - val_loss: 0.0140\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0449 - val_loss: 0.0140\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0448 - val_loss: 0.0140\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 91us/sample - loss: 0.0464 - val_loss: 0.0139\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0429 - val_loss: 0.0139\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 84us/sample - loss: 0.0426 - val_loss: 0.0139\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 89us/sample - loss: 0.0365 - val_loss: 0.0139\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 97us/sample - loss: 0.0456 - val_loss: 0.0139\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 88us/sample - loss: 0.0397 - val_loss: 0.0138\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 93us/sample - loss: 0.0372 - val_loss: 0.0138\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 87us/sample - loss: 0.0395 - val_loss: 0.0138\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0384 - val_loss: 0.0138\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 91us/sample - loss: 0.0378 - val_loss: 0.0137\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 91us/sample - loss: 0.0358 - val_loss: 0.0137\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0348 - val_loss: 0.0136\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 95us/sample - loss: 0.0365 - val_loss: 0.0135\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 91us/sample - loss: 0.0373 - val_loss: 0.0134\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0330 - val_loss: 0.0134\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 101us/sample - loss: 0.0319 - val_loss: 0.0134\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0353 - val_loss: 0.0133\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0363 - val_loss: 0.0133\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0326 - val_loss: 0.0132\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 103us/sample - loss: 0.0295 - val_loss: 0.0131\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 135us/sample - loss: 0.0334 - val_loss: 0.0130\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 105us/sample - loss: 0.0325 - val_loss: 0.0129\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 112us/sample - loss: 0.0293 - val_loss: 0.0129\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 113us/sample - loss: 0.0310 - val_loss: 0.0128\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 115us/sample - loss: 0.0304 - val_loss: 0.0127\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 110us/sample - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0290 - val_loss: 0.0127\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 113us/sample - loss: 0.0343 - val_loss: 0.0126\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 117us/sample - loss: 0.0318 - val_loss: 0.0125\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 118us/sample - loss: 0.0299 - val_loss: 0.0125\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 115us/sample - loss: 0.0293 - val_loss: 0.0124\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 115us/sample - loss: 0.0303 - val_loss: 0.0123\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.031 - 0s 189us/sample - loss: 0.0309 - val_loss: 0.0123\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 123us/sample - loss: 0.0291 - val_loss: 0.0123\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 115us/sample - loss: 0.0264 - val_loss: 0.0123\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0268 - val_loss: 0.0122\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 108us/sample - loss: 0.0271 - val_loss: 0.0121\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 109us/sample - loss: 0.0285 - val_loss: 0.0120\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0274 - val_loss: 0.0119\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0273 - val_loss: 0.0119\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0263 - val_loss: 0.0118\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0246 - val_loss: 0.0117\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0117\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 95us/sample - loss: 0.0277 - val_loss: 0.0117\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 101us/sample - loss: 0.0231 - val_loss: 0.0116\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0250 - val_loss: 0.0115\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0235 - val_loss: 0.0115\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0245 - val_loss: 0.0114\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0227 - val_loss: 0.0113\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0247 - val_loss: 0.0113\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0112\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 94us/sample - loss: 0.0236 - val_loss: 0.0112\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0224 - val_loss: 0.0112\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0227 - val_loss: 0.0111\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0245 - val_loss: 0.0111\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 85us/sample - loss: 0.0226 - val_loss: 0.0111\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0235 - val_loss: 0.0110\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0244 - val_loss: 0.0110\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0232 - val_loss: 0.0109\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0211 - val_loss: 0.0109\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0223 - val_loss: 0.0109\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0216 - val_loss: 0.0108\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0204 - val_loss: 0.0108\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 101us/sample - loss: 0.0224 - val_loss: 0.0107\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0204 - val_loss: 0.0107\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 103us/sample - loss: 0.0189 - val_loss: 0.0106\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 99us/sample - loss: 0.0185 - val_loss: 0.0106\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0217 - val_loss: 0.0106\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 103us/sample - loss: 0.0196 - val_loss: 0.0106\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 107us/sample - loss: 0.0210 - val_loss: 0.0106\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0171 - val_loss: 0.0105\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0197 - val_loss: 0.0105\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0187 - val_loss: 0.0104\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0198 - val_loss: 0.0103\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 94us/sample - loss: 0.0196 - val_loss: 0.0103\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0179 - val_loss: 0.0102\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 106us/sample - loss: 0.0185 - val_loss: 0.0102\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 101us/sample - loss: 0.0188 - val_loss: 0.0102\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 103us/sample - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 118us/sample - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 109us/sample - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 108us/sample - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0177 - val_loss: 0.0099\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 89us/sample - loss: 0.0192 - val_loss: 0.0099\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0190 - val_loss: 0.0098\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0098\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0177 - val_loss: 0.0098\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0098\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0170 - val_loss: 0.0097\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0176 - val_loss: 0.0097\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0158 - val_loss: 0.0097\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0157 - val_loss: 0.0096\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0138 - val_loss: 0.0094\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0153 - val_loss: 0.0094\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 102us/sample - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0133 - val_loss: 0.0092\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0134 - val_loss: 0.0092\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0151 - val_loss: 0.0092\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 107us/sample - loss: 0.0145 - val_loss: 0.0091\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.251 - 0s 581us/sample - loss: 0.2135 - val_loss: 0.0630\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.252 - 0s 91us/sample - loss: 0.2201 - val_loss: 0.0599\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 95us/sample - loss: 0.1958 - val_loss: 0.0572\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 96us/sample - loss: 0.1957 - val_loss: 0.0550\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 103us/sample - loss: 0.1693 - val_loss: 0.0530\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 96us/sample - loss: 0.1545 - val_loss: 0.0514\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 93us/sample - loss: 0.1654 - val_loss: 0.0502\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 90us/sample - loss: 0.1615 - val_loss: 0.0488\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 94us/sample - loss: 0.1694 - val_loss: 0.0475\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.171 - 0s 92us/sample - loss: 0.1544 - val_loss: 0.0466\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.190 - 0s 102us/sample - loss: 0.1378 - val_loss: 0.0454\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.180 - 0s 101us/sample - loss: 0.1269 - val_loss: 0.0446\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 106us/sample - loss: 0.1493 - val_loss: 0.0434\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 93us/sample - loss: 0.1297 - val_loss: 0.0423\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 108us/sample - loss: 0.1340 - val_loss: 0.0413\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.157 - 0s 99us/sample - loss: 0.1250 - val_loss: 0.0404\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 108us/sample - loss: 0.1317 - val_loss: 0.0395\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.128 - 0s 106us/sample - loss: 0.1296 - val_loss: 0.0386\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 99us/sample - loss: 0.1129 - val_loss: 0.0378\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 98us/sample - loss: 0.1021 - val_loss: 0.0369\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 90us/sample - loss: 0.1146 - val_loss: 0.0362\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 100us/sample - loss: 0.1104 - val_loss: 0.0354\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 103us/sample - loss: 0.0945 - val_loss: 0.0348\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 96us/sample - loss: 0.1049 - val_loss: 0.0341\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 98us/sample - loss: 0.0888 - val_loss: 0.0335\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 94us/sample - loss: 0.0888 - val_loss: 0.0331\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 98us/sample - loss: 0.1068 - val_loss: 0.0325\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 91us/sample - loss: 0.1019 - val_loss: 0.0320\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 95us/sample - loss: 0.0916 - val_loss: 0.0314\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 98us/sample - loss: 0.0793 - val_loss: 0.0308\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 91us/sample - loss: 0.0894 - val_loss: 0.0303\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 100us/sample - loss: 0.0862 - val_loss: 0.0298\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 105us/sample - loss: 0.0816 - val_loss: 0.0294\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0856 - val_loss: 0.0290\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 98us/sample - loss: 0.0811 - val_loss: 0.0286\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 79us/sample - loss: 0.0724 - val_loss: 0.0283\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 86us/sample - loss: 0.0753 - val_loss: 0.0280\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 86us/sample - loss: 0.0721 - val_loss: 0.0277\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 94us/sample - loss: 0.0754 - val_loss: 0.0274\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 96us/sample - loss: 0.0670 - val_loss: 0.0270\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 86us/sample - loss: 0.0697 - val_loss: 0.0266\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.127 - 0s 93us/sample - loss: 0.0615 - val_loss: 0.0264\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 95us/sample - loss: 0.0610 - val_loss: 0.0262\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 98us/sample - loss: 0.0636 - val_loss: 0.0259\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 88us/sample - loss: 0.0708 - val_loss: 0.0255\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 89us/sample - loss: 0.0649 - val_loss: 0.0253\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 87us/sample - loss: 0.0637 - val_loss: 0.0250\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 109us/sample - loss: 0.0612 - val_loss: 0.0247\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.0568 - val_loss: 0.0245\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 103us/sample - loss: 0.0531 - val_loss: 0.0241\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 100us/sample - loss: 0.0558 - val_loss: 0.0240\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 108us/sample - loss: 0.0584 - val_loss: 0.0237\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 98us/sample - loss: 0.0546 - val_loss: 0.0234\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0483 - val_loss: 0.0231\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 87us/sample - loss: 0.0541 - val_loss: 0.0228\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 95us/sample - loss: 0.0499 - val_loss: 0.0225\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 103us/sample - loss: 0.0500 - val_loss: 0.0223\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 103us/sample - loss: 0.0461 - val_loss: 0.0220\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 101us/sample - loss: 0.0488 - val_loss: 0.0219\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 106us/sample - loss: 0.0471 - val_loss: 0.0217\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 96us/sample - loss: 0.0458 - val_loss: 0.0215\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 108us/sample - loss: 0.0480 - val_loss: 0.0213\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 107us/sample - loss: 0.0476 - val_loss: 0.0210\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0454 - val_loss: 0.0209\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 110us/sample - loss: 0.0414 - val_loss: 0.0208\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 96us/sample - loss: 0.0423 - val_loss: 0.0207\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0421 - val_loss: 0.0205\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 100us/sample - loss: 0.0395 - val_loss: 0.0204\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0440 - val_loss: 0.0203\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0366 - val_loss: 0.0202\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 98us/sample - loss: 0.0389 - val_loss: 0.0200\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0379 - val_loss: 0.0199\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.0373 - val_loss: 0.0197\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 105us/sample - loss: 0.0400 - val_loss: 0.0196\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 103us/sample - loss: 0.0378 - val_loss: 0.0195\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 100us/sample - loss: 0.0349 - val_loss: 0.0193\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 96us/sample - loss: 0.0345 - val_loss: 0.0192\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 85us/sample - loss: 0.0374 - val_loss: 0.0190\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0362 - val_loss: 0.0188\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0352 - val_loss: 0.0187\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0340 - val_loss: 0.0186\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 106us/sample - loss: 0.0310 - val_loss: 0.0184\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 98us/sample - loss: 0.0317 - val_loss: 0.0183\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 83us/sample - loss: 0.0361 - val_loss: 0.0181\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 87us/sample - loss: 0.0298 - val_loss: 0.0180\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 93us/sample - loss: 0.0310 - val_loss: 0.0179\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 89us/sample - loss: 0.0361 - val_loss: 0.0177\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0326 - val_loss: 0.0176\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 80us/sample - loss: 0.0285 - val_loss: 0.0175\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0258 - val_loss: 0.0174\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 83us/sample - loss: 0.0308 - val_loss: 0.0173\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0283 - val_loss: 0.0172\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 91us/sample - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 91us/sample - loss: 0.0307 - val_loss: 0.0170\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0282 - val_loss: 0.0168\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 91us/sample - loss: 0.0318 - val_loss: 0.0167\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0291 - val_loss: 0.0166\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 96us/sample - loss: 0.0293 - val_loss: 0.0165\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0256 - val_loss: 0.0164\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0280 - val_loss: 0.0162\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0253 - val_loss: 0.0161\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0252 - val_loss: 0.0159\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 96us/sample - loss: 0.0270 - val_loss: 0.0158\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0246 - val_loss: 0.0157\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0268 - val_loss: 0.0156\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0247 - val_loss: 0.0154\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0259 - val_loss: 0.0154\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 104us/sample - loss: 0.0247 - val_loss: 0.0153\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 101us/sample - loss: 0.0212 - val_loss: 0.0152\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 122us/sample - loss: 0.0235 - val_loss: 0.0151\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0237 - val_loss: 0.0150\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 99us/sample - loss: 0.0230 - val_loss: 0.0149\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 96us/sample - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0255 - val_loss: 0.0147\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0224 - val_loss: 0.0146\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0228 - val_loss: 0.0145\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0216 - val_loss: 0.0143\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 113us/sample - loss: 0.0222 - val_loss: 0.0142\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 120us/sample - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0225 - val_loss: 0.0140\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0203 - val_loss: 0.0139\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0220 - val_loss: 0.0137\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0199 - val_loss: 0.0135\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0197 - val_loss: 0.0134\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0197 - val_loss: 0.0133\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 91us/sample - loss: 0.0213 - val_loss: 0.0132\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 84us/sample - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 99us/sample - loss: 0.0217 - val_loss: 0.0131\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 107us/sample - loss: 0.0191 - val_loss: 0.0129\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 120us/sample - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0194 - val_loss: 0.0127\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0169 - val_loss: 0.0122\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 92us/sample - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 103us/sample - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 101us/sample - loss: 0.0167 - val_loss: 0.0117\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 99us/sample - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 101us/sample - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0114\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.260 - 0s 622us/sample - loss: 0.2452 - val_loss: 0.1903\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.257 - 0s 101us/sample - loss: 0.2280 - val_loss: 0.1788\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 96us/sample - loss: 0.2134 - val_loss: 0.1684\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 96us/sample - loss: 0.1797 - val_loss: 0.1595\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.265 - 0s 98us/sample - loss: 0.1905 - val_loss: 0.1509\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.215 - 0s 103us/sample - loss: 0.1644 - val_loss: 0.1431\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 97us/sample - loss: 0.1701 - val_loss: 0.1360\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 94us/sample - loss: 0.1405 - val_loss: 0.1295\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 93us/sample - loss: 0.1577 - val_loss: 0.1235\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.179 - 0s 94us/sample - loss: 0.1461 - val_loss: 0.1171\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 92us/sample - loss: 0.1421 - val_loss: 0.1112\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.179 - 0s 97us/sample - loss: 0.1357 - val_loss: 0.1061\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 97us/sample - loss: 0.1195 - val_loss: 0.1012\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 96us/sample - loss: 0.1347 - val_loss: 0.0965\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.220 - 0s 93us/sample - loss: 0.1301 - val_loss: 0.0916\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 97us/sample - loss: 0.1016 - val_loss: 0.0879\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 83us/sample - loss: 0.1069 - val_loss: 0.0844\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 92us/sample - loss: 0.1001 - val_loss: 0.0805\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 90us/sample - loss: 0.0954 - val_loss: 0.0772\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 95us/sample - loss: 0.0954 - val_loss: 0.0738\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 107us/sample - loss: 0.0936 - val_loss: 0.0705\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 101us/sample - loss: 0.0924 - val_loss: 0.0676\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 103us/sample - loss: 0.0862 - val_loss: 0.0644\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 104us/sample - loss: 0.0776 - val_loss: 0.0613\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 105us/sample - loss: 0.0826 - val_loss: 0.0584\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 107us/sample - loss: 0.0779 - val_loss: 0.0558\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.179 - 0s 98us/sample - loss: 0.0724 - val_loss: 0.0535\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 103us/sample - loss: 0.0735 - val_loss: 0.0513\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 112us/sample - loss: 0.0649 - val_loss: 0.0493\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 96us/sample - loss: 0.0603 - val_loss: 0.0474\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 100us/sample - loss: 0.0615 - val_loss: 0.0456\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 94us/sample - loss: 0.0629 - val_loss: 0.0440\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0585 - val_loss: 0.0425\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 99us/sample - loss: 0.0625 - val_loss: 0.0410\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 103us/sample - loss: 0.0557 - val_loss: 0.0396\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 111us/sample - loss: 0.0553 - val_loss: 0.0383\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 102us/sample - loss: 0.0521 - val_loss: 0.0372\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0504 - val_loss: 0.0361\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0512 - val_loss: 0.0349\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 96us/sample - loss: 0.0495 - val_loss: 0.0338\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0480 - val_loss: 0.0330\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 90us/sample - loss: 0.0478 - val_loss: 0.0321\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 94us/sample - loss: 0.0485 - val_loss: 0.0314\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 90us/sample - loss: 0.0441 - val_loss: 0.0306\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0395 - val_loss: 0.0297\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 89us/sample - loss: 0.0380 - val_loss: 0.0291\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0448 - val_loss: 0.0285\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 86us/sample - loss: 0.0457 - val_loss: 0.0278\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 93us/sample - loss: 0.0395 - val_loss: 0.0273\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0402 - val_loss: 0.0267\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0356 - val_loss: 0.0262\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 102us/sample - loss: 0.0375 - val_loss: 0.0247\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 93us/sample - loss: 0.0388 - val_loss: 0.0243\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 94us/sample - loss: 0.0326 - val_loss: 0.0239\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 101us/sample - loss: 0.0342 - val_loss: 0.0235\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0356 - val_loss: 0.0232\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 91us/sample - loss: 0.0337 - val_loss: 0.0229\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0331 - val_loss: 0.0225\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 92us/sample - loss: 0.0289 - val_loss: 0.0222\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 95us/sample - loss: 0.0328 - val_loss: 0.0218\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0309 - val_loss: 0.0215\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 113us/sample - loss: 0.0271 - val_loss: 0.0213\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 103us/sample - loss: 0.0298 - val_loss: 0.0210\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0292 - val_loss: 0.0206\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 98us/sample - loss: 0.0301 - val_loss: 0.0203\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0266 - val_loss: 0.0201\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 105us/sample - loss: 0.0268 - val_loss: 0.0199\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 99us/sample - loss: 0.0320 - val_loss: 0.0196\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 99us/sample - loss: 0.0264 - val_loss: 0.0194\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0278 - val_loss: 0.0192\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0264 - val_loss: 0.0189\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 103us/sample - loss: 0.0299 - val_loss: 0.0187\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0285 - val_loss: 0.0185\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 122us/sample - loss: 0.0319 - val_loss: 0.0183\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 111us/sample - loss: 0.0267 - val_loss: 0.0181\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 111us/sample - loss: 0.0285 - val_loss: 0.0179\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 113us/sample - loss: 0.0258 - val_loss: 0.0177\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 115us/sample - loss: 0.0274 - val_loss: 0.0174\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 118us/sample - loss: 0.0267 - val_loss: 0.0172\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 115us/sample - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 108us/sample - loss: 0.0261 - val_loss: 0.0169\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0255 - val_loss: 0.0167\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0270 - val_loss: 0.0165\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 117us/sample - loss: 0.0251 - val_loss: 0.0164\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0278 - val_loss: 0.0162\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 118us/sample - loss: 0.0251 - val_loss: 0.0160\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 113us/sample - loss: 0.0265 - val_loss: 0.0159\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0217 - val_loss: 0.0157\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 93us/sample - loss: 0.0232 - val_loss: 0.0155\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0210 - val_loss: 0.0154\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0250 - val_loss: 0.0153\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 101us/sample - loss: 0.0235 - val_loss: 0.0151\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0193 - val_loss: 0.0150\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0255 - val_loss: 0.0149\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0212 - val_loss: 0.0147\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 108us/sample - loss: 0.0204 - val_loss: 0.0146\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 99us/sample - loss: 0.0216 - val_loss: 0.0144\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0237 - val_loss: 0.0143\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 108us/sample - loss: 0.0229 - val_loss: 0.0141\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0229 - val_loss: 0.0140\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0217 - val_loss: 0.0139\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0191 - val_loss: 0.0137\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 107us/sample - loss: 0.0188 - val_loss: 0.0136\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 105us/sample - loss: 0.0208 - val_loss: 0.0134\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 110us/sample - loss: 0.0190 - val_loss: 0.0133\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 94us/sample - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 97us/sample - loss: 0.0192 - val_loss: 0.0131\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 123us/sample - loss: 0.0203 - val_loss: 0.0130\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 123us/sample - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 101us/sample - loss: 0.0192 - val_loss: 0.0129\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0188 - val_loss: 0.0127\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 92us/sample - loss: 0.0209 - val_loss: 0.0126\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0185 - val_loss: 0.0125\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0188 - val_loss: 0.0123\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0182 - val_loss: 0.0121\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0189 - val_loss: 0.0120\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0175 - val_loss: 0.0116\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0180 - val_loss: 0.0113\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 139us/sample - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 92us/sample - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0110\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0109\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0106\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 87us/sample - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0104\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0161 - val_loss: 0.0102\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0160 - val_loss: 0.0101\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0139 - val_loss: 0.0100\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 1.128 - 0s 593us/sample - loss: 1.1567 - val_loss: 0.9849\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.084 - 0s 101us/sample - loss: 1.0478 - val_loss: 0.9238\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.953 - 0s 93us/sample - loss: 0.9907 - val_loss: 0.8653\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.937 - 0s 96us/sample - loss: 0.8794 - val_loss: 0.8104\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.782 - 0s 92us/sample - loss: 0.9041 - val_loss: 0.7580\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.771 - 0s 95us/sample - loss: 0.7798 - val_loss: 0.7059\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.544 - 0s 88us/sample - loss: 0.7962 - val_loss: 0.6572\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.392 - 0s 88us/sample - loss: 0.6889 - val_loss: 0.6124\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.825 - 0s 88us/sample - loss: 0.6710 - val_loss: 0.5687\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.264 - 0s 89us/sample - loss: 0.6213 - val_loss: 0.5280\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.678 - 0s 99us/sample - loss: 0.5466 - val_loss: 0.4902\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.667 - 0s 99us/sample - loss: 0.5628 - val_loss: 0.4542\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.286 - 0s 105us/sample - loss: 0.4895 - val_loss: 0.4202\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.450 - 0s 104us/sample - loss: 0.4649 - val_loss: 0.3886\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.416 - 0s 93us/sample - loss: 0.4353 - val_loss: 0.3600\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.568 - 0s 96us/sample - loss: 0.4075 - val_loss: 0.3331\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.202 - 0s 94us/sample - loss: 0.3811 - val_loss: 0.3080\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.297 - 0s 90us/sample - loss: 0.3470 - val_loss: 0.2840\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.416 - 0s 100us/sample - loss: 0.3284 - val_loss: 0.2625\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.582 - 0s 99us/sample - loss: 0.3024 - val_loss: 0.2422\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.283 - 0s 103us/sample - loss: 0.3104 - val_loss: 0.2234\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.237 - 0s 107us/sample - loss: 0.2775 - val_loss: 0.2056\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.268 - 0s 105us/sample - loss: 0.2674 - val_loss: 0.1886\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 108us/sample - loss: 0.2425 - val_loss: 0.1743\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.248 - 0s 106us/sample - loss: 0.1989 - val_loss: 0.1604\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.203 - 0s 103us/sample - loss: 0.2061 - val_loss: 0.1482\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.250 - 0s 108us/sample - loss: 0.1863 - val_loss: 0.1369\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 102us/sample - loss: 0.1752 - val_loss: 0.1268\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 93us/sample - loss: 0.1798 - val_loss: 0.1170\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.154 - 0s 105us/sample - loss: 0.1486 - val_loss: 0.1077\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 96us/sample - loss: 0.1621 - val_loss: 0.1000\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 96us/sample - loss: 0.1577 - val_loss: 0.0928\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 81us/sample - loss: 0.1310 - val_loss: 0.0859\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 81us/sample - loss: 0.1216 - val_loss: 0.0801\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.195 - 0s 83us/sample - loss: 0.1484 - val_loss: 0.0746\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 88us/sample - loss: 0.1337 - val_loss: 0.0688\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.1168 - val_loss: 0.0644\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 83us/sample - loss: 0.1198 - val_loss: 0.0600\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 88us/sample - loss: 0.1079 - val_loss: 0.0562\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 91us/sample - loss: 0.1026 - val_loss: 0.0530\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 91us/sample - loss: 0.1161 - val_loss: 0.0497\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.1004 - val_loss: 0.0468\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 96us/sample - loss: 0.1010 - val_loss: 0.0442\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 89us/sample - loss: 0.0947 - val_loss: 0.0420\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.112 - 0s 93us/sample - loss: 0.0996 - val_loss: 0.0399\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 94us/sample - loss: 0.0937 - val_loss: 0.0378\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 83us/sample - loss: 0.0935 - val_loss: 0.0360\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 88us/sample - loss: 0.0882 - val_loss: 0.0345\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 97us/sample - loss: 0.0877 - val_loss: 0.0330\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 99us/sample - loss: 0.0871 - val_loss: 0.0317\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 92us/sample - loss: 0.0786 - val_loss: 0.0305\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 81us/sample - loss: 0.0814 - val_loss: 0.0295\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 79us/sample - loss: 0.0751 - val_loss: 0.0287\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 86us/sample - loss: 0.0775 - val_loss: 0.0278\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 81us/sample - loss: 0.0823 - val_loss: 0.0269\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 101us/sample - loss: 0.0723 - val_loss: 0.0262\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 97us/sample - loss: 0.0734 - val_loss: 0.0253\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 98us/sample - loss: 0.0798 - val_loss: 0.0246\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 96us/sample - loss: 0.0736 - val_loss: 0.0238\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 95us/sample - loss: 0.0654 - val_loss: 0.0234\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 97us/sample - loss: 0.0672 - val_loss: 0.0231\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 105us/sample - loss: 0.0692 - val_loss: 0.0228\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 110us/sample - loss: 0.0673 - val_loss: 0.0223\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 100us/sample - loss: 0.0599 - val_loss: 0.0220\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 99us/sample - loss: 0.0698 - val_loss: 0.0216\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 101us/sample - loss: 0.0642 - val_loss: 0.0215\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0628 - val_loss: 0.0213\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 98us/sample - loss: 0.0652 - val_loss: 0.0211\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 94us/sample - loss: 0.0528 - val_loss: 0.0207\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0607 - val_loss: 0.0203\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 91us/sample - loss: 0.0540 - val_loss: 0.0201\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0634 - val_loss: 0.0199\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 97us/sample - loss: 0.0599 - val_loss: 0.0196\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 92us/sample - loss: 0.0621 - val_loss: 0.0194\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 98us/sample - loss: 0.0626 - val_loss: 0.0190\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 92us/sample - loss: 0.0558 - val_loss: 0.0189\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 93us/sample - loss: 0.0536 - val_loss: 0.0188\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 90us/sample - loss: 0.0494 - val_loss: 0.0186\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 98us/sample - loss: 0.0530 - val_loss: 0.0184\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 94us/sample - loss: 0.0508 - val_loss: 0.0183\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 91us/sample - loss: 0.0507 - val_loss: 0.0182\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 96us/sample - loss: 0.0539 - val_loss: 0.0182\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 93us/sample - loss: 0.0540 - val_loss: 0.0181\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 92us/sample - loss: 0.0481 - val_loss: 0.0179\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 93us/sample - loss: 0.0491 - val_loss: 0.0178\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 91us/sample - loss: 0.0458 - val_loss: 0.0178\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0463 - val_loss: 0.0176\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 91us/sample - loss: 0.0468 - val_loss: 0.0176\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 86us/sample - loss: 0.0484 - val_loss: 0.0173\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0439 - val_loss: 0.0172\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0412 - val_loss: 0.0171\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 93us/sample - loss: 0.0471 - val_loss: 0.0171\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 89us/sample - loss: 0.0488 - val_loss: 0.0171\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0482 - val_loss: 0.0170\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0457 - val_loss: 0.0169\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0431 - val_loss: 0.0168\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 86us/sample - loss: 0.0468 - val_loss: 0.0168\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 83us/sample - loss: 0.0403 - val_loss: 0.0167\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 87us/sample - loss: 0.0399 - val_loss: 0.0167\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 105us/sample - loss: 0.0388 - val_loss: 0.0166\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 103us/sample - loss: 0.0384 - val_loss: 0.0167\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 110us/sample - loss: 0.0399 - val_loss: 0.0167\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0433 - val_loss: 0.0167\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 92us/sample - loss: 0.0384 - val_loss: 0.0167\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 88us/sample - loss: 0.0349 - val_loss: 0.0168\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 96us/sample - loss: 0.0370 - val_loss: 0.0167\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 96us/sample - loss: 0.0397 - val_loss: 0.0167\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0403 - val_loss: 0.0166\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.0410 - val_loss: 0.0166\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0357 - val_loss: 0.0165\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0338 - val_loss: 0.0164\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 98us/sample - loss: 0.0370 - val_loss: 0.0163\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 100us/sample - loss: 0.0325 - val_loss: 0.0163\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 99us/sample - loss: 0.0343 - val_loss: 0.0162\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0409 - val_loss: 0.0161\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0325 - val_loss: 0.0160\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0344 - val_loss: 0.0160\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0335 - val_loss: 0.0160\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 101us/sample - loss: 0.0305 - val_loss: 0.0159\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 83us/sample - loss: 0.0357 - val_loss: 0.0159\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 85us/sample - loss: 0.0337 - val_loss: 0.0159\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0321 - val_loss: 0.0158\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0311 - val_loss: 0.0157\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0311 - val_loss: 0.0157\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 93us/sample - loss: 0.0300 - val_loss: 0.0157\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0309 - val_loss: 0.0156\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 88us/sample - loss: 0.0302 - val_loss: 0.0156\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 91us/sample - loss: 0.0295 - val_loss: 0.0155\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0289 - val_loss: 0.0155\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0313 - val_loss: 0.0154\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0281 - val_loss: 0.0154\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0288 - val_loss: 0.0153\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0263 - val_loss: 0.0152\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0253 - val_loss: 0.0151\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0300 - val_loss: 0.0151\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 91us/sample - loss: 0.0293 - val_loss: 0.0150\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0268 - val_loss: 0.0149\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0249 - val_loss: 0.0149\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 101us/sample - loss: 0.0266 - val_loss: 0.0150\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0279 - val_loss: 0.0149\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 89us/sample - loss: 0.0277 - val_loss: 0.0149\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0242 - val_loss: 0.0148\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0273 - val_loss: 0.0147\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 107us/sample - loss: 0.0263 - val_loss: 0.0146\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 100us/sample - loss: 0.0248 - val_loss: 0.0146\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 115us/sample - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 108us/sample - loss: 0.0238 - val_loss: 0.0146\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 108us/sample - loss: 0.0273 - val_loss: 0.0146\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0289 - val_loss: 0.0145\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0236 - val_loss: 0.0144\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 1.978 - 0s 588us/sample - loss: 1.7008 - val_loss: 1.3953\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.040 - 0s 93us/sample - loss: 1.5872 - val_loss: 1.2863\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.708 - 0s 93us/sample - loss: 1.5736 - val_loss: 1.1851\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.427 - 0s 105us/sample - loss: 1.3617 - val_loss: 1.0905\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.786 - 0s 86us/sample - loss: 1.2303 - val_loss: 1.0085\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.884 - 0s 91us/sample - loss: 1.1951 - val_loss: 0.9282\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.021 - 0s 96us/sample - loss: 1.1705 - val_loss: 0.8537\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.246 - 0s 93us/sample - loss: 1.0510 - val_loss: 0.7874\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.806 - 0s 91us/sample - loss: 0.9077 - val_loss: 0.7249\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.580 - 0s 91us/sample - loss: 0.8318 - val_loss: 0.6684\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.892 - 0s 91us/sample - loss: 0.9452 - val_loss: 0.6110\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.912 - 0s 86us/sample - loss: 0.6946 - val_loss: 0.5643\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.868 - 0s 89us/sample - loss: 0.7890 - val_loss: 0.5173\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.667 - 0s 88us/sample - loss: 0.7534 - val_loss: 0.4751\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.471 - 0s 94us/sample - loss: 0.6850 - val_loss: 0.4349\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.937 - 0s 86us/sample - loss: 0.6455 - val_loss: 0.3977\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.781 - 0s 96us/sample - loss: 0.6344 - val_loss: 0.3641\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.716 - 0s 91us/sample - loss: 0.5742 - val_loss: 0.3348\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.476 - 0s 96us/sample - loss: 0.5608 - val_loss: 0.3091\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.414 - 0s 100us/sample - loss: 0.5242 - val_loss: 0.2852\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.636 - 0s 108us/sample - loss: 0.4649 - val_loss: 0.2627\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.576 - 0s 98us/sample - loss: 0.5231 - val_loss: 0.2417\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.450 - 0s 114us/sample - loss: 0.5072 - val_loss: 0.2213\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.407 - 0s 110us/sample - loss: 0.4195 - val_loss: 0.2041\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.703 - 0s 100us/sample - loss: 0.4530 - val_loss: 0.1881\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.350 - 0s 99us/sample - loss: 0.4622 - val_loss: 0.1731\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.500 - 0s 100us/sample - loss: 0.4199 - val_loss: 0.1596\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.429 - 0s 93us/sample - loss: 0.4325 - val_loss: 0.1463\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.523 - 0s 98us/sample - loss: 0.3611 - val_loss: 0.1356\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.261 - 0s 97us/sample - loss: 0.3271 - val_loss: 0.1265\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.256 - 0s 97us/sample - loss: 0.3245 - val_loss: 0.1186\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.449 - 0s 98us/sample - loss: 0.3498 - val_loss: 0.1107\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.171 - 0s 96us/sample - loss: 0.2988 - val_loss: 0.1044\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.779 - 0s 98us/sample - loss: 0.3613 - val_loss: 0.0971\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.363 - 0s 96us/sample - loss: 0.3226 - val_loss: 0.0908\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.242 - 0s 110us/sample - loss: 0.3025 - val_loss: 0.0854\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 91us/sample - loss: 0.2843 - val_loss: 0.0812\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.242 - 0s 105us/sample - loss: 0.2965 - val_loss: 0.0776\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 94us/sample - loss: 0.2948 - val_loss: 0.0746\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.198 - 0s 85us/sample - loss: 0.3013 - val_loss: 0.0712\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.316 - 0s 86us/sample - loss: 0.2958 - val_loss: 0.0685\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.275 - 0s 84us/sample - loss: 0.2794 - val_loss: 0.0663\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.473 - 0s 84us/sample - loss: 0.2754 - val_loss: 0.0640\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.266 - 0s 87us/sample - loss: 0.2998 - val_loss: 0.0617\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.369 - 0s 88us/sample - loss: 0.2529 - val_loss: 0.0600\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.257 - 0s 93us/sample - loss: 0.2703 - val_loss: 0.0581\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.226 - 0s 95us/sample - loss: 0.2463 - val_loss: 0.0568\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.160 - 0s 91us/sample - loss: 0.2633 - val_loss: 0.0552\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.257 - 0s 93us/sample - loss: 0.2634 - val_loss: 0.0540\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.256 - 0s 93us/sample - loss: 0.2296 - val_loss: 0.0528\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.327 - 0s 83us/sample - loss: 0.2314 - val_loss: 0.0517\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.334 - 0s 93us/sample - loss: 0.2579 - val_loss: 0.0501\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.312 - 0s 87us/sample - loss: 0.2593 - val_loss: 0.0485\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.331 - 0s 86us/sample - loss: 0.2301 - val_loss: 0.0480\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 86us/sample - loss: 0.2380 - val_loss: 0.0472\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.437 - 0s 81us/sample - loss: 0.2369 - val_loss: 0.0465\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.312 - 0s 83us/sample - loss: 0.2150 - val_loss: 0.0463\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 83us/sample - loss: 0.1956 - val_loss: 0.0457\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.230 - 0s 83us/sample - loss: 0.2157 - val_loss: 0.0450\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.341 - 0s 84us/sample - loss: 0.2250 - val_loss: 0.0445\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.255 - 0s 86us/sample - loss: 0.2124 - val_loss: 0.0441\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 88us/sample - loss: 0.2159 - val_loss: 0.0434\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 91us/sample - loss: 0.2091 - val_loss: 0.0430\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.211 - 0s 86us/sample - loss: 0.2313 - val_loss: 0.0429\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.222 - 0s 94us/sample - loss: 0.2192 - val_loss: 0.0423\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 100us/sample - loss: 0.2100 - val_loss: 0.0419\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 100us/sample - loss: 0.2070 - val_loss: 0.0414\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 93us/sample - loss: 0.1987 - val_loss: 0.0407\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 101us/sample - loss: 0.1790 - val_loss: 0.0403\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.236 - 0s 97us/sample - loss: 0.1851 - val_loss: 0.0401\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.271 - 0s 99us/sample - loss: 0.1822 - val_loss: 0.0395\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.222 - 0s 103us/sample - loss: 0.2000 - val_loss: 0.0391\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 105us/sample - loss: 0.2046 - val_loss: 0.0385\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.228 - 0s 100us/sample - loss: 0.1793 - val_loss: 0.0379\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.145 - 0s 96us/sample - loss: 0.1918 - val_loss: 0.0376\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.314 - 0s 91us/sample - loss: 0.1817 - val_loss: 0.0372\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.152 - 0s 93us/sample - loss: 0.1662 - val_loss: 0.0367\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.228 - 0s 95us/sample - loss: 0.1799 - val_loss: 0.0362\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.191 - 0s 100us/sample - loss: 0.1810 - val_loss: 0.0356\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.213 - 0s 91us/sample - loss: 0.1695 - val_loss: 0.0353\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 96us/sample - loss: 0.1632 - val_loss: 0.0350\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 93us/sample - loss: 0.1649 - val_loss: 0.0346\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 92us/sample - loss: 0.1474 - val_loss: 0.0344\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 93us/sample - loss: 0.1673 - val_loss: 0.0343\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 87us/sample - loss: 0.1572 - val_loss: 0.0338\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.207 - 0s 83us/sample - loss: 0.1536 - val_loss: 0.0335\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.170 - 0s 83us/sample - loss: 0.1505 - val_loss: 0.0331\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 80us/sample - loss: 0.1606 - val_loss: 0.0328\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 82us/sample - loss: 0.1476 - val_loss: 0.0325\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 81us/sample - loss: 0.1477 - val_loss: 0.0323\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 89us/sample - loss: 0.1444 - val_loss: 0.0320\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 88us/sample - loss: 0.1495 - val_loss: 0.0317\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.177 - 0s 111us/sample - loss: 0.1411 - val_loss: 0.0312\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.124 - 0s 107us/sample - loss: 0.1353 - val_loss: 0.0308\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 101us/sample - loss: 0.1400 - val_loss: 0.0304\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 101us/sample - loss: 0.1419 - val_loss: 0.0300\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.183 - 0s 103us/sample - loss: 0.1583 - val_loss: 0.0296\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 104us/sample - loss: 0.1456 - val_loss: 0.0292\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 110us/sample - loss: 0.1369 - val_loss: 0.0289\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 113us/sample - loss: 0.1311 - val_loss: 0.0284\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 120us/sample - loss: 0.1192 - val_loss: 0.0282\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 117us/sample - loss: 0.1271 - val_loss: 0.0278\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 113us/sample - loss: 0.1251 - val_loss: 0.0274\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 100us/sample - loss: 0.1098 - val_loss: 0.0270\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 125us/sample - loss: 0.1107 - val_loss: 0.0267\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 137us/sample - loss: 0.1029 - val_loss: 0.0264\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 132us/sample - loss: 0.1027 - val_loss: 0.0262\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 111us/sample - loss: 0.1024 - val_loss: 0.0261\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 122us/sample - loss: 0.1163 - val_loss: 0.0259\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 130us/sample - loss: 0.1090 - val_loss: 0.0258\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 130us/sample - loss: 0.1188 - val_loss: 0.0253\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.190 - 0s 115us/sample - loss: 0.1085 - val_loss: 0.0250\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 110us/sample - loss: 0.1054 - val_loss: 0.0246\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 121us/sample - loss: 0.1037 - val_loss: 0.0244\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 118us/sample - loss: 0.0947 - val_loss: 0.0241\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 135us/sample - loss: 0.0930 - val_loss: 0.0239\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.117 - 0s 137us/sample - loss: 0.1098 - val_loss: 0.0237\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 113us/sample - loss: 0.0864 - val_loss: 0.0235\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 114us/sample - loss: 0.0717 - val_loss: 0.0234\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 106us/sample - loss: 0.0938 - val_loss: 0.0231\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 113us/sample - loss: 0.0913 - val_loss: 0.0230\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 115us/sample - loss: 0.0910 - val_loss: 0.0228\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 127us/sample - loss: 0.0820 - val_loss: 0.0226\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 100us/sample - loss: 0.0829 - val_loss: 0.0224\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 118us/sample - loss: 0.0867 - val_loss: 0.0223\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 90us/sample - loss: 0.0835 - val_loss: 0.0220\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 81us/sample - loss: 0.0767 - val_loss: 0.0217\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 83us/sample - loss: 0.0688 - val_loss: 0.0216\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 88us/sample - loss: 0.0796 - val_loss: 0.0214\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 91us/sample - loss: 0.0761 - val_loss: 0.0212\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 92us/sample - loss: 0.0734 - val_loss: 0.0211\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 114us/sample - loss: 0.0703 - val_loss: 0.0210\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 108us/sample - loss: 0.0808 - val_loss: 0.0207\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 115us/sample - loss: 0.0666 - val_loss: 0.0205\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 86us/sample - loss: 0.0725 - val_loss: 0.0203\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 89us/sample - loss: 0.0692 - val_loss: 0.0202\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 92us/sample - loss: 0.0672 - val_loss: 0.0201\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 85us/sample - loss: 0.0693 - val_loss: 0.0200\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 95us/sample - loss: 0.0649 - val_loss: 0.0197\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 90us/sample - loss: 0.0722 - val_loss: 0.0194\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 91us/sample - loss: 0.0729 - val_loss: 0.0192\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0664 - val_loss: 0.0189\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 112us/sample - loss: 0.0652 - val_loss: 0.0187\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 110us/sample - loss: 0.0637 - val_loss: 0.0185\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 104us/sample - loss: 0.0638 - val_loss: 0.0184\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 112us/sample - loss: 0.0605 - val_loss: 0.0182\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 105us/sample - loss: 0.0591 - val_loss: 0.0180\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 103us/sample - loss: 0.0555 - val_loss: 0.0179\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 96us/sample - loss: 0.0516 - val_loss: 0.0178\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 100us/sample - loss: 0.0612 - val_loss: 0.0176\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 2.151 - 0s 757us/sample - loss: 2.3253 - val_loss: 2.3026\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.987 - 0s 115us/sample - loss: 2.2810 - val_loss: 2.1877\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 2.201 - 0s 83us/sample - loss: 2.0861 - val_loss: 2.0834\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 2.309 - 0s 91us/sample - loss: 2.0226 - val_loss: 1.9847\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.695 - 0s 88us/sample - loss: 1.9379 - val_loss: 1.8892\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.869 - 0s 87us/sample - loss: 1.8216 - val_loss: 1.8003\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.921 - 0s 88us/sample - loss: 1.7214 - val_loss: 1.7146\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.913 - 0s 89us/sample - loss: 1.7586 - val_loss: 1.6302\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.958 - 0s 98us/sample - loss: 1.6517 - val_loss: 1.5518\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.867 - 0s 94us/sample - loss: 1.5622 - val_loss: 1.4766\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.452 - 0s 91us/sample - loss: 1.4006 - val_loss: 1.4082\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.419 - 0s 95us/sample - loss: 1.4226 - val_loss: 1.3431\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.329 - 0s 93us/sample - loss: 1.2635 - val_loss: 1.2811\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.140 - 0s 91us/sample - loss: 1.2016 - val_loss: 1.2254\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.947 - 0s 91us/sample - loss: 1.2148 - val_loss: 1.1687\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.193 - 0s 93us/sample - loss: 1.1106 - val_loss: 1.1160\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.808 - 0s 100us/sample - loss: 1.0866 - val_loss: 1.0649\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.823 - 0s 98us/sample - loss: 1.0100 - val_loss: 1.0177\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.230 - 0s 95us/sample - loss: 0.9197 - val_loss: 0.9743\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.875 - 0s 105us/sample - loss: 0.9275 - val_loss: 0.9321\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.896 - 0s 103us/sample - loss: 0.9186 - val_loss: 0.8914\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.891 - 0s 101us/sample - loss: 0.8226 - val_loss: 0.8528\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.891 - 0s 98us/sample - loss: 0.8163 - val_loss: 0.8160\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.920 - 0s 100us/sample - loss: 0.7743 - val_loss: 0.7798\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.599 - 0s 97us/sample - loss: 0.7029 - val_loss: 0.7463\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.786 - 0s 98us/sample - loss: 0.7176 - val_loss: 0.7114\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.732 - 0s 111us/sample - loss: 0.6521 - val_loss: 0.6757\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.526 - 0s 96us/sample - loss: 0.6417 - val_loss: 0.6402\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.758 - 0s 90us/sample - loss: 0.6175 - val_loss: 0.6041\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.629 - 0s 98us/sample - loss: 0.5552 - val_loss: 0.5698\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.511 - 0s 101us/sample - loss: 0.5239 - val_loss: 0.5365\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.524 - 0s 98us/sample - loss: 0.5022 - val_loss: 0.5045\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.518 - 0s 96us/sample - loss: 0.4885 - val_loss: 0.4753\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.330 - 0s 103us/sample - loss: 0.4594 - val_loss: 0.4468\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.394 - 0s 94us/sample - loss: 0.4107 - val_loss: 0.4207\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.304 - 0s 96us/sample - loss: 0.4026 - val_loss: 0.3967\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.499 - 0s 86us/sample - loss: 0.3790 - val_loss: 0.3738\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.308 - 0s 83us/sample - loss: 0.3313 - val_loss: 0.3521\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.237 - 0s 82us/sample - loss: 0.3290 - val_loss: 0.3321\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.368 - 0s 93us/sample - loss: 0.3136 - val_loss: 0.3130\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.418 - 0s 110us/sample - loss: 0.2900 - val_loss: 0.2958\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.227 - 0s 108us/sample - loss: 0.2784 - val_loss: 0.2792\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 100us/sample - loss: 0.2609 - val_loss: 0.2640\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.196 - 0s 102us/sample - loss: 0.2368 - val_loss: 0.2495\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.238 - 0s 115us/sample - loss: 0.2491 - val_loss: 0.2355\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 105us/sample - loss: 0.2222 - val_loss: 0.2231\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.298 - 0s 101us/sample - loss: 0.2121 - val_loss: 0.2109\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 112us/sample - loss: 0.2101 - val_loss: 0.1993\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 102us/sample - loss: 0.1915 - val_loss: 0.1884\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.199 - 0s 96us/sample - loss: 0.1916 - val_loss: 0.1786\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 96us/sample - loss: 0.1815 - val_loss: 0.1689\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.223 - 0s 94us/sample - loss: 0.1611 - val_loss: 0.1603\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.325 - 0s 93us/sample - loss: 0.1609 - val_loss: 0.1517\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 103us/sample - loss: 0.1509 - val_loss: 0.1436\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 105us/sample - loss: 0.1451 - val_loss: 0.1361\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.177 - 0s 100us/sample - loss: 0.1477 - val_loss: 0.1294\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 105us/sample - loss: 0.1381 - val_loss: 0.1229\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 93us/sample - loss: 0.1367 - val_loss: 0.1171\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 115us/sample - loss: 0.1183 - val_loss: 0.1117\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 103us/sample - loss: 0.1254 - val_loss: 0.1066\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 113us/sample - loss: 0.1236 - val_loss: 0.1017\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 105us/sample - loss: 0.1187 - val_loss: 0.0972\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 113us/sample - loss: 0.1146 - val_loss: 0.0926\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 108us/sample - loss: 0.1050 - val_loss: 0.0888\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 122us/sample - loss: 0.1191 - val_loss: 0.0853\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 120us/sample - loss: 0.0957 - val_loss: 0.0819\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 112us/sample - loss: 0.0942 - val_loss: 0.0790\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 108us/sample - loss: 0.1074 - val_loss: 0.0759\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 113us/sample - loss: 0.1109 - val_loss: 0.0730\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 130us/sample - loss: 0.0999 - val_loss: 0.0701\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 125us/sample - loss: 0.0876 - val_loss: 0.0675\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 135us/sample - loss: 0.0848 - val_loss: 0.0653\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 130us/sample - loss: 0.0852 - val_loss: 0.0633\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 120us/sample - loss: 0.0846 - val_loss: 0.0612\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 128us/sample - loss: 0.0830 - val_loss: 0.0593\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 124us/sample - loss: 0.0820 - val_loss: 0.0576\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 118us/sample - loss: 0.0754 - val_loss: 0.0562\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 110us/sample - loss: 0.0759 - val_loss: 0.0548\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 110us/sample - loss: 0.0736 - val_loss: 0.0534\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 110us/sample - loss: 0.0751 - val_loss: 0.0521\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 113us/sample - loss: 0.0761 - val_loss: 0.0507\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 118us/sample - loss: 0.0724 - val_loss: 0.0494\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 113us/sample - loss: 0.0700 - val_loss: 0.0482\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 123us/sample - loss: 0.0694 - val_loss: 0.0470\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 110us/sample - loss: 0.0715 - val_loss: 0.0459\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 105us/sample - loss: 0.0693 - val_loss: 0.0449\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 115us/sample - loss: 0.0677 - val_loss: 0.0439\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 115us/sample - loss: 0.0557 - val_loss: 0.0430\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 120us/sample - loss: 0.0686 - val_loss: 0.0421\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 113us/sample - loss: 0.0641 - val_loss: 0.0415\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 120us/sample - loss: 0.0610 - val_loss: 0.0407\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 110us/sample - loss: 0.0640 - val_loss: 0.0399\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 117us/sample - loss: 0.0697 - val_loss: 0.0393\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 110us/sample - loss: 0.0743 - val_loss: 0.0387\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 118us/sample - loss: 0.0589 - val_loss: 0.0381\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 127us/sample - loss: 0.0579 - val_loss: 0.0376\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 123us/sample - loss: 0.0628 - val_loss: 0.0371\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 133us/sample - loss: 0.0615 - val_loss: 0.0366\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 119us/sample - loss: 0.0644 - val_loss: 0.0360\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 119us/sample - loss: 0.0561 - val_loss: 0.0356\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 125us/sample - loss: 0.0587 - val_loss: 0.0352\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 125us/sample - loss: 0.0608 - val_loss: 0.0348\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 120us/sample - loss: 0.0601 - val_loss: 0.0345\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 123us/sample - loss: 0.0646 - val_loss: 0.0343\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 127us/sample - loss: 0.0546 - val_loss: 0.0340\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 125us/sample - loss: 0.0561 - val_loss: 0.0336\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 130us/sample - loss: 0.0504 - val_loss: 0.0334\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 132us/sample - loss: 0.0511 - val_loss: 0.0332\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 127us/sample - loss: 0.0541 - val_loss: 0.0329\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 125us/sample - loss: 0.0527 - val_loss: 0.0326\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 127us/sample - loss: 0.0577 - val_loss: 0.0324\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 130us/sample - loss: 0.0530 - val_loss: 0.0319\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 127us/sample - loss: 0.0500 - val_loss: 0.0315\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.0454 - val_loss: 0.0312\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 103us/sample - loss: 0.0530 - val_loss: 0.0309\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 102us/sample - loss: 0.0571 - val_loss: 0.0306\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.0523 - val_loss: 0.0303\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 105us/sample - loss: 0.0465 - val_loss: 0.0300\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 100us/sample - loss: 0.0453 - val_loss: 0.0298\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 96us/sample - loss: 0.0464 - val_loss: 0.0297\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 103us/sample - loss: 0.0430 - val_loss: 0.0295\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 130us/sample - loss: 0.0452 - val_loss: 0.0292\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0407 - val_loss: 0.0290\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 99us/sample - loss: 0.0404 - val_loss: 0.0287\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 100us/sample - loss: 0.0460 - val_loss: 0.0286\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 98us/sample - loss: 0.0452 - val_loss: 0.0283\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0455 - val_loss: 0.0281\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0445 - val_loss: 0.0278\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 99us/sample - loss: 0.0415 - val_loss: 0.0276\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 99us/sample - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 105us/sample - loss: 0.0429 - val_loss: 0.0271\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 105us/sample - loss: 0.0442 - val_loss: 0.0268\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 108us/sample - loss: 0.0404 - val_loss: 0.0266\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 110us/sample - loss: 0.0396 - val_loss: 0.0264\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 164us/sample - loss: 0.0395 - val_loss: 0.0263\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 115us/sample - loss: 0.0394 - val_loss: 0.0261\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 122us/sample - loss: 0.0395 - val_loss: 0.0259\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 120us/sample - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 130us/sample - loss: 0.0382 - val_loss: 0.0255\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 116us/sample - loss: 0.0364 - val_loss: 0.0255\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 113us/sample - loss: 0.0369 - val_loss: 0.0253\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 119us/sample - loss: 0.0390 - val_loss: 0.0251\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 133us/sample - loss: 0.0386 - val_loss: 0.0249\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 127us/sample - loss: 0.0350 - val_loss: 0.0248\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 120us/sample - loss: 0.0363 - val_loss: 0.0246\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 130us/sample - loss: 0.0321 - val_loss: 0.0244\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 132us/sample - loss: 0.0377 - val_loss: 0.0242\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 115us/sample - loss: 0.0319 - val_loss: 0.0240\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 110us/sample - loss: 0.0369 - val_loss: 0.0240\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 115us/sample - loss: 0.0341 - val_loss: 0.0238\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 1.063 - 0s 809us/sample - loss: 0.9034 - val_loss: 0.8830\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.995 - 0s 113us/sample - loss: 0.8600 - val_loss: 0.8461\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.815 - 0s 118us/sample - loss: 0.8210 - val_loss: 0.8104\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.801 - 0s 110us/sample - loss: 0.7883 - val_loss: 0.7766\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.681 - 0s 116us/sample - loss: 0.7280 - val_loss: 0.7450\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.696 - 0s 113us/sample - loss: 0.6868 - val_loss: 0.7145\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.746 - 0s 120us/sample - loss: 0.6705 - val_loss: 0.6859\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.516 - 0s 110us/sample - loss: 0.6170 - val_loss: 0.6584\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.607 - 0s 130us/sample - loss: 0.6227 - val_loss: 0.6313\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.546 - 0s 123us/sample - loss: 0.5490 - val_loss: 0.6067\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.592 - 0s 115us/sample - loss: 0.5265 - val_loss: 0.5837\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.538 - 0s 123us/sample - loss: 0.5103 - val_loss: 0.5614\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.438 - 0s 127us/sample - loss: 0.5007 - val_loss: 0.5397\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.521 - 0s 127us/sample - loss: 0.5049 - val_loss: 0.5178\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.403 - 0s 123us/sample - loss: 0.4715 - val_loss: 0.4969\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.370 - 0s 118us/sample - loss: 0.4504 - val_loss: 0.4775\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.444 - 0s 115us/sample - loss: 0.4494 - val_loss: 0.4581\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.439 - 0s 115us/sample - loss: 0.3955 - val_loss: 0.4400\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.442 - 0s 110us/sample - loss: 0.3875 - val_loss: 0.4229\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.376 - 0s 105us/sample - loss: 0.3806 - val_loss: 0.4064\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.404 - 0s 108us/sample - loss: 0.3545 - val_loss: 0.3905\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.389 - 0s 123us/sample - loss: 0.3583 - val_loss: 0.3754\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.264 - 0s 118us/sample - loss: 0.3468 - val_loss: 0.3607\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.255 - 0s 120us/sample - loss: 0.3238 - val_loss: 0.3466\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.286 - 0s 108us/sample - loss: 0.3003 - val_loss: 0.3339\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.301 - 0s 103us/sample - loss: 0.3010 - val_loss: 0.3217\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.465 - 0s 113us/sample - loss: 0.2831 - val_loss: 0.3100\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.323 - 0s 110us/sample - loss: 0.2687 - val_loss: 0.2987\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.253 - 0s 103us/sample - loss: 0.2716 - val_loss: 0.2878\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.262 - 0s 105us/sample - loss: 0.2535 - val_loss: 0.2777\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.268 - 0s 115us/sample - loss: 0.2442 - val_loss: 0.2675\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.224 - 0s 109us/sample - loss: 0.2330 - val_loss: 0.2580\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.173 - 0s 110us/sample - loss: 0.2247 - val_loss: 0.2492\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.238 - 0s 119us/sample - loss: 0.2234 - val_loss: 0.2404\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.210 - 0s 114us/sample - loss: 0.1956 - val_loss: 0.2324\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 111us/sample - loss: 0.2014 - val_loss: 0.2244\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 108us/sample - loss: 0.1977 - val_loss: 0.2167\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.202 - 0s 118us/sample - loss: 0.1937 - val_loss: 0.2094\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.213 - 0s 127us/sample - loss: 0.1849 - val_loss: 0.2023\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.150 - 0s 127us/sample - loss: 0.1755 - val_loss: 0.1959\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 118us/sample - loss: 0.1682 - val_loss: 0.1896\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 118us/sample - loss: 0.1608 - val_loss: 0.1833\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 129us/sample - loss: 0.1619 - val_loss: 0.1776\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 118us/sample - loss: 0.1477 - val_loss: 0.1720\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.168 - 0s 123us/sample - loss: 0.1477 - val_loss: 0.1668\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 130us/sample - loss: 0.1408 - val_loss: 0.1619\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 120us/sample - loss: 0.1369 - val_loss: 0.1570\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 123us/sample - loss: 0.1283 - val_loss: 0.1524\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.297 - 0s 115us/sample - loss: 0.1326 - val_loss: 0.1479\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 113us/sample - loss: 0.1217 - val_loss: 0.1438\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 124us/sample - loss: 0.1203 - val_loss: 0.1398\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 127us/sample - loss: 0.1156 - val_loss: 0.1359\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 113us/sample - loss: 0.1160 - val_loss: 0.1321\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 118us/sample - loss: 0.1066 - val_loss: 0.1286\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 115us/sample - loss: 0.1041 - val_loss: 0.1254\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 118us/sample - loss: 0.1070 - val_loss: 0.1222\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 130us/sample - loss: 0.0955 - val_loss: 0.1191\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 120us/sample - loss: 0.0949 - val_loss: 0.1161\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 118us/sample - loss: 0.0914 - val_loss: 0.1134\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 108us/sample - loss: 0.0912 - val_loss: 0.1107\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 110us/sample - loss: 0.0941 - val_loss: 0.1077\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 105us/sample - loss: 0.0893 - val_loss: 0.1051\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 98us/sample - loss: 0.0837 - val_loss: 0.1025\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 98us/sample - loss: 0.0837 - val_loss: 0.1000\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 100us/sample - loss: 0.0819 - val_loss: 0.0977\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 113us/sample - loss: 0.0788 - val_loss: 0.0955\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 132us/sample - loss: 0.0813 - val_loss: 0.0932\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 123us/sample - loss: 0.0733 - val_loss: 0.0911\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 118us/sample - loss: 0.0787 - val_loss: 0.0890\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 120us/sample - loss: 0.0701 - val_loss: 0.0870\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 132us/sample - loss: 0.0695 - val_loss: 0.0851\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 125us/sample - loss: 0.0668 - val_loss: 0.0834\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 128us/sample - loss: 0.0660 - val_loss: 0.0816\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 123us/sample - loss: 0.0662 - val_loss: 0.0798\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 140us/sample - loss: 0.0643 - val_loss: 0.0781\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 137us/sample - loss: 0.0617 - val_loss: 0.0765\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 136us/sample - loss: 0.0614 - val_loss: 0.0750\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 130us/sample - loss: 0.0609 - val_loss: 0.0735\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 135us/sample - loss: 0.0617 - val_loss: 0.0719\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 135us/sample - loss: 0.0549 - val_loss: 0.0705\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 140us/sample - loss: 0.0554 - val_loss: 0.0692\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 139us/sample - loss: 0.0539 - val_loss: 0.0679\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 132us/sample - loss: 0.0550 - val_loss: 0.0665\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 136us/sample - loss: 0.0521 - val_loss: 0.0653\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 137us/sample - loss: 0.0534 - val_loss: 0.0640\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 142us/sample - loss: 0.0514 - val_loss: 0.0628\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 127us/sample - loss: 0.0505 - val_loss: 0.0616\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 140us/sample - loss: 0.0495 - val_loss: 0.0605\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 142us/sample - loss: 0.0502 - val_loss: 0.0594\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 132us/sample - loss: 0.0455 - val_loss: 0.0584\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 129us/sample - loss: 0.0474 - val_loss: 0.0574\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 123us/sample - loss: 0.0467 - val_loss: 0.0563\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 122us/sample - loss: 0.0458 - val_loss: 0.0553\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 121us/sample - loss: 0.0460 - val_loss: 0.0542\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 120us/sample - loss: 0.0434 - val_loss: 0.0533\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 120us/sample - loss: 0.0435 - val_loss: 0.0524\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 113us/sample - loss: 0.0416 - val_loss: 0.0515\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0437 - val_loss: 0.0506\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 118us/sample - loss: 0.0404 - val_loss: 0.0498\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 118us/sample - loss: 0.0391 - val_loss: 0.0489\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 109us/sample - loss: 0.0400 - val_loss: 0.0481\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 101us/sample - loss: 0.0380 - val_loss: 0.0473\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0363 - val_loss: 0.0466\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 103us/sample - loss: 0.0365 - val_loss: 0.0458\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 107us/sample - loss: 0.0391 - val_loss: 0.0450\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 103us/sample - loss: 0.0358 - val_loss: 0.0443\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 105us/sample - loss: 0.0344 - val_loss: 0.0436\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 105us/sample - loss: 0.0363 - val_loss: 0.0429\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0330 - val_loss: 0.0422\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0345 - val_loss: 0.0415\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 110us/sample - loss: 0.0342 - val_loss: 0.0409\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 118us/sample - loss: 0.0321 - val_loss: 0.0402\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 127us/sample - loss: 0.0310 - val_loss: 0.0396\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 120us/sample - loss: 0.0313 - val_loss: 0.0390\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 115us/sample - loss: 0.0310 - val_loss: 0.0384\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 113us/sample - loss: 0.0288 - val_loss: 0.0378\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 127us/sample - loss: 0.0299 - val_loss: 0.0372\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 113us/sample - loss: 0.0281 - val_loss: 0.0366\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 114us/sample - loss: 0.0297 - val_loss: 0.0361\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 110us/sample - loss: 0.0282 - val_loss: 0.0355\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 120us/sample - loss: 0.0273 - val_loss: 0.0350\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 135us/sample - loss: 0.0288 - val_loss: 0.0344\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 127us/sample - loss: 0.0279 - val_loss: 0.0339\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 123us/sample - loss: 0.0277 - val_loss: 0.0333\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 115us/sample - loss: 0.0254 - val_loss: 0.0328\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 125us/sample - loss: 0.0241 - val_loss: 0.0324\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 120us/sample - loss: 0.0253 - val_loss: 0.0319\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 119us/sample - loss: 0.0245 - val_loss: 0.0315\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 127us/sample - loss: 0.0242 - val_loss: 0.0310\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 101us/sample - loss: 0.0248 - val_loss: 0.0306\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 113us/sample - loss: 0.0228 - val_loss: 0.0302\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0243 - val_loss: 0.0297\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 103us/sample - loss: 0.0233 - val_loss: 0.0293\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 115us/sample - loss: 0.0230 - val_loss: 0.0289\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0234 - val_loss: 0.0285\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0232 - val_loss: 0.0280\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 154us/sample - loss: 0.0229 - val_loss: 0.0276\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0216 - val_loss: 0.0272\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0214 - val_loss: 0.0268\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0210 - val_loss: 0.0264\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 103us/sample - loss: 0.0214 - val_loss: 0.0260\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0207 - val_loss: 0.0256\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 106us/sample - loss: 0.0203 - val_loss: 0.0253\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 105us/sample - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0184 - val_loss: 0.0246\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 105us/sample - loss: 0.0188 - val_loss: 0.0243\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 110us/sample - loss: 0.0183 - val_loss: 0.0240\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 108us/sample - loss: 0.0195 - val_loss: 0.0236\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0193 - val_loss: 0.0233\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0188 - val_loss: 0.0229\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.138 - 0s 880us/sample - loss: 0.1877 - val_loss: 0.0240\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.245 - 0s 140us/sample - loss: 0.2111 - val_loss: 0.0238\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 127us/sample - loss: 0.1813 - val_loss: 0.0237\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.188 - 0s 127us/sample - loss: 0.1740 - val_loss: 0.0235\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 108us/sample - loss: 0.1574 - val_loss: 0.0233\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 93us/sample - loss: 0.1685 - val_loss: 0.0232\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 93us/sample - loss: 0.1524 - val_loss: 0.0229\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 96us/sample - loss: 0.1657 - val_loss: 0.0231\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 88us/sample - loss: 0.1566 - val_loss: 0.0228\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 93us/sample - loss: 0.1483 - val_loss: 0.0226\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 101us/sample - loss: 0.1608 - val_loss: 0.0224\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.171 - 0s 104us/sample - loss: 0.1564 - val_loss: 0.0222\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 96us/sample - loss: 0.1234 - val_loss: 0.0220\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 86us/sample - loss: 0.1101 - val_loss: 0.0221\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.128 - 0s 89us/sample - loss: 0.1268 - val_loss: 0.0221\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 87us/sample - loss: 0.1237 - val_loss: 0.0219\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 95us/sample - loss: 0.1214 - val_loss: 0.0215\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.178 - 0s 108us/sample - loss: 0.1172 - val_loss: 0.0213\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.112 - 0s 123us/sample - loss: 0.1267 - val_loss: 0.0205\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 132us/sample - loss: 0.1063 - val_loss: 0.0203\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 135us/sample - loss: 0.1038 - val_loss: 0.0201\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 142us/sample - loss: 0.0978 - val_loss: 0.0200\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 130us/sample - loss: 0.0958 - val_loss: 0.0196\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 130us/sample - loss: 0.1005 - val_loss: 0.0193\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 125us/sample - loss: 0.1008 - val_loss: 0.0191\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 132us/sample - loss: 0.0964 - val_loss: 0.0187\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 123us/sample - loss: 0.0970 - val_loss: 0.0185\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 123us/sample - loss: 0.0854 - val_loss: 0.0181\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 124us/sample - loss: 0.0864 - val_loss: 0.0178\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 123us/sample - loss: 0.0801 - val_loss: 0.0178\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 130us/sample - loss: 0.0802 - val_loss: 0.0176\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 125us/sample - loss: 0.0769 - val_loss: 0.0175\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 130us/sample - loss: 0.0764 - val_loss: 0.0174\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 128us/sample - loss: 0.0758 - val_loss: 0.0172\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 127us/sample - loss: 0.0770 - val_loss: 0.0170\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 110us/sample - loss: 0.0594 - val_loss: 0.0170\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 108us/sample - loss: 0.0681 - val_loss: 0.0169\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 117us/sample - loss: 0.0643 - val_loss: 0.0167\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 105us/sample - loss: 0.0689 - val_loss: 0.0166\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 118us/sample - loss: 0.0620 - val_loss: 0.0165\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 123us/sample - loss: 0.0569 - val_loss: 0.0163\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 105us/sample - loss: 0.0530 - val_loss: 0.0164\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0584 - val_loss: 0.0163\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 105us/sample - loss: 0.0540 - val_loss: 0.0161\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 110us/sample - loss: 0.0532 - val_loss: 0.0160\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 104us/sample - loss: 0.0560 - val_loss: 0.0160\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 115us/sample - loss: 0.0513 - val_loss: 0.0160\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 100us/sample - loss: 0.0548 - val_loss: 0.0160\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 105us/sample - loss: 0.0430 - val_loss: 0.0158\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 100us/sample - loss: 0.0496 - val_loss: 0.0157\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 103us/sample - loss: 0.0471 - val_loss: 0.0157\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 103us/sample - loss: 0.0492 - val_loss: 0.0156\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 101us/sample - loss: 0.0515 - val_loss: 0.0155\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 103us/sample - loss: 0.0487 - val_loss: 0.0154\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 115us/sample - loss: 0.0487 - val_loss: 0.0153\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 113us/sample - loss: 0.0451 - val_loss: 0.0152\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 125us/sample - loss: 0.0437 - val_loss: 0.0152\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 118us/sample - loss: 0.0420 - val_loss: 0.0150\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 110us/sample - loss: 0.0383 - val_loss: 0.0149\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 111us/sample - loss: 0.0367 - val_loss: 0.0149\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 127us/sample - loss: 0.0426 - val_loss: 0.0149\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 115us/sample - loss: 0.0372 - val_loss: 0.0150\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 107us/sample - loss: 0.0403 - val_loss: 0.0150\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 140us/sample - loss: 0.0368 - val_loss: 0.0149\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 120us/sample - loss: 0.0382 - val_loss: 0.0148\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 125us/sample - loss: 0.0357 - val_loss: 0.0146\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 115us/sample - loss: 0.0363 - val_loss: 0.0146\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 123us/sample - loss: 0.0360 - val_loss: 0.0146\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 125us/sample - loss: 0.0336 - val_loss: 0.0146\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 110us/sample - loss: 0.0325 - val_loss: 0.0145\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 108us/sample - loss: 0.0345 - val_loss: 0.0143\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 105us/sample - loss: 0.0319 - val_loss: 0.0142\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 106us/sample - loss: 0.0325 - val_loss: 0.0140\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0303 - val_loss: 0.0139\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 92us/sample - loss: 0.0297 - val_loss: 0.0137\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 94us/sample - loss: 0.0307 - val_loss: 0.0137\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0302 - val_loss: 0.0135\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 96us/sample - loss: 0.0266 - val_loss: 0.0134\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0267 - val_loss: 0.0134\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0295 - val_loss: 0.0133\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0277 - val_loss: 0.0132\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 91us/sample - loss: 0.0279 - val_loss: 0.0130\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0273 - val_loss: 0.0129\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0273 - val_loss: 0.0128\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0279 - val_loss: 0.0127\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0242 - val_loss: 0.0128\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 96us/sample - loss: 0.0230 - val_loss: 0.0127\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0226 - val_loss: 0.0126\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 94us/sample - loss: 0.0237 - val_loss: 0.0125\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0248 - val_loss: 0.0126\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 92us/sample - loss: 0.0222 - val_loss: 0.0126\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 91us/sample - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0204 - val_loss: 0.0123\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0220 - val_loss: 0.0121\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0204 - val_loss: 0.0120\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0213 - val_loss: 0.0119\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0206 - val_loss: 0.0119\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0201 - val_loss: 0.0118\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 115us/sample - loss: 0.0206 - val_loss: 0.0116\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 118us/sample - loss: 0.0193 - val_loss: 0.0116\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 118us/sample - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 118us/sample - loss: 0.0207 - val_loss: 0.0114\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 116us/sample - loss: 0.0175 - val_loss: 0.0114\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 125us/sample - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0189 - val_loss: 0.0113\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 112us/sample - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0182 - val_loss: 0.0110\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0168 - val_loss: 0.0110\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 89us/sample - loss: 0.0180 - val_loss: 0.0109\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 99us/sample - loss: 0.0169 - val_loss: 0.0107\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0105\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 89us/sample - loss: 0.0170 - val_loss: 0.0105\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0162 - val_loss: 0.0105\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0167 - val_loss: 0.0104\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 104us/sample - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 109us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 113us/sample - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 109us/sample - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0124 - val_loss: 0.0095\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.825 - 0s 733us/sample - loss: 0.6479 - val_loss: 0.3623\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.609 - 0s 105us/sample - loss: 0.6088 - val_loss: 0.3303\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.619 - 0s 96us/sample - loss: 0.5552 - val_loss: 0.3007\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.433 - 0s 91us/sample - loss: 0.5213 - val_loss: 0.2740\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.474 - 0s 98us/sample - loss: 0.4838 - val_loss: 0.2495\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.530 - 0s 93us/sample - loss: 0.4627 - val_loss: 0.2272\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.590 - 0s 93us/sample - loss: 0.4155 - val_loss: 0.2076\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.325 - 0s 97us/sample - loss: 0.3953 - val_loss: 0.1886\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.460 - 0s 96us/sample - loss: 0.3465 - val_loss: 0.1716\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.321 - 0s 101us/sample - loss: 0.3409 - val_loss: 0.1566\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.356 - 0s 103us/sample - loss: 0.3301 - val_loss: 0.1424\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.311 - 0s 118us/sample - loss: 0.2737 - val_loss: 0.1302\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.224 - 0s 123us/sample - loss: 0.2849 - val_loss: 0.1190\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.353 - 0s 108us/sample - loss: 0.2519 - val_loss: 0.1083\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.339 - 0s 107us/sample - loss: 0.2500 - val_loss: 0.0989\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.250 - 0s 110us/sample - loss: 0.2405 - val_loss: 0.0900\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.195 - 0s 105us/sample - loss: 0.2207 - val_loss: 0.0819\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 122us/sample - loss: 0.1888 - val_loss: 0.0750\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.176 - 0s 117us/sample - loss: 0.1766 - val_loss: 0.0690\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.177 - 0s 108us/sample - loss: 0.1846 - val_loss: 0.0631\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 111us/sample - loss: 0.1592 - val_loss: 0.0577\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 115us/sample - loss: 0.1508 - val_loss: 0.0530\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 110us/sample - loss: 0.1427 - val_loss: 0.0491\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 108us/sample - loss: 0.1358 - val_loss: 0.0454\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 108us/sample - loss: 0.1276 - val_loss: 0.0421\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 110us/sample - loss: 0.1323 - val_loss: 0.0388\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 115us/sample - loss: 0.1178 - val_loss: 0.0361\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 113us/sample - loss: 0.1096 - val_loss: 0.0335\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 96us/sample - loss: 0.1135 - val_loss: 0.0313\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.127 - 0s 110us/sample - loss: 0.1044 - val_loss: 0.0293\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 100us/sample - loss: 0.0961 - val_loss: 0.0274\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 98us/sample - loss: 0.0880 - val_loss: 0.0260\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 100us/sample - loss: 0.0919 - val_loss: 0.0245\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.150 - 0s 98us/sample - loss: 0.0906 - val_loss: 0.0232\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 108us/sample - loss: 0.0881 - val_loss: 0.0221\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 103us/sample - loss: 0.0828 - val_loss: 0.0210\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 100us/sample - loss: 0.0803 - val_loss: 0.0202\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 100us/sample - loss: 0.0705 - val_loss: 0.0195\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 103us/sample - loss: 0.0757 - val_loss: 0.0189\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 99us/sample - loss: 0.0690 - val_loss: 0.0184\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 97us/sample - loss: 0.0713 - val_loss: 0.0180\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 100us/sample - loss: 0.0673 - val_loss: 0.0177\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.0636 - val_loss: 0.0175\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 100us/sample - loss: 0.0637 - val_loss: 0.0173\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 116us/sample - loss: 0.0595 - val_loss: 0.0171\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 115us/sample - loss: 0.0613 - val_loss: 0.0170\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 118us/sample - loss: 0.0603 - val_loss: 0.0170\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 120us/sample - loss: 0.0576 - val_loss: 0.0170\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 130us/sample - loss: 0.0600 - val_loss: 0.0170\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 137us/sample - loss: 0.0572 - val_loss: 0.0171\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 133us/sample - loss: 0.0547 - val_loss: 0.0172\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 130us/sample - loss: 0.0539 - val_loss: 0.0173\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 130us/sample - loss: 0.0498 - val_loss: 0.0174\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 125us/sample - loss: 0.0534 - val_loss: 0.0176\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 118us/sample - loss: 0.0524 - val_loss: 0.0177\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 130us/sample - loss: 0.0493 - val_loss: 0.0179\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 127us/sample - loss: 0.0504 - val_loss: 0.0181\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 130us/sample - loss: 0.0514 - val_loss: 0.0183\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 125us/sample - loss: 0.0518 - val_loss: 0.0185\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 125us/sample - loss: 0.0508 - val_loss: 0.0186\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 130us/sample - loss: 0.0494 - val_loss: 0.0188\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 125us/sample - loss: 0.0505 - val_loss: 0.0190\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 127us/sample - loss: 0.0482 - val_loss: 0.0192\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 130us/sample - loss: 0.0450 - val_loss: 0.0193\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 132us/sample - loss: 0.0462 - val_loss: 0.0195\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 130us/sample - loss: 0.0484 - val_loss: 0.0197\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 120us/sample - loss: 0.0451 - val_loss: 0.0198\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 110us/sample - loss: 0.0504 - val_loss: 0.0200\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 110us/sample - loss: 0.0435 - val_loss: 0.0201\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 113us/sample - loss: 0.0473 - val_loss: 0.0202\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 110us/sample - loss: 0.0467 - val_loss: 0.0204\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 113us/sample - loss: 0.0462 - val_loss: 0.0206\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 128us/sample - loss: 0.0428 - val_loss: 0.0207\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 115us/sample - loss: 0.0450 - val_loss: 0.0208\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 118us/sample - loss: 0.0462 - val_loss: 0.0210\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 96us/sample - loss: 0.0431 - val_loss: 0.0211\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 109us/sample - loss: 0.0448 - val_loss: 0.0211\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 1.930 - 0s 872us/sample - loss: 2.1112 - val_loss: 1.8188\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 2.490 - 0s 107us/sample - loss: 1.9775 - val_loss: 1.7400\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.963 - 0s 122us/sample - loss: 1.9475 - val_loss: 1.6638\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.331 - 0s 103us/sample - loss: 1.7727 - val_loss: 1.5908\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.960 - 0s 98us/sample - loss: 1.7578 - val_loss: 1.5193\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 2.145 - 0s 127us/sample - loss: 1.7650 - val_loss: 1.4495\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.926 - 0s 122us/sample - loss: 1.7031 - val_loss: 1.3810\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.415 - 0s 103us/sample - loss: 1.6523 - val_loss: 1.3140\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.581 - 0s 88us/sample - loss: 1.4994 - val_loss: 1.2515\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.585 - 0s 98us/sample - loss: 1.4265 - val_loss: 1.1918\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.383 - 0s 92us/sample - loss: 1.3817 - val_loss: 1.1362\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.462 - 0s 97us/sample - loss: 1.2618 - val_loss: 1.0824\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.118 - 0s 100us/sample - loss: 1.2159 - val_loss: 1.0304\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.145 - 0s 101us/sample - loss: 1.2158 - val_loss: 0.9795\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.041 - 0s 90us/sample - loss: 1.0986 - val_loss: 0.9320\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.052 - 0s 93us/sample - loss: 1.0660 - val_loss: 0.8848\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.895 - 0s 105us/sample - loss: 1.0231 - val_loss: 0.8414\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.867 - 0s 96us/sample - loss: 1.0059 - val_loss: 0.7982\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.894 - 0s 93us/sample - loss: 0.9905 - val_loss: 0.7543\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.065 - 0s 91us/sample - loss: 0.8829 - val_loss: 0.7135\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.988 - 0s 99us/sample - loss: 0.8588 - val_loss: 0.6758\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.835 - 0s 96us/sample - loss: 0.7750 - val_loss: 0.6397\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.780 - 0s 88us/sample - loss: 0.7518 - val_loss: 0.6051\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.616 - 0s 98us/sample - loss: 0.7367 - val_loss: 0.5713\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.706 - 0s 99us/sample - loss: 0.7294 - val_loss: 0.5379\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.531 - 0s 113us/sample - loss: 0.6590 - val_loss: 0.5065\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.641 - 0s 108us/sample - loss: 0.6416 - val_loss: 0.4759\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.674 - 0s 120us/sample - loss: 0.6166 - val_loss: 0.4464\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.572 - 0s 101us/sample - loss: 0.5655 - val_loss: 0.4183\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.667 - 0s 113us/sample - loss: 0.5408 - val_loss: 0.3925\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.782 - 0s 108us/sample - loss: 0.5278 - val_loss: 0.3677\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.538 - 0s 111us/sample - loss: 0.5072 - val_loss: 0.3436\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.450 - 0s 110us/sample - loss: 0.4671 - val_loss: 0.3205\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.447 - 0s 111us/sample - loss: 0.4355 - val_loss: 0.2993\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.480 - 0s 115us/sample - loss: 0.4343 - val_loss: 0.2788\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.370 - 0s 110us/sample - loss: 0.4041 - val_loss: 0.2596\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.336 - 0s 108us/sample - loss: 0.3833 - val_loss: 0.2422\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.304 - 0s 113us/sample - loss: 0.3444 - val_loss: 0.2257\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.289 - 0s 118us/sample - loss: 0.3344 - val_loss: 0.2100\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.330 - 0s 116us/sample - loss: 0.3121 - val_loss: 0.1951\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.340 - 0s 118us/sample - loss: 0.2940 - val_loss: 0.1810\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.243 - 0s 122us/sample - loss: 0.2890 - val_loss: 0.1685\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.402 - 0s 118us/sample - loss: 0.2745 - val_loss: 0.1563\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.270 - 0s 110us/sample - loss: 0.2349 - val_loss: 0.1464\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.254 - 0s 110us/sample - loss: 0.2510 - val_loss: 0.1363\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.172 - 0s 105us/sample - loss: 0.2406 - val_loss: 0.1269\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.226 - 0s 104us/sample - loss: 0.2203 - val_loss: 0.1185\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 96us/sample - loss: 0.2022 - val_loss: 0.1109\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.312 - 0s 93us/sample - loss: 0.2013 - val_loss: 0.1041\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 105us/sample - loss: 0.1850 - val_loss: 0.0978\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 120us/sample - loss: 0.1832 - val_loss: 0.0925\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 109us/sample - loss: 0.1744 - val_loss: 0.0871\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.216 - 0s 105us/sample - loss: 0.1769 - val_loss: 0.0823\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 142us/sample - loss: 0.1604 - val_loss: 0.0778\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 125us/sample - loss: 0.1424 - val_loss: 0.0738\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 110us/sample - loss: 0.1433 - val_loss: 0.0704\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 108us/sample - loss: 0.1494 - val_loss: 0.0674\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 113us/sample - loss: 0.1557 - val_loss: 0.0644\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 93us/sample - loss: 0.1361 - val_loss: 0.0617\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 101us/sample - loss: 0.1174 - val_loss: 0.0595\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 103us/sample - loss: 0.1321 - val_loss: 0.0574\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 105us/sample - loss: 0.1236 - val_loss: 0.0556\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 106us/sample - loss: 0.1217 - val_loss: 0.0540\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 113us/sample - loss: 0.1138 - val_loss: 0.0526\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 120us/sample - loss: 0.1132 - val_loss: 0.0513\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 111us/sample - loss: 0.1107 - val_loss: 0.0501\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 120us/sample - loss: 0.1128 - val_loss: 0.0489\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.127 - 0s 130us/sample - loss: 0.1155 - val_loss: 0.0480\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 125us/sample - loss: 0.1066 - val_loss: 0.0471\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 125us/sample - loss: 0.1042 - val_loss: 0.0463\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 123us/sample - loss: 0.1012 - val_loss: 0.0456\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 130us/sample - loss: 0.0966 - val_loss: 0.0450\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 108us/sample - loss: 0.1051 - val_loss: 0.0444\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 113us/sample - loss: 0.0954 - val_loss: 0.0439\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 113us/sample - loss: 0.0952 - val_loss: 0.0434\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 116us/sample - loss: 0.0928 - val_loss: 0.0429\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 106us/sample - loss: 0.0953 - val_loss: 0.0425\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 120us/sample - loss: 0.0923 - val_loss: 0.0421\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 118us/sample - loss: 0.0958 - val_loss: 0.0417\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 108us/sample - loss: 0.0873 - val_loss: 0.0413\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 101us/sample - loss: 0.0876 - val_loss: 0.0409\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.115 - 0s 103us/sample - loss: 0.0813 - val_loss: 0.0406\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 91us/sample - loss: 0.0975 - val_loss: 0.0402\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 88us/sample - loss: 0.0865 - val_loss: 0.0399\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 85us/sample - loss: 0.0816 - val_loss: 0.0395\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 91us/sample - loss: 0.0898 - val_loss: 0.0392\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 81us/sample - loss: 0.0858 - val_loss: 0.0388\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 81us/sample - loss: 0.0842 - val_loss: 0.0384\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.112 - 0s 92us/sample - loss: 0.0853 - val_loss: 0.0381\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 89us/sample - loss: 0.0745 - val_loss: 0.0378\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 92us/sample - loss: 0.0777 - val_loss: 0.0375\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 87us/sample - loss: 0.0727 - val_loss: 0.0372\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 95us/sample - loss: 0.0797 - val_loss: 0.0369\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 91us/sample - loss: 0.0728 - val_loss: 0.0366\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 91us/sample - loss: 0.0788 - val_loss: 0.0363\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.115 - 0s 101us/sample - loss: 0.0743 - val_loss: 0.0360\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 86us/sample - loss: 0.0736 - val_loss: 0.0357\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 93us/sample - loss: 0.0715 - val_loss: 0.0354\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 98us/sample - loss: 0.0671 - val_loss: 0.0351\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 87us/sample - loss: 0.0644 - val_loss: 0.0348\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 94us/sample - loss: 0.0703 - val_loss: 0.0345\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 89us/sample - loss: 0.0724 - val_loss: 0.0343\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0671 - val_loss: 0.0340\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 90us/sample - loss: 0.0633 - val_loss: 0.0338\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 93us/sample - loss: 0.0648 - val_loss: 0.0335\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 99us/sample - loss: 0.0671 - val_loss: 0.0332\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 123us/sample - loss: 0.0695 - val_loss: 0.0328\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 110us/sample - loss: 0.0702 - val_loss: 0.0326\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 110us/sample - loss: 0.0612 - val_loss: 0.0323\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 94us/sample - loss: 0.0591 - val_loss: 0.0320\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 101us/sample - loss: 0.0581 - val_loss: 0.0318\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 96us/sample - loss: 0.0588 - val_loss: 0.0315\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 88us/sample - loss: 0.0629 - val_loss: 0.0312\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 143us/sample - loss: 0.0598 - val_loss: 0.0309\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 113us/sample - loss: 0.0558 - val_loss: 0.0307\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 101us/sample - loss: 0.0563 - val_loss: 0.0304\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0576 - val_loss: 0.0301\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0550 - val_loss: 0.0299\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 91us/sample - loss: 0.0573 - val_loss: 0.0296\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 98us/sample - loss: 0.0553 - val_loss: 0.0293\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 96us/sample - loss: 0.0534 - val_loss: 0.0291\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 90us/sample - loss: 0.0530 - val_loss: 0.0288\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 100us/sample - loss: 0.0545 - val_loss: 0.0286\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 103us/sample - loss: 0.0499 - val_loss: 0.0284\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 119us/sample - loss: 0.0525 - val_loss: 0.0282\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 96us/sample - loss: 0.0524 - val_loss: 0.0279\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 96us/sample - loss: 0.0485 - val_loss: 0.0277\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 93us/sample - loss: 0.0500 - val_loss: 0.0275\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0487 - val_loss: 0.0272\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 88us/sample - loss: 0.0515 - val_loss: 0.0270\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 86us/sample - loss: 0.0482 - val_loss: 0.0269\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 85us/sample - loss: 0.0441 - val_loss: 0.0267\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 87us/sample - loss: 0.0477 - val_loss: 0.0265\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 84us/sample - loss: 0.0473 - val_loss: 0.0264\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 93us/sample - loss: 0.0463 - val_loss: 0.0262\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 88us/sample - loss: 0.0498 - val_loss: 0.0260\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 85us/sample - loss: 0.0452 - val_loss: 0.0258\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 78us/sample - loss: 0.0452 - val_loss: 0.0256\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 91us/sample - loss: 0.0433 - val_loss: 0.0253\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 91us/sample - loss: 0.0425 - val_loss: 0.0252\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 125us/sample - loss: 0.0448 - val_loss: 0.0250\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0392 - val_loss: 0.0248\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 100us/sample - loss: 0.0419 - val_loss: 0.0246\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 86us/sample - loss: 0.0433 - val_loss: 0.0244\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 87us/sample - loss: 0.0411 - val_loss: 0.0242\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 96us/sample - loss: 0.0394 - val_loss: 0.0240\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 92us/sample - loss: 0.0432 - val_loss: 0.0238\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0373 - val_loss: 0.0237\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 112us/sample - loss: 0.0386 - val_loss: 0.0235\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 108us/sample - loss: 0.0395 - val_loss: 0.0233\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.323 - 0s 799us/sample - loss: 0.2625 - val_loss: 0.3181\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.259 - 0s 108us/sample - loss: 0.2515 - val_loss: 0.2953\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.272 - 0s 98us/sample - loss: 0.2338 - val_loss: 0.2731\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 80us/sample - loss: 0.2155 - val_loss: 0.2528\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 83us/sample - loss: 0.2146 - val_loss: 0.2330\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 91us/sample - loss: 0.1954 - val_loss: 0.2154\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.168 - 0s 86us/sample - loss: 0.1874 - val_loss: 0.2001\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.143 - 0s 86us/sample - loss: 0.1607 - val_loss: 0.1872\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.188 - 0s 88us/sample - loss: 0.1688 - val_loss: 0.1743\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 85us/sample - loss: 0.1510 - val_loss: 0.1632\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 89us/sample - loss: 0.1537 - val_loss: 0.1541\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 105us/sample - loss: 0.1474 - val_loss: 0.1454\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.171 - 0s 107us/sample - loss: 0.1373 - val_loss: 0.1364\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 114us/sample - loss: 0.1243 - val_loss: 0.1300\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 96us/sample - loss: 0.1304 - val_loss: 0.1236\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 92us/sample - loss: 0.1314 - val_loss: 0.1184\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 82us/sample - loss: 0.1336 - val_loss: 0.1143\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.139 - 0s 96us/sample - loss: 0.1192 - val_loss: 0.1096\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 86us/sample - loss: 0.1141 - val_loss: 0.1047\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 80us/sample - loss: 0.1149 - val_loss: 0.1018\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 86us/sample - loss: 0.1054 - val_loss: 0.0985\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 96us/sample - loss: 0.1045 - val_loss: 0.0955\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 101us/sample - loss: 0.1106 - val_loss: 0.0936\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 100us/sample - loss: 0.0938 - val_loss: 0.0904\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 96us/sample - loss: 0.1027 - val_loss: 0.0880\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 101us/sample - loss: 0.0995 - val_loss: 0.0856\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0947 - val_loss: 0.0835\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 95us/sample - loss: 0.0927 - val_loss: 0.0812\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0982 - val_loss: 0.0801\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 96us/sample - loss: 0.0913 - val_loss: 0.0793\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 96us/sample - loss: 0.0940 - val_loss: 0.0780\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 92us/sample - loss: 0.0869 - val_loss: 0.0767\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 92us/sample - loss: 0.0828 - val_loss: 0.0750\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 104us/sample - loss: 0.0901 - val_loss: 0.0728\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 97us/sample - loss: 0.0820 - val_loss: 0.0714\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 93us/sample - loss: 0.0852 - val_loss: 0.0704\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 101us/sample - loss: 0.0760 - val_loss: 0.0688\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 98us/sample - loss: 0.0736 - val_loss: 0.0668\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 96us/sample - loss: 0.0727 - val_loss: 0.0658\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 96us/sample - loss: 0.0680 - val_loss: 0.0640\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 103us/sample - loss: 0.0749 - val_loss: 0.0624\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 95us/sample - loss: 0.0681 - val_loss: 0.0608\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 83us/sample - loss: 0.0734 - val_loss: 0.0593\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 82us/sample - loss: 0.0661 - val_loss: 0.0586\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 86us/sample - loss: 0.0662 - val_loss: 0.0577\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 93us/sample - loss: 0.0569 - val_loss: 0.0568\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0628 - val_loss: 0.0553\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0628 - val_loss: 0.0541\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 96us/sample - loss: 0.0593 - val_loss: 0.0527\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 88us/sample - loss: 0.0587 - val_loss: 0.0517\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0533 - val_loss: 0.0507\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0525 - val_loss: 0.0494\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0555 - val_loss: 0.0479\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 88us/sample - loss: 0.0555 - val_loss: 0.0475\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 89us/sample - loss: 0.0529 - val_loss: 0.0469\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 83us/sample - loss: 0.0528 - val_loss: 0.0458\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 92us/sample - loss: 0.0538 - val_loss: 0.0450\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 125us/sample - loss: 0.0489 - val_loss: 0.0441\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 93us/sample - loss: 0.0588 - val_loss: 0.0433\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 96us/sample - loss: 0.0469 - val_loss: 0.0419\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 91us/sample - loss: 0.0451 - val_loss: 0.0412\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 90us/sample - loss: 0.0440 - val_loss: 0.0402\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 93us/sample - loss: 0.0482 - val_loss: 0.0394\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0466 - val_loss: 0.0384\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0427 - val_loss: 0.0372\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0412 - val_loss: 0.0364\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 94us/sample - loss: 0.0420 - val_loss: 0.0357\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 104us/sample - loss: 0.0360 - val_loss: 0.0346\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 101us/sample - loss: 0.0452 - val_loss: 0.0336\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 97us/sample - loss: 0.0380 - val_loss: 0.0328\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0475 - val_loss: 0.0322\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 102us/sample - loss: 0.0420 - val_loss: 0.0316\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 95us/sample - loss: 0.0404 - val_loss: 0.0309\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 105us/sample - loss: 0.0389 - val_loss: 0.0302\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 107us/sample - loss: 0.0372 - val_loss: 0.0296\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 118us/sample - loss: 0.0365 - val_loss: 0.0285\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 113us/sample - loss: 0.0350 - val_loss: 0.0279\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 102us/sample - loss: 0.0361 - val_loss: 0.0275\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0385 - val_loss: 0.0273\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 99us/sample - loss: 0.0336 - val_loss: 0.0269\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 97us/sample - loss: 0.0349 - val_loss: 0.0263\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 100us/sample - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0331 - val_loss: 0.0254\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0331 - val_loss: 0.0251\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 101us/sample - loss: 0.0317 - val_loss: 0.0248\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 83us/sample - loss: 0.0350 - val_loss: 0.0243\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 89us/sample - loss: 0.0338 - val_loss: 0.0237\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0278 - val_loss: 0.0232\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0315 - val_loss: 0.0228\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 98us/sample - loss: 0.0325 - val_loss: 0.0225\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 103us/sample - loss: 0.0285 - val_loss: 0.0220\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 89us/sample - loss: 0.0281 - val_loss: 0.0217\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 96us/sample - loss: 0.0316 - val_loss: 0.0211\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0263 - val_loss: 0.0208\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0275 - val_loss: 0.0203\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 81us/sample - loss: 0.0289 - val_loss: 0.0200\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 85us/sample - loss: 0.0255 - val_loss: 0.0197\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0261 - val_loss: 0.0194\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 84us/sample - loss: 0.0253 - val_loss: 0.0189\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 83us/sample - loss: 0.0266 - val_loss: 0.0185\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 83us/sample - loss: 0.0275 - val_loss: 0.0183\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0278 - val_loss: 0.0182\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0269 - val_loss: 0.0179\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 83us/sample - loss: 0.0259 - val_loss: 0.0178\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0262 - val_loss: 0.0173\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0222 - val_loss: 0.0172\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0222 - val_loss: 0.0169\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 99us/sample - loss: 0.0241 - val_loss: 0.0167\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 113us/sample - loss: 0.0230 - val_loss: 0.0167\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0237 - val_loss: 0.0165\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 102us/sample - loss: 0.0234 - val_loss: 0.0164\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 120us/sample - loss: 0.0233 - val_loss: 0.0161\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 120us/sample - loss: 0.0226 - val_loss: 0.0158\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 128us/sample - loss: 0.0216 - val_loss: 0.0157\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 123us/sample - loss: 0.0251 - val_loss: 0.0155\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 127us/sample - loss: 0.0207 - val_loss: 0.0152\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 135us/sample - loss: 0.0218 - val_loss: 0.0151\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 118us/sample - loss: 0.0211 - val_loss: 0.0149\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 127us/sample - loss: 0.0222 - val_loss: 0.0148\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 128us/sample - loss: 0.0225 - val_loss: 0.0147\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 113us/sample - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 113us/sample - loss: 0.0212 - val_loss: 0.0143\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 110us/sample - loss: 0.0200 - val_loss: 0.0142\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 121us/sample - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 115us/sample - loss: 0.0216 - val_loss: 0.0139\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 108us/sample - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0215 - val_loss: 0.0137\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0189 - val_loss: 0.0137\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0181 - val_loss: 0.0136\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0173 - val_loss: 0.0136\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0197 - val_loss: 0.0135\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0196 - val_loss: 0.0134\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0187 - val_loss: 0.0133\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0167 - val_loss: 0.0131\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0184 - val_loss: 0.0131\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0172 - val_loss: 0.0129\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0127\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 97us/sample - loss: 0.0174 - val_loss: 0.0126\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 118us/sample - loss: 0.0166 - val_loss: 0.0124\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 81us/sample - loss: 0.0161 - val_loss: 0.0121\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0147 - val_loss: 0.0119\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.897 - 0s 803us/sample - loss: 0.5048 - val_loss: 0.2632\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.453 - 0s 92us/sample - loss: 0.4525 - val_loss: 0.2420\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.606 - 0s 99us/sample - loss: 0.4022 - val_loss: 0.2234\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.384 - 0s 93us/sample - loss: 0.4015 - val_loss: 0.2058\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.680 - 0s 91us/sample - loss: 0.3713 - val_loss: 0.1890\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.318 - 0s 96us/sample - loss: 0.3150 - val_loss: 0.1754\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.481 - 0s 98us/sample - loss: 0.3324 - val_loss: 0.1629\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.518 - 0s 96us/sample - loss: 0.3175 - val_loss: 0.1499\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.276 - 0s 96us/sample - loss: 0.2806 - val_loss: 0.1400\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.422 - 0s 93us/sample - loss: 0.2703 - val_loss: 0.1310\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.282 - 0s 89us/sample - loss: 0.2856 - val_loss: 0.1227\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.287 - 0s 88us/sample - loss: 0.2509 - val_loss: 0.1145\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 88us/sample - loss: 0.2507 - val_loss: 0.1085\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.181 - 0s 85us/sample - loss: 0.2248 - val_loss: 0.1036\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.176 - 0s 86us/sample - loss: 0.2362 - val_loss: 0.0983\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.202 - 0s 86us/sample - loss: 0.2169 - val_loss: 0.0937\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.223 - 0s 87us/sample - loss: 0.2240 - val_loss: 0.0896\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.302 - 0s 85us/sample - loss: 0.2002 - val_loss: 0.0855\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.352 - 0s 96us/sample - loss: 0.1961 - val_loss: 0.0821\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 86us/sample - loss: 0.1916 - val_loss: 0.0793\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.238 - 0s 85us/sample - loss: 0.1779 - val_loss: 0.0770\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.255 - 0s 96us/sample - loss: 0.1913 - val_loss: 0.0745\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.205 - 0s 107us/sample - loss: 0.1759 - val_loss: 0.0722\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 96us/sample - loss: 0.1746 - val_loss: 0.0702\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 105us/sample - loss: 0.1614 - val_loss: 0.0686\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.194 - 0s 93us/sample - loss: 0.1517 - val_loss: 0.0672\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.231 - 0s 103us/sample - loss: 0.1672 - val_loss: 0.0658\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 106us/sample - loss: 0.1463 - val_loss: 0.0644\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 107us/sample - loss: 0.1552 - val_loss: 0.0628\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.180 - 0s 106us/sample - loss: 0.1346 - val_loss: 0.0616\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 96us/sample - loss: 0.1455 - val_loss: 0.0603\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 105us/sample - loss: 0.1360 - val_loss: 0.0591\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 96us/sample - loss: 0.1389 - val_loss: 0.0579\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 86us/sample - loss: 0.1332 - val_loss: 0.0569\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.157 - 0s 98us/sample - loss: 0.1535 - val_loss: 0.0558\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 95us/sample - loss: 0.1289 - val_loss: 0.0548\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 88us/sample - loss: 0.1361 - val_loss: 0.0538\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.172 - 0s 91us/sample - loss: 0.1266 - val_loss: 0.0529\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.179 - 0s 97us/sample - loss: 0.1284 - val_loss: 0.0519\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 115us/sample - loss: 0.1148 - val_loss: 0.0510\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 115us/sample - loss: 0.1180 - val_loss: 0.0501\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 96us/sample - loss: 0.1145 - val_loss: 0.0493\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 83us/sample - loss: 0.1119 - val_loss: 0.0486\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 86us/sample - loss: 0.1106 - val_loss: 0.0478\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.117 - 0s 93us/sample - loss: 0.1043 - val_loss: 0.0471\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 91us/sample - loss: 0.1058 - val_loss: 0.0465\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 105us/sample - loss: 0.1030 - val_loss: 0.0459\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 93us/sample - loss: 0.0884 - val_loss: 0.0453\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 80us/sample - loss: 0.1007 - val_loss: 0.0447\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 90us/sample - loss: 0.1030 - val_loss: 0.0441\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 91us/sample - loss: 0.0920 - val_loss: 0.0436\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.115 - 0s 91us/sample - loss: 0.0988 - val_loss: 0.0430\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 96us/sample - loss: 0.0891 - val_loss: 0.0425\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 101us/sample - loss: 0.0888 - val_loss: 0.0419\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 90us/sample - loss: 0.0966 - val_loss: 0.0413\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 91us/sample - loss: 0.0794 - val_loss: 0.0409\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 97us/sample - loss: 0.0808 - val_loss: 0.0404\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 91us/sample - loss: 0.0837 - val_loss: 0.0399\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 83us/sample - loss: 0.0764 - val_loss: 0.0395\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 93us/sample - loss: 0.0842 - val_loss: 0.0390\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 90us/sample - loss: 0.0806 - val_loss: 0.0386\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0757 - val_loss: 0.0381\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 102us/sample - loss: 0.0774 - val_loss: 0.0376\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 105us/sample - loss: 0.0717 - val_loss: 0.0371\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 102us/sample - loss: 0.0731 - val_loss: 0.0366\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 120us/sample - loss: 0.0764 - val_loss: 0.0361\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 105us/sample - loss: 0.0652 - val_loss: 0.0356\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 113us/sample - loss: 0.0675 - val_loss: 0.0352\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 98us/sample - loss: 0.0639 - val_loss: 0.0349\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 100us/sample - loss: 0.0633 - val_loss: 0.0344\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 97us/sample - loss: 0.0559 - val_loss: 0.0340\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0601 - val_loss: 0.0336\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 124us/sample - loss: 0.0590 - val_loss: 0.0332\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 103us/sample - loss: 0.0611 - val_loss: 0.0328\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 102us/sample - loss: 0.0615 - val_loss: 0.0324\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 100us/sample - loss: 0.0621 - val_loss: 0.0319\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 104us/sample - loss: 0.0594 - val_loss: 0.0316\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 98us/sample - loss: 0.0591 - val_loss: 0.0312\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 98us/sample - loss: 0.0538 - val_loss: 0.0309\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 98us/sample - loss: 0.0552 - val_loss: 0.0305\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0543 - val_loss: 0.0302\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 96us/sample - loss: 0.0504 - val_loss: 0.0299\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 96us/sample - loss: 0.0499 - val_loss: 0.0295\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 99us/sample - loss: 0.0483 - val_loss: 0.0291\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 88us/sample - loss: 0.0459 - val_loss: 0.0287\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0517 - val_loss: 0.0283\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 81us/sample - loss: 0.0497 - val_loss: 0.0279\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 86us/sample - loss: 0.0462 - val_loss: 0.0276\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0477 - val_loss: 0.0273\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 81us/sample - loss: 0.0431 - val_loss: 0.0269\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 83us/sample - loss: 0.0442 - val_loss: 0.0266\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0428 - val_loss: 0.0263\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 82us/sample - loss: 0.0453 - val_loss: 0.0261\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 89us/sample - loss: 0.0438 - val_loss: 0.0257\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 88us/sample - loss: 0.0433 - val_loss: 0.0253\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 85us/sample - loss: 0.0405 - val_loss: 0.0249\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 81us/sample - loss: 0.0381 - val_loss: 0.0245\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0365 - val_loss: 0.0243\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 88us/sample - loss: 0.0413 - val_loss: 0.0241\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 96us/sample - loss: 0.0379 - val_loss: 0.0239\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 88us/sample - loss: 0.0384 - val_loss: 0.0236\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0366 - val_loss: 0.0233\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0331 - val_loss: 0.0231\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 82us/sample - loss: 0.0380 - val_loss: 0.0228\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0312 - val_loss: 0.0226\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0353 - val_loss: 0.0223\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0339 - val_loss: 0.0221\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 89us/sample - loss: 0.0329 - val_loss: 0.0219\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 99us/sample - loss: 0.0316 - val_loss: 0.0218\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 107us/sample - loss: 0.0322 - val_loss: 0.0215\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 103us/sample - loss: 0.0302 - val_loss: 0.0213\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 103us/sample - loss: 0.0296 - val_loss: 0.0211\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 103us/sample - loss: 0.0310 - val_loss: 0.0208\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 103us/sample - loss: 0.0319 - val_loss: 0.0206\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 104us/sample - loss: 0.0292 - val_loss: 0.0204\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 105us/sample - loss: 0.0275 - val_loss: 0.0203\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 118us/sample - loss: 0.0293 - val_loss: 0.0200\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 98us/sample - loss: 0.0290 - val_loss: 0.0199\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 118us/sample - loss: 0.0278 - val_loss: 0.0198\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0277 - val_loss: 0.0197\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 102us/sample - loss: 0.0270 - val_loss: 0.0196\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0286 - val_loss: 0.0194\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 96us/sample - loss: 0.0270 - val_loss: 0.0191\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 92us/sample - loss: 0.0277 - val_loss: 0.0189\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 100us/sample - loss: 0.0265 - val_loss: 0.0187\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0268 - val_loss: 0.0185\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0250 - val_loss: 0.0182\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 99us/sample - loss: 0.0261 - val_loss: 0.0182\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 113us/sample - loss: 0.0238 - val_loss: 0.0181\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 85us/sample - loss: 0.0251 - val_loss: 0.0179\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 79us/sample - loss: 0.0236 - val_loss: 0.0178\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 96us/sample - loss: 0.0238 - val_loss: 0.0178\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0244 - val_loss: 0.0177\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0244 - val_loss: 0.0176\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 89us/sample - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0224 - val_loss: 0.0172\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0216 - val_loss: 0.0170\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0223 - val_loss: 0.0169\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0206 - val_loss: 0.0168\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0227 - val_loss: 0.0167\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0239 - val_loss: 0.0166\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0237 - val_loss: 0.0165\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0221 - val_loss: 0.0164\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 92us/sample - loss: 0.0235 - val_loss: 0.0164\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0209 - val_loss: 0.0163\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0225 - val_loss: 0.0163\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0204 - val_loss: 0.0162\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0198 - val_loss: 0.0160\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0206 - val_loss: 0.0159\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.183 - 0s 784us/sample - loss: 0.2050 - val_loss: 0.1017\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 103us/sample - loss: 0.1907 - val_loss: 0.1003\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.203 - 0s 88us/sample - loss: 0.1882 - val_loss: 0.0991\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.310 - 0s 81us/sample - loss: 0.1832 - val_loss: 0.0980\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 93us/sample - loss: 0.1899 - val_loss: 0.0969\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 87us/sample - loss: 0.1723 - val_loss: 0.0959\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 88us/sample - loss: 0.1688 - val_loss: 0.0948\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 91us/sample - loss: 0.1619 - val_loss: 0.0934\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.137 - 0s 100us/sample - loss: 0.1512 - val_loss: 0.0924\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 98us/sample - loss: 0.1554 - val_loss: 0.0911\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 96us/sample - loss: 0.1549 - val_loss: 0.0898\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 85us/sample - loss: 0.1519 - val_loss: 0.0885\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 98us/sample - loss: 0.1537 - val_loss: 0.0871\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 95us/sample - loss: 0.1483 - val_loss: 0.0859\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.205 - 0s 115us/sample - loss: 0.1441 - val_loss: 0.0846\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 101us/sample - loss: 0.1296 - val_loss: 0.0835\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 96us/sample - loss: 0.1322 - val_loss: 0.0823\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 101us/sample - loss: 0.1218 - val_loss: 0.0812\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 96us/sample - loss: 0.1245 - val_loss: 0.0800\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 87us/sample - loss: 0.1185 - val_loss: 0.0788\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 87us/sample - loss: 0.1173 - val_loss: 0.0777\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 88us/sample - loss: 0.1186 - val_loss: 0.0766\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 86us/sample - loss: 0.1071 - val_loss: 0.0756\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 85us/sample - loss: 0.1120 - val_loss: 0.0747\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 91us/sample - loss: 0.1087 - val_loss: 0.0737\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 97us/sample - loss: 0.1007 - val_loss: 0.0727\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 118us/sample - loss: 0.1000 - val_loss: 0.0716\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.124 - 0s 92us/sample - loss: 0.1024 - val_loss: 0.0706\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 91us/sample - loss: 0.0983 - val_loss: 0.0694\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 98us/sample - loss: 0.0926 - val_loss: 0.0685\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 106us/sample - loss: 0.0955 - val_loss: 0.0674\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 92us/sample - loss: 0.0881 - val_loss: 0.0665\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 91us/sample - loss: 0.0907 - val_loss: 0.0655\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 100us/sample - loss: 0.0864 - val_loss: 0.0646\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0818 - val_loss: 0.0637\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 105us/sample - loss: 0.0901 - val_loss: 0.0627\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 92us/sample - loss: 0.0793 - val_loss: 0.0620\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 93us/sample - loss: 0.0833 - val_loss: 0.0611\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 94us/sample - loss: 0.0804 - val_loss: 0.0601\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 93us/sample - loss: 0.0734 - val_loss: 0.0592\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 105us/sample - loss: 0.0768 - val_loss: 0.0583\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 98us/sample - loss: 0.0732 - val_loss: 0.0576\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 92us/sample - loss: 0.0713 - val_loss: 0.0568\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 104us/sample - loss: 0.0713 - val_loss: 0.0559\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 101us/sample - loss: 0.0734 - val_loss: 0.0551\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 85us/sample - loss: 0.0675 - val_loss: 0.0543\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 78us/sample - loss: 0.0662 - val_loss: 0.0535\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 91us/sample - loss: 0.0655 - val_loss: 0.0528\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0655 - val_loss: 0.0521\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 81us/sample - loss: 0.0676 - val_loss: 0.0513\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0665 - val_loss: 0.0506\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 91us/sample - loss: 0.0587 - val_loss: 0.0500\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 88us/sample - loss: 0.0502 - val_loss: 0.0493\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 86us/sample - loss: 0.0585 - val_loss: 0.0486\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 93us/sample - loss: 0.0538 - val_loss: 0.0480\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 90us/sample - loss: 0.0581 - val_loss: 0.0473\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 86us/sample - loss: 0.0566 - val_loss: 0.0467\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 88us/sample - loss: 0.0544 - val_loss: 0.0461\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 94us/sample - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 90us/sample - loss: 0.0477 - val_loss: 0.0448\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0536 - val_loss: 0.0442\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 83us/sample - loss: 0.0486 - val_loss: 0.0436\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 83us/sample - loss: 0.0496 - val_loss: 0.0430\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 91us/sample - loss: 0.0501 - val_loss: 0.0423\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 96us/sample - loss: 0.0439 - val_loss: 0.0418\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 96us/sample - loss: 0.0467 - val_loss: 0.0412\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 81us/sample - loss: 0.0479 - val_loss: 0.0407\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 81us/sample - loss: 0.0430 - val_loss: 0.0401\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0395 - val_loss: 0.0396\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 94us/sample - loss: 0.0442 - val_loss: 0.0391\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 96us/sample - loss: 0.0449 - val_loss: 0.0386\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 90us/sample - loss: 0.0407 - val_loss: 0.0381\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0418 - val_loss: 0.0376\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0410 - val_loss: 0.0371\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0411 - val_loss: 0.0367\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0404 - val_loss: 0.0362\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0390 - val_loss: 0.0358\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 95us/sample - loss: 0.0385 - val_loss: 0.0353\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0371 - val_loss: 0.0349\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 100us/sample - loss: 0.0379 - val_loss: 0.0344\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0360 - val_loss: 0.0340\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 127us/sample - loss: 0.0376 - val_loss: 0.0336\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 98us/sample - loss: 0.0341 - val_loss: 0.0332\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0341 - val_loss: 0.0328\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 106us/sample - loss: 0.0333 - val_loss: 0.0324\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 110us/sample - loss: 0.0331 - val_loss: 0.0320\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0340 - val_loss: 0.0316\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 107us/sample - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 91us/sample - loss: 0.0321 - val_loss: 0.0309\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 82us/sample - loss: 0.0302 - val_loss: 0.0305\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0300 - val_loss: 0.0297\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 85us/sample - loss: 0.0292 - val_loss: 0.0294\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 81us/sample - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 89us/sample - loss: 0.0285 - val_loss: 0.0283\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0260 - val_loss: 0.0277\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 86us/sample - loss: 0.0258 - val_loss: 0.0274\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0253 - val_loss: 0.0268\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0246 - val_loss: 0.0265\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 87us/sample - loss: 0.0265 - val_loss: 0.0262\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 85us/sample - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 80us/sample - loss: 0.0243 - val_loss: 0.0256\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0243 - val_loss: 0.0253\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0239 - val_loss: 0.0250\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0239 - val_loss: 0.0247\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0212 - val_loss: 0.0244\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 82us/sample - loss: 0.0228 - val_loss: 0.0242\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0239\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 85us/sample - loss: 0.0209 - val_loss: 0.0236\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0216 - val_loss: 0.0234\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0231\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0198 - val_loss: 0.0228\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0192 - val_loss: 0.0226\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 101us/sample - loss: 0.0199 - val_loss: 0.0223\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0221\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 93us/sample - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0192 - val_loss: 0.0214\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0186 - val_loss: 0.0211\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0184 - val_loss: 0.0209\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0173 - val_loss: 0.0206\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0177 - val_loss: 0.0204\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0170 - val_loss: 0.0192\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0159 - val_loss: 0.0189\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 113us/sample - loss: 0.0154 - val_loss: 0.0187\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0160 - val_loss: 0.0184\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 115us/sample - loss: 0.0142 - val_loss: 0.0182\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0155 - val_loss: 0.0180\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0154 - val_loss: 0.0177\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 115us/sample - loss: 0.0144 - val_loss: 0.0175\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 113us/sample - loss: 0.0134 - val_loss: 0.0171\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0130 - val_loss: 0.0169\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0136 - val_loss: 0.0167\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0114 - val_loss: 0.0155\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0124 - val_loss: 0.0152\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.413 - 0s 814us/sample - loss: 0.2790 - val_loss: 0.1388\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.273 - 0s 105us/sample - loss: 0.2329 - val_loss: 0.1253\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.269 - 0s 117us/sample - loss: 0.2375 - val_loss: 0.1125\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.283 - 0s 108us/sample - loss: 0.2162 - val_loss: 0.1015\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.245 - 0s 94us/sample - loss: 0.2102 - val_loss: 0.0916\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 85us/sample - loss: 0.1901 - val_loss: 0.0823\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.243 - 0s 86us/sample - loss: 0.1731 - val_loss: 0.0744\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.310 - 0s 88us/sample - loss: 0.1827 - val_loss: 0.0675\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 98us/sample - loss: 0.1737 - val_loss: 0.0613\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.166 - 0s 100us/sample - loss: 0.1578 - val_loss: 0.0563\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.174 - 0s 107us/sample - loss: 0.1523 - val_loss: 0.0520\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.213 - 0s 93us/sample - loss: 0.1558 - val_loss: 0.0482\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 88us/sample - loss: 0.1308 - val_loss: 0.0454\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 96us/sample - loss: 0.1324 - val_loss: 0.0431\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 86us/sample - loss: 0.1368 - val_loss: 0.0413\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 88us/sample - loss: 0.1174 - val_loss: 0.0402\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 91us/sample - loss: 0.1138 - val_loss: 0.0394\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 88us/sample - loss: 0.1072 - val_loss: 0.0387\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 108us/sample - loss: 0.1012 - val_loss: 0.0384\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 109us/sample - loss: 0.1099 - val_loss: 0.0382\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 101us/sample - loss: 0.1001 - val_loss: 0.0381\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 97us/sample - loss: 0.1049 - val_loss: 0.0379\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 91us/sample - loss: 0.0932 - val_loss: 0.0378\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 100us/sample - loss: 0.0860 - val_loss: 0.0380\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 91us/sample - loss: 0.0857 - val_loss: 0.0384\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 143us/sample - loss: 0.0894 - val_loss: 0.0383\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 92us/sample - loss: 0.0893 - val_loss: 0.0382\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 93us/sample - loss: 0.0845 - val_loss: 0.0379\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 120us/sample - loss: 0.0970 - val_loss: 0.0379\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 111us/sample - loss: 0.0803 - val_loss: 0.0380\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 119us/sample - loss: 0.0801 - val_loss: 0.0377\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 112us/sample - loss: 0.0771 - val_loss: 0.0373\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 98us/sample - loss: 0.0785 - val_loss: 0.0371\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 96us/sample - loss: 0.0791 - val_loss: 0.0371\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 86us/sample - loss: 0.0784 - val_loss: 0.0370\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 98us/sample - loss: 0.0662 - val_loss: 0.0369\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 93us/sample - loss: 0.0697 - val_loss: 0.0367\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 93us/sample - loss: 0.0717 - val_loss: 0.0365\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 103us/sample - loss: 0.0710 - val_loss: 0.0362\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.0673 - val_loss: 0.0362\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 103us/sample - loss: 0.0653 - val_loss: 0.0362\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 93us/sample - loss: 0.0654 - val_loss: 0.0359\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 96us/sample - loss: 0.0610 - val_loss: 0.0354\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 100us/sample - loss: 0.0685 - val_loss: 0.0350\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 93us/sample - loss: 0.0629 - val_loss: 0.0346\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 108us/sample - loss: 0.0613 - val_loss: 0.0345\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 86us/sample - loss: 0.0616 - val_loss: 0.0343\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 92us/sample - loss: 0.0600 - val_loss: 0.0344\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 90us/sample - loss: 0.0583 - val_loss: 0.0341\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 80us/sample - loss: 0.0561 - val_loss: 0.0339\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 91us/sample - loss: 0.0569 - val_loss: 0.0336\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 91us/sample - loss: 0.0513 - val_loss: 0.0334\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 84us/sample - loss: 0.0572 - val_loss: 0.0333\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 108us/sample - loss: 0.0534 - val_loss: 0.0332\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0496 - val_loss: 0.0330\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0544 - val_loss: 0.0326\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 106us/sample - loss: 0.0505 - val_loss: 0.0322\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 100us/sample - loss: 0.0517 - val_loss: 0.0320\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 112us/sample - loss: 0.0505 - val_loss: 0.0318\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 83us/sample - loss: 0.0503 - val_loss: 0.0319\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 84us/sample - loss: 0.0499 - val_loss: 0.0320\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0445 - val_loss: 0.0318\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0432 - val_loss: 0.0316\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 115us/sample - loss: 0.0456 - val_loss: 0.0314\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 114us/sample - loss: 0.0448 - val_loss: 0.0312\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 97us/sample - loss: 0.0457 - val_loss: 0.0309\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0408 - val_loss: 0.0308\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 105us/sample - loss: 0.0405 - val_loss: 0.0306\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 112us/sample - loss: 0.0418 - val_loss: 0.0303\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 110us/sample - loss: 0.0422 - val_loss: 0.0301\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 115us/sample - loss: 0.0417 - val_loss: 0.0298\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 103us/sample - loss: 0.0397 - val_loss: 0.0297\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 103us/sample - loss: 0.0415 - val_loss: 0.0294\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - ETA: 0s - loss: 0.040 - 0s 171us/sample - loss: 0.0405 - val_loss: 0.0292\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 103us/sample - loss: 0.0362 - val_loss: 0.0291\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 101us/sample - loss: 0.0402 - val_loss: 0.0288\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 123us/sample - loss: 0.0364 - val_loss: 0.0286\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 123us/sample - loss: 0.0331 - val_loss: 0.0283\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 123us/sample - loss: 0.0340 - val_loss: 0.0280\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0353 - val_loss: 0.0278\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 101us/sample - loss: 0.0339 - val_loss: 0.0276\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 115us/sample - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 100us/sample - loss: 0.0345 - val_loss: 0.0270\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 99us/sample - loss: 0.0343 - val_loss: 0.0268\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 88us/sample - loss: 0.0352 - val_loss: 0.0264\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 79us/sample - loss: 0.0308 - val_loss: 0.0262\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0345 - val_loss: 0.0259\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0314 - val_loss: 0.0258\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0325 - val_loss: 0.0258\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 83us/sample - loss: 0.0310 - val_loss: 0.0255\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0325 - val_loss: 0.0253\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 92us/sample - loss: 0.0295 - val_loss: 0.0251\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0289 - val_loss: 0.0250\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0288 - val_loss: 0.0249\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0291 - val_loss: 0.0247\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 81us/sample - loss: 0.0306 - val_loss: 0.0244\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0285 - val_loss: 0.0243\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0278 - val_loss: 0.0243\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 92us/sample - loss: 0.0258 - val_loss: 0.0243\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0264 - val_loss: 0.0238\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0260 - val_loss: 0.0237\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0258 - val_loss: 0.0234\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0273 - val_loss: 0.0231\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0238 - val_loss: 0.0229\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0248 - val_loss: 0.0227\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0259 - val_loss: 0.0224\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 109us/sample - loss: 0.0264 - val_loss: 0.0221\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 113us/sample - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0256 - val_loss: 0.0219\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 109us/sample - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 96us/sample - loss: 0.0231 - val_loss: 0.0217\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 110us/sample - loss: 0.0239 - val_loss: 0.0214\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0221 - val_loss: 0.0213\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 97us/sample - loss: 0.0220 - val_loss: 0.0212\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 94us/sample - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0200 - val_loss: 0.0207\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0215 - val_loss: 0.0199\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0194 - val_loss: 0.0195\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0186 - val_loss: 0.0193\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 97us/sample - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0173 - val_loss: 0.0183\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0181\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0179\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0188 - val_loss: 0.0178\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 99us/sample - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0174\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0166 - val_loss: 0.0163\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0150 - val_loss: 0.0161\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 99us/sample - loss: 0.0146 - val_loss: 0.0159\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.131 - 0s 701us/sample - loss: 0.1071 - val_loss: 0.0987\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 91us/sample - loss: 0.0996 - val_loss: 0.0926\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 88us/sample - loss: 0.0966 - val_loss: 0.0867\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 86us/sample - loss: 0.0869 - val_loss: 0.0812\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 93us/sample - loss: 0.0853 - val_loss: 0.0760\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 86us/sample - loss: 0.0797 - val_loss: 0.0712\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 89us/sample - loss: 0.0767 - val_loss: 0.0668\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 85us/sample - loss: 0.0690 - val_loss: 0.0628\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 86us/sample - loss: 0.0669 - val_loss: 0.0590\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 89us/sample - loss: 0.0608 - val_loss: 0.0555\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 94us/sample - loss: 0.0619 - val_loss: 0.0522\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 86us/sample - loss: 0.0560 - val_loss: 0.0491\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 113us/sample - loss: 0.0556 - val_loss: 0.0463\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 99us/sample - loss: 0.0474 - val_loss: 0.0438\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.0486 - val_loss: 0.0414\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 93us/sample - loss: 0.0435 - val_loss: 0.0391\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0454 - val_loss: 0.0369\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 98us/sample - loss: 0.0401 - val_loss: 0.0351\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 88us/sample - loss: 0.0383 - val_loss: 0.0334\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 96us/sample - loss: 0.0385 - val_loss: 0.0319\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 83us/sample - loss: 0.0327 - val_loss: 0.0304\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0353 - val_loss: 0.0291\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 108us/sample - loss: 0.0326 - val_loss: 0.0278\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 97us/sample - loss: 0.0339 - val_loss: 0.0267\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 113us/sample - loss: 0.0300 - val_loss: 0.0257\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 108us/sample - loss: 0.0303 - val_loss: 0.0247\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 115us/sample - loss: 0.0289 - val_loss: 0.0238\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0250 - val_loss: 0.0230\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 113us/sample - loss: 0.0264 - val_loss: 0.0223\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 102us/sample - loss: 0.0264 - val_loss: 0.0217\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0272 - val_loss: 0.0211\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0253 - val_loss: 0.0205\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 97us/sample - loss: 0.0279 - val_loss: 0.0199\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0236 - val_loss: 0.0194\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0234 - val_loss: 0.0189\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0264 - val_loss: 0.0185\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0238 - val_loss: 0.0182\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 92us/sample - loss: 0.0261 - val_loss: 0.0178\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0240 - val_loss: 0.0175\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0246 - val_loss: 0.0171\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0210 - val_loss: 0.0168\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 92us/sample - loss: 0.0236 - val_loss: 0.0165\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 80us/sample - loss: 0.0213 - val_loss: 0.0163\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 102us/sample - loss: 0.0240 - val_loss: 0.0161\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0158\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0232 - val_loss: 0.0156\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0247 - val_loss: 0.0155\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0265 - val_loss: 0.0153\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0230 - val_loss: 0.0151\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 83us/sample - loss: 0.0222 - val_loss: 0.0150\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0237 - val_loss: 0.0149\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 84us/sample - loss: 0.0223 - val_loss: 0.0148\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0211 - val_loss: 0.0146\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0225 - val_loss: 0.0145\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0144\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0206 - val_loss: 0.0143\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0191 - val_loss: 0.0142\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0226 - val_loss: 0.0141\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 87us/sample - loss: 0.0212 - val_loss: 0.0140\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0221 - val_loss: 0.0139\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0210 - val_loss: 0.0139\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 94us/sample - loss: 0.0203 - val_loss: 0.0137\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0193 - val_loss: 0.0137\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 81us/sample - loss: 0.0193 - val_loss: 0.0135\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0194 - val_loss: 0.0134\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0207 - val_loss: 0.0133\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0200 - val_loss: 0.0132\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 92us/sample - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0130\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0190 - val_loss: 0.0128\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0185 - val_loss: 0.0128\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0167 - val_loss: 0.0128\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 97us/sample - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0188 - val_loss: 0.0127\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 116us/sample - loss: 0.0192 - val_loss: 0.0127\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0197 - val_loss: 0.0126\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 107us/sample - loss: 0.0185 - val_loss: 0.0123\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 96us/sample - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 79us/sample - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0160 - val_loss: 0.0120\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0180 - val_loss: 0.0120\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0155 - val_loss: 0.0119\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 82us/sample - loss: 0.0159 - val_loss: 0.0118\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0116\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 114us/sample - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0154 - val_loss: 0.0111\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 81us/sample - loss: 0.0152 - val_loss: 0.0110\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 109us/sample - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 89us/sample - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 101us/sample - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 87us/sample - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0095\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0106 - val_loss: 0.0093\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.908 - 0s 796us/sample - loss: 0.8005 - val_loss: 0.5388\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.826 - 0s 100us/sample - loss: 0.7726 - val_loss: 0.4988\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.582 - 0s 88us/sample - loss: 0.6992 - val_loss: 0.4609\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.765 - 0s 81us/sample - loss: 0.6629 - val_loss: 0.4248\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.842 - 0s 86us/sample - loss: 0.6222 - val_loss: 0.3895\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.836 - 0s 96us/sample - loss: 0.5385 - val_loss: 0.3583\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.509 - 0s 88us/sample - loss: 0.5260 - val_loss: 0.3281\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.621 - 0s 90us/sample - loss: 0.5341 - val_loss: 0.2985\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.489 - 0s 91us/sample - loss: 0.4663 - val_loss: 0.2713\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.592 - 0s 86us/sample - loss: 0.4186 - val_loss: 0.2466\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.366 - 0s 89us/sample - loss: 0.3924 - val_loss: 0.2238\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.483 - 0s 93us/sample - loss: 0.3632 - val_loss: 0.2032\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.475 - 0s 90us/sample - loss: 0.3516 - val_loss: 0.1838\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.335 - 0s 91us/sample - loss: 0.3105 - val_loss: 0.1665\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.276 - 0s 85us/sample - loss: 0.2782 - val_loss: 0.1513\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.301 - 0s 96us/sample - loss: 0.2562 - val_loss: 0.1374\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.338 - 0s 98us/sample - loss: 0.2556 - val_loss: 0.1240\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 93us/sample - loss: 0.2331 - val_loss: 0.1132\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.220 - 0s 94us/sample - loss: 0.2284 - val_loss: 0.1024\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.263 - 0s 93us/sample - loss: 0.2093 - val_loss: 0.0930\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.217 - 0s 88us/sample - loss: 0.1872 - val_loss: 0.0852\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.173 - 0s 103us/sample - loss: 0.1779 - val_loss: 0.0788\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.229 - 0s 108us/sample - loss: 0.1777 - val_loss: 0.0726\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 100us/sample - loss: 0.1652 - val_loss: 0.0675\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 105us/sample - loss: 0.1580 - val_loss: 0.0636\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 100us/sample - loss: 0.1394 - val_loss: 0.0599\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.204 - 0s 144us/sample - loss: 0.1350 - val_loss: 0.0568\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 100us/sample - loss: 0.1406 - val_loss: 0.0540\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 98us/sample - loss: 0.1368 - val_loss: 0.0518\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 108us/sample - loss: 0.1347 - val_loss: 0.0500\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 115us/sample - loss: 0.1328 - val_loss: 0.0482\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 94us/sample - loss: 0.1267 - val_loss: 0.0465\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 98us/sample - loss: 0.1236 - val_loss: 0.0452\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 91us/sample - loss: 0.1198 - val_loss: 0.0441\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 94us/sample - loss: 0.1172 - val_loss: 0.0431\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 90us/sample - loss: 0.1112 - val_loss: 0.0421\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 96us/sample - loss: 0.1236 - val_loss: 0.0411\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 92us/sample - loss: 0.1093 - val_loss: 0.0404\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 91us/sample - loss: 0.1084 - val_loss: 0.0396\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 103us/sample - loss: 0.1100 - val_loss: 0.0387\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 96us/sample - loss: 0.1030 - val_loss: 0.0380\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 86us/sample - loss: 0.1052 - val_loss: 0.0372\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 80us/sample - loss: 0.0996 - val_loss: 0.0366\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 98us/sample - loss: 0.0980 - val_loss: 0.0361\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 92us/sample - loss: 0.0962 - val_loss: 0.0356\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 90us/sample - loss: 0.0978 - val_loss: 0.0351\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 81us/sample - loss: 0.0977 - val_loss: 0.0348\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 110us/sample - loss: 0.0947 - val_loss: 0.0342\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 100us/sample - loss: 0.0950 - val_loss: 0.0335\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 88us/sample - loss: 0.0891 - val_loss: 0.0330\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 91us/sample - loss: 0.1013 - val_loss: 0.0324\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 97us/sample - loss: 0.0959 - val_loss: 0.0320\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 93us/sample - loss: 0.0966 - val_loss: 0.0317\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 86us/sample - loss: 0.0776 - val_loss: 0.0315\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 88us/sample - loss: 0.0822 - val_loss: 0.0311\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 87us/sample - loss: 0.0812 - val_loss: 0.0306\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 89us/sample - loss: 0.0851 - val_loss: 0.0303\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 93us/sample - loss: 0.0850 - val_loss: 0.0299\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0871 - val_loss: 0.0295\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 96us/sample - loss: 0.0725 - val_loss: 0.0291\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 88us/sample - loss: 0.0675 - val_loss: 0.0288\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 87us/sample - loss: 0.0766 - val_loss: 0.0285\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.124 - 0s 86us/sample - loss: 0.0702 - val_loss: 0.0281\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0659 - val_loss: 0.0278\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 86us/sample - loss: 0.0706 - val_loss: 0.0275\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 107us/sample - loss: 0.0690 - val_loss: 0.0271\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0664 - val_loss: 0.0268\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 92us/sample - loss: 0.0649 - val_loss: 0.0265\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.128 - 0s 98us/sample - loss: 0.0692 - val_loss: 0.0262\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 94us/sample - loss: 0.0635 - val_loss: 0.0259\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 96us/sample - loss: 0.0647 - val_loss: 0.0257\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 103us/sample - loss: 0.0645 - val_loss: 0.0255\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 98us/sample - loss: 0.0553 - val_loss: 0.0252\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 108us/sample - loss: 0.0541 - val_loss: 0.0250\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 101us/sample - loss: 0.0602 - val_loss: 0.0248\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 105us/sample - loss: 0.0581 - val_loss: 0.0245\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 94us/sample - loss: 0.0603 - val_loss: 0.0243\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 105us/sample - loss: 0.0535 - val_loss: 0.0240\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 103us/sample - loss: 0.0517 - val_loss: 0.0237\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 99us/sample - loss: 0.0543 - val_loss: 0.0234\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 91us/sample - loss: 0.0538 - val_loss: 0.0232\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 91us/sample - loss: 0.0513 - val_loss: 0.0231\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 96us/sample - loss: 0.0561 - val_loss: 0.0228\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0485 - val_loss: 0.0225\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 94us/sample - loss: 0.0513 - val_loss: 0.0223\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0503 - val_loss: 0.0220\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 83us/sample - loss: 0.0491 - val_loss: 0.0219\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 81us/sample - loss: 0.0475 - val_loss: 0.0217\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 83us/sample - loss: 0.0454 - val_loss: 0.0215\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 83us/sample - loss: 0.0495 - val_loss: 0.0213\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 97us/sample - loss: 0.0517 - val_loss: 0.0212\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 94us/sample - loss: 0.0433 - val_loss: 0.0210\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 92us/sample - loss: 0.0427 - val_loss: 0.0208\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0482 - val_loss: 0.0206\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0443 - val_loss: 0.0204\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 91us/sample - loss: 0.0429 - val_loss: 0.0202\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 94us/sample - loss: 0.0471 - val_loss: 0.0200\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 88us/sample - loss: 0.0408 - val_loss: 0.0198\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0431 - val_loss: 0.0197\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0409 - val_loss: 0.0196\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 85us/sample - loss: 0.0447 - val_loss: 0.0195\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 86us/sample - loss: 0.0397 - val_loss: 0.0191\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0395 - val_loss: 0.0189\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 92us/sample - loss: 0.0407 - val_loss: 0.0187\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0359 - val_loss: 0.0186\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 87us/sample - loss: 0.0383 - val_loss: 0.0185\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 97us/sample - loss: 0.0383 - val_loss: 0.0184\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0351 - val_loss: 0.0182\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 105us/sample - loss: 0.0372 - val_loss: 0.0180\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0354 - val_loss: 0.0179\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 110us/sample - loss: 0.0373 - val_loss: 0.0178\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 98us/sample - loss: 0.0371 - val_loss: 0.0177\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 95us/sample - loss: 0.0353 - val_loss: 0.0177\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0374 - val_loss: 0.0176\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 96us/sample - loss: 0.0356 - val_loss: 0.0176\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0365 - val_loss: 0.0174\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 98us/sample - loss: 0.0342 - val_loss: 0.0173\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 108us/sample - loss: 0.0329 - val_loss: 0.0173\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 102us/sample - loss: 0.0325 - val_loss: 0.0173\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 90us/sample - loss: 0.0327 - val_loss: 0.0171\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0309 - val_loss: 0.0170\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0289 - val_loss: 0.0168\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 96us/sample - loss: 0.0345 - val_loss: 0.0168\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0310 - val_loss: 0.0167\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0319 - val_loss: 0.0167\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 97us/sample - loss: 0.0304 - val_loss: 0.0166\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0283 - val_loss: 0.0164\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0294 - val_loss: 0.0163\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0301 - val_loss: 0.0162\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0309 - val_loss: 0.0161\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0289 - val_loss: 0.0160\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 92us/sample - loss: 0.0267 - val_loss: 0.0159\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0253 - val_loss: 0.0158\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 90us/sample - loss: 0.0282 - val_loss: 0.0157\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0308 - val_loss: 0.0157\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0314 - val_loss: 0.0157\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0273 - val_loss: 0.0156\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 85us/sample - loss: 0.0294 - val_loss: 0.0156\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0280 - val_loss: 0.0155\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0259 - val_loss: 0.0154\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0279 - val_loss: 0.0154\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0259 - val_loss: 0.0153\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0260 - val_loss: 0.0153\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 86us/sample - loss: 0.0242 - val_loss: 0.0152\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0246 - val_loss: 0.0151\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0226 - val_loss: 0.0149\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0245 - val_loss: 0.0148\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 1.060 - 0s 829us/sample - loss: 0.9414 - val_loss: 0.7579\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.643 - 0s 101us/sample - loss: 0.8953 - val_loss: 0.7309\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.890 - 0s 89us/sample - loss: 0.8875 - val_loss: 0.7033\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.834 - 0s 90us/sample - loss: 0.8146 - val_loss: 0.6774\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.787 - 0s 85us/sample - loss: 0.8044 - val_loss: 0.6523\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.778 - 0s 91us/sample - loss: 0.7888 - val_loss: 0.6269\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.765 - 0s 94us/sample - loss: 0.7200 - val_loss: 0.6021\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.817 - 0s 79us/sample - loss: 0.7285 - val_loss: 0.5778\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.552 - 0s 83us/sample - loss: 0.7159 - val_loss: 0.5528\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.659 - 0s 84us/sample - loss: 0.6734 - val_loss: 0.5276\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.705 - 0s 88us/sample - loss: 0.6312 - val_loss: 0.5025\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.687 - 0s 86us/sample - loss: 0.6494 - val_loss: 0.4766\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.693 - 0s 95us/sample - loss: 0.5746 - val_loss: 0.4511\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.627 - 0s 105us/sample - loss: 0.5590 - val_loss: 0.4236\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.495 - 0s 95us/sample - loss: 0.5612 - val_loss: 0.3944\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.505 - 0s 86us/sample - loss: 0.5322 - val_loss: 0.3635\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.479 - 0s 103us/sample - loss: 0.4657 - val_loss: 0.3343\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.464 - 0s 103us/sample - loss: 0.4505 - val_loss: 0.3051\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.592 - 0s 95us/sample - loss: 0.4306 - val_loss: 0.2750\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.397 - 0s 90us/sample - loss: 0.3968 - val_loss: 0.2455\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.303 - 0s 84us/sample - loss: 0.3714 - val_loss: 0.2181\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.443 - 0s 80us/sample - loss: 0.3307 - val_loss: 0.1941\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.250 - 0s 84us/sample - loss: 0.2973 - val_loss: 0.1714\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.360 - 0s 83us/sample - loss: 0.2751 - val_loss: 0.1505\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.233 - 0s 83us/sample - loss: 0.2623 - val_loss: 0.1319\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.238 - 0s 98us/sample - loss: 0.2432 - val_loss: 0.1149\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.166 - 0s 100us/sample - loss: 0.2089 - val_loss: 0.1010\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.299 - 0s 99us/sample - loss: 0.2033 - val_loss: 0.0885\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.224 - 0s 100us/sample - loss: 0.1910 - val_loss: 0.0770\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 96us/sample - loss: 0.1700 - val_loss: 0.0681\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 93us/sample - loss: 0.1555 - val_loss: 0.0607\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 91us/sample - loss: 0.1453 - val_loss: 0.0542\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.255 - 0s 106us/sample - loss: 0.1690 - val_loss: 0.0487\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.150 - 0s 98us/sample - loss: 0.1304 - val_loss: 0.0435\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.157 - 0s 101us/sample - loss: 0.1287 - val_loss: 0.0397\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 98us/sample - loss: 0.1348 - val_loss: 0.0366\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 91us/sample - loss: 0.1251 - val_loss: 0.0341\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 101us/sample - loss: 0.1322 - val_loss: 0.0319\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 103us/sample - loss: 0.1165 - val_loss: 0.0301\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 89us/sample - loss: 0.1187 - val_loss: 0.0286\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.207 - 0s 100us/sample - loss: 0.1128 - val_loss: 0.0275\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 113us/sample - loss: 0.0996 - val_loss: 0.0265\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 123us/sample - loss: 0.1138 - val_loss: 0.0256\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 113us/sample - loss: 0.0975 - val_loss: 0.0250\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.1086 - val_loss: 0.0245\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 96us/sample - loss: 0.1046 - val_loss: 0.0242\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 91us/sample - loss: 0.1007 - val_loss: 0.0240\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 82us/sample - loss: 0.0915 - val_loss: 0.0237\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 110us/sample - loss: 0.1001 - val_loss: 0.0234\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 86us/sample - loss: 0.0916 - val_loss: 0.0232\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.115 - 0s 96us/sample - loss: 0.0979 - val_loss: 0.0231\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 79us/sample - loss: 0.0888 - val_loss: 0.0229\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 86us/sample - loss: 0.0989 - val_loss: 0.0228\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 88us/sample - loss: 0.1010 - val_loss: 0.0226\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 86us/sample - loss: 0.0974 - val_loss: 0.0225\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 86us/sample - loss: 0.0912 - val_loss: 0.0224\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 88us/sample - loss: 0.0904 - val_loss: 0.0223\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 78us/sample - loss: 0.0869 - val_loss: 0.0222\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 91us/sample - loss: 0.0967 - val_loss: 0.0221\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 83us/sample - loss: 0.0825 - val_loss: 0.0220\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 84us/sample - loss: 0.0749 - val_loss: 0.0219\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 91us/sample - loss: 0.0918 - val_loss: 0.0219\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 83us/sample - loss: 0.0834 - val_loss: 0.0218\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 89us/sample - loss: 0.0810 - val_loss: 0.0217\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 88us/sample - loss: 0.0740 - val_loss: 0.0217\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 85us/sample - loss: 0.0821 - val_loss: 0.0216\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 93us/sample - loss: 0.0732 - val_loss: 0.0215\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 85us/sample - loss: 0.0812 - val_loss: 0.0215\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 90us/sample - loss: 0.0828 - val_loss: 0.0213\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 103us/sample - loss: 0.0790 - val_loss: 0.0213\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 101us/sample - loss: 0.0820 - val_loss: 0.0213\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 98us/sample - loss: 0.0853 - val_loss: 0.0212\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0761 - val_loss: 0.0212\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 98us/sample - loss: 0.0776 - val_loss: 0.0211\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 98us/sample - loss: 0.0709 - val_loss: 0.0211\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 96us/sample - loss: 0.0673 - val_loss: 0.0210\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 96us/sample - loss: 0.0704 - val_loss: 0.0209\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 97us/sample - loss: 0.0681 - val_loss: 0.0208\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 104us/sample - loss: 0.0666 - val_loss: 0.0207\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 98us/sample - loss: 0.0685 - val_loss: 0.0206\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 93us/sample - loss: 0.0621 - val_loss: 0.0205\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 90us/sample - loss: 0.0683 - val_loss: 0.0204\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0663 - val_loss: 0.0203\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 86us/sample - loss: 0.0643 - val_loss: 0.0203\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 101us/sample - loss: 0.0617 - val_loss: 0.0203\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 95us/sample - loss: 0.0563 - val_loss: 0.0203\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 105us/sample - loss: 0.0607 - val_loss: 0.0202\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 117us/sample - loss: 0.0607 - val_loss: 0.0201\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 100us/sample - loss: 0.0603 - val_loss: 0.0200\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 92us/sample - loss: 0.0660 - val_loss: 0.0200\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 83us/sample - loss: 0.0645 - val_loss: 0.0198\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 81us/sample - loss: 0.0532 - val_loss: 0.0196\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 83us/sample - loss: 0.0490 - val_loss: 0.0196\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 83us/sample - loss: 0.0629 - val_loss: 0.0195\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 92us/sample - loss: 0.0538 - val_loss: 0.0194\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0579 - val_loss: 0.0193\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 87us/sample - loss: 0.0540 - val_loss: 0.0193\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 94us/sample - loss: 0.0542 - val_loss: 0.0192\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 90us/sample - loss: 0.0543 - val_loss: 0.0192\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 89us/sample - loss: 0.0572 - val_loss: 0.0191\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 125us/sample - loss: 0.0563 - val_loss: 0.0190\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 88us/sample - loss: 0.0547 - val_loss: 0.0189\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0545 - val_loss: 0.0188\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 88us/sample - loss: 0.0556 - val_loss: 0.0187\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0505 - val_loss: 0.0186\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 97us/sample - loss: 0.0512 - val_loss: 0.0185\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0494 - val_loss: 0.0184\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 94us/sample - loss: 0.0493 - val_loss: 0.0184\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 85us/sample - loss: 0.0410 - val_loss: 0.0183\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0433 - val_loss: 0.0182\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 92us/sample - loss: 0.0474 - val_loss: 0.0182\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 85us/sample - loss: 0.0433 - val_loss: 0.0181\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 91us/sample - loss: 0.0434 - val_loss: 0.0180\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 104us/sample - loss: 0.0401 - val_loss: 0.0180\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 92us/sample - loss: 0.0410 - val_loss: 0.0179\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 107us/sample - loss: 0.0414 - val_loss: 0.0177\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 96us/sample - loss: 0.0377 - val_loss: 0.0177\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.0415 - val_loss: 0.0176\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 100us/sample - loss: 0.0457 - val_loss: 0.0176\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 100us/sample - loss: 0.0407 - val_loss: 0.0175\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 108us/sample - loss: 0.0385 - val_loss: 0.0175\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 101us/sample - loss: 0.0432 - val_loss: 0.0173\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0369 - val_loss: 0.0172\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 96us/sample - loss: 0.0388 - val_loss: 0.0171\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 89us/sample - loss: 0.0358 - val_loss: 0.0171\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 91us/sample - loss: 0.0368 - val_loss: 0.0171\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 92us/sample - loss: 0.0372 - val_loss: 0.0170\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0343 - val_loss: 0.0171\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0342 - val_loss: 0.0169\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0347 - val_loss: 0.0168\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 91us/sample - loss: 0.0340 - val_loss: 0.0166\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0371 - val_loss: 0.0166\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 96us/sample - loss: 0.0353 - val_loss: 0.0165\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0371 - val_loss: 0.0164\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0324 - val_loss: 0.0163\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 95us/sample - loss: 0.0355 - val_loss: 0.0162\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0335 - val_loss: 0.0161\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0337 - val_loss: 0.0161\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0330 - val_loss: 0.0160\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 85us/sample - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0316 - val_loss: 0.0160\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 88us/sample - loss: 0.0334 - val_loss: 0.0159\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0312 - val_loss: 0.0158\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 88us/sample - loss: 0.0324 - val_loss: 0.0157\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 86us/sample - loss: 0.0316 - val_loss: 0.0156\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0274 - val_loss: 0.0155\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 83us/sample - loss: 0.0275 - val_loss: 0.0154\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 81us/sample - loss: 0.0287 - val_loss: 0.0154\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0282 - val_loss: 0.0153\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0279 - val_loss: 0.0152\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.253 - 0s 1ms/sample - loss: 0.2093 - val_loss: 0.2089\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 117us/sample - loss: 0.1941 - val_loss: 0.1904\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.194 - 0s 110us/sample - loss: 0.1749 - val_loss: 0.1739\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 106us/sample - loss: 0.1576 - val_loss: 0.1592\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.182 - 0s 115us/sample - loss: 0.1568 - val_loss: 0.1451\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 118us/sample - loss: 0.1322 - val_loss: 0.1328\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 111us/sample - loss: 0.1262 - val_loss: 0.1217\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 115us/sample - loss: 0.1200 - val_loss: 0.1110\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 110us/sample - loss: 0.1063 - val_loss: 0.1013\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 104us/sample - loss: 0.0948 - val_loss: 0.0930\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 115us/sample - loss: 0.1002 - val_loss: 0.0853\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 109us/sample - loss: 0.0961 - val_loss: 0.0784\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 98us/sample - loss: 0.0897 - val_loss: 0.0720\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 99us/sample - loss: 0.0807 - val_loss: 0.0664\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 101us/sample - loss: 0.0798 - val_loss: 0.0617\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0723 - val_loss: 0.0577\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 103us/sample - loss: 0.0662 - val_loss: 0.0540\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 98us/sample - loss: 0.0605 - val_loss: 0.0507\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 101us/sample - loss: 0.0653 - val_loss: 0.0479\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 115us/sample - loss: 0.0641 - val_loss: 0.0455\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 96us/sample - loss: 0.0615 - val_loss: 0.0434\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 81us/sample - loss: 0.0585 - val_loss: 0.0413\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 96us/sample - loss: 0.0564 - val_loss: 0.0396\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 91us/sample - loss: 0.0552 - val_loss: 0.0381\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 100us/sample - loss: 0.0549 - val_loss: 0.0369\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 96us/sample - loss: 0.0524 - val_loss: 0.0357\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 105us/sample - loss: 0.0540 - val_loss: 0.0348\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 94us/sample - loss: 0.0528 - val_loss: 0.0338\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 95us/sample - loss: 0.0560 - val_loss: 0.0331\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0507 - val_loss: 0.0323\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 102us/sample - loss: 0.0554 - val_loss: 0.0315\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.0487 - val_loss: 0.0308\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 97us/sample - loss: 0.0510 - val_loss: 0.0302\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0446 - val_loss: 0.0295\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.0489 - val_loss: 0.0294\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0426 - val_loss: 0.0290\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 100us/sample - loss: 0.0443 - val_loss: 0.0285\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 95us/sample - loss: 0.0455 - val_loss: 0.0281\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0437 - val_loss: 0.0279\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 102us/sample - loss: 0.0427 - val_loss: 0.0275\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0437 - val_loss: 0.0273\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 116us/sample - loss: 0.0448 - val_loss: 0.0269\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 85us/sample - loss: 0.0413 - val_loss: 0.0267\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 95us/sample - loss: 0.0433 - val_loss: 0.0265\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 82us/sample - loss: 0.0385 - val_loss: 0.0261\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0412 - val_loss: 0.0256\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 87us/sample - loss: 0.0426 - val_loss: 0.0253\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0407 - val_loss: 0.0251\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 109us/sample - loss: 0.0371 - val_loss: 0.0248\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0377 - val_loss: 0.0246\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 81us/sample - loss: 0.0370 - val_loss: 0.0242\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 81us/sample - loss: 0.0384 - val_loss: 0.0240\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0376 - val_loss: 0.0237\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 86us/sample - loss: 0.0348 - val_loss: 0.0234\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 83us/sample - loss: 0.0346 - val_loss: 0.0232\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0375 - val_loss: 0.0231\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 84us/sample - loss: 0.0360 - val_loss: 0.0229\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 88us/sample - loss: 0.0355 - val_loss: 0.0227\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 88us/sample - loss: 0.0339 - val_loss: 0.0225\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0327 - val_loss: 0.0224\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 92us/sample - loss: 0.0371 - val_loss: 0.0221\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 93us/sample - loss: 0.0341 - val_loss: 0.0218\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0348 - val_loss: 0.0216\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 96us/sample - loss: 0.0331 - val_loss: 0.0213\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 84us/sample - loss: 0.0320 - val_loss: 0.0212\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 89us/sample - loss: 0.0326 - val_loss: 0.0210\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 95us/sample - loss: 0.0326 - val_loss: 0.0208\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 98us/sample - loss: 0.0292 - val_loss: 0.0207\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 104us/sample - loss: 0.0312 - val_loss: 0.0205\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 96us/sample - loss: 0.0309 - val_loss: 0.0204\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0294 - val_loss: 0.0203\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 94us/sample - loss: 0.0295 - val_loss: 0.0203\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 99us/sample - loss: 0.0309 - val_loss: 0.0201\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 103us/sample - loss: 0.0282 - val_loss: 0.0200\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0305 - val_loss: 0.0199\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0296 - val_loss: 0.0197\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 101us/sample - loss: 0.0279 - val_loss: 0.0195\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0303 - val_loss: 0.0195\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 101us/sample - loss: 0.0279 - val_loss: 0.0194\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 98us/sample - loss: 0.0275 - val_loss: 0.0192\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0296 - val_loss: 0.0191\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0291 - val_loss: 0.0190\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 97us/sample - loss: 0.0283 - val_loss: 0.0189\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0261 - val_loss: 0.0188\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 108us/sample - loss: 0.0252 - val_loss: 0.0186\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0267 - val_loss: 0.0185\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0257 - val_loss: 0.0183\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0275 - val_loss: 0.0182\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 86us/sample - loss: 0.0257 - val_loss: 0.0181\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0250 - val_loss: 0.0179\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 84us/sample - loss: 0.0263 - val_loss: 0.0178\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0253 - val_loss: 0.0178\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0258 - val_loss: 0.0178\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 89us/sample - loss: 0.0249 - val_loss: 0.0177\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0253 - val_loss: 0.0176\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 97us/sample - loss: 0.0230 - val_loss: 0.0175\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0241 - val_loss: 0.0173\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0221 - val_loss: 0.0171\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 118us/sample - loss: 0.0241 - val_loss: 0.0170\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0169\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0227 - val_loss: 0.0168\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0227 - val_loss: 0.0166\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0215 - val_loss: 0.0165\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0220 - val_loss: 0.0164\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0224 - val_loss: 0.0163\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 101us/sample - loss: 0.0226 - val_loss: 0.0163\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0208 - val_loss: 0.0161\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0213 - val_loss: 0.0159\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0210 - val_loss: 0.0158\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 120us/sample - loss: 0.0213 - val_loss: 0.0157\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 104us/sample - loss: 0.0210 - val_loss: 0.0157\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0189 - val_loss: 0.0156\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0218 - val_loss: 0.0156\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 116us/sample - loss: 0.0201 - val_loss: 0.0155\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 113us/sample - loss: 0.0190 - val_loss: 0.0154\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 113us/sample - loss: 0.0200 - val_loss: 0.0152\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0190 - val_loss: 0.0152\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 113us/sample - loss: 0.0182 - val_loss: 0.0151\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0200 - val_loss: 0.0150\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0183 - val_loss: 0.0149\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0181 - val_loss: 0.0148\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0181 - val_loss: 0.0147\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0173 - val_loss: 0.0145\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 92us/sample - loss: 0.0177 - val_loss: 0.0144\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0143\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 99us/sample - loss: 0.0181 - val_loss: 0.0142\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 89us/sample - loss: 0.0165 - val_loss: 0.0141\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 85us/sample - loss: 0.0170 - val_loss: 0.0141\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 82us/sample - loss: 0.0176 - val_loss: 0.0140\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0139\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0138\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 80us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 102us/sample - loss: 0.0154 - val_loss: 0.0133\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0148 - val_loss: 0.0129\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0151 - val_loss: 0.0129\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0143 - val_loss: 0.0127\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0126\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 78us/sample - loss: 0.0150 - val_loss: 0.0126\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 468us/sample - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0123\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 113us/sample - loss: 0.0133 - val_loss: 0.0122\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 1.339 - 0s 708us/sample - loss: 1.2082 - val_loss: 0.6961\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.632 - 0s 87us/sample - loss: 0.9820 - val_loss: 0.6312\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.272 - 0s 88us/sample - loss: 0.9252 - val_loss: 0.5737\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.134 - 0s 96us/sample - loss: 0.9537 - val_loss: 0.5168\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.753 - 0s 90us/sample - loss: 0.9108 - val_loss: 0.4677\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.696 - 0s 91us/sample - loss: 0.9519 - val_loss: 0.4246\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.700 - 0s 94us/sample - loss: 0.8072 - val_loss: 0.3842\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.837 - 0s 96us/sample - loss: 0.8290 - val_loss: 0.3476\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.975 - 0s 91us/sample - loss: 0.7688 - val_loss: 0.3147\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.366 - 0s 93us/sample - loss: 0.7376 - val_loss: 0.2887\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.742 - 0s 88us/sample - loss: 0.7652 - val_loss: 0.2623\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.646 - 0s 93us/sample - loss: 0.5808 - val_loss: 0.2421\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.512 - 0s 115us/sample - loss: 0.6450 - val_loss: 0.2233\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.612 - 0s 116us/sample - loss: 0.5560 - val_loss: 0.2069\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.464 - 0s 89us/sample - loss: 0.6678 - val_loss: 0.1951\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.521 - 0s 91us/sample - loss: 0.5647 - val_loss: 0.1834\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.642 - 0s 98us/sample - loss: 0.6163 - val_loss: 0.1740\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.533 - 0s 83us/sample - loss: 0.5376 - val_loss: 0.1625\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.414 - 0s 90us/sample - loss: 0.5554 - val_loss: 0.1546\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.878 - 0s 87us/sample - loss: 0.5726 - val_loss: 0.1482\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.637 - 0s 93us/sample - loss: 0.5389 - val_loss: 0.1424\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.915 - 0s 100us/sample - loss: 0.5362 - val_loss: 0.1374\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.503 - 0s 103us/sample - loss: 0.5465 - val_loss: 0.1366\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.606 - 0s 105us/sample - loss: 0.5506 - val_loss: 0.1338\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.331 - 0s 104us/sample - loss: 0.4840 - val_loss: 0.1274\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.431 - 0s 103us/sample - loss: 0.4784 - val_loss: 0.1246\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.632 - 0s 104us/sample - loss: 0.4761 - val_loss: 0.1209\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.382 - 0s 103us/sample - loss: 0.4326 - val_loss: 0.1193\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.360 - 0s 112us/sample - loss: 0.4366 - val_loss: 0.1154\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.535 - 0s 105us/sample - loss: 0.4620 - val_loss: 0.1132\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.320 - 0s 101us/sample - loss: 0.4067 - val_loss: 0.1102\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.376 - 0s 103us/sample - loss: 0.4161 - val_loss: 0.1056\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.438 - 0s 104us/sample - loss: 0.4051 - val_loss: 0.1030\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.372 - 0s 99us/sample - loss: 0.3816 - val_loss: 0.1007\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.427 - 0s 94us/sample - loss: 0.3859 - val_loss: 0.0996\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.339 - 0s 119us/sample - loss: 0.3970 - val_loss: 0.0998\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.265 - 0s 92us/sample - loss: 0.3860 - val_loss: 0.0982\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.157 - 0s 96us/sample - loss: 0.3817 - val_loss: 0.0965\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.374 - 0s 102us/sample - loss: 0.3369 - val_loss: 0.0949\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.652 - 0s 90us/sample - loss: 0.3597 - val_loss: 0.0925\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.302 - 0s 97us/sample - loss: 0.3161 - val_loss: 0.0924\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.205 - 0s 84us/sample - loss: 0.3222 - val_loss: 0.0899\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.382 - 0s 81us/sample - loss: 0.3256 - val_loss: 0.0886\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.243 - 0s 80us/sample - loss: 0.3333 - val_loss: 0.0867\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.222 - 0s 80us/sample - loss: 0.3136 - val_loss: 0.0849\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.241 - 0s 84us/sample - loss: 0.3342 - val_loss: 0.0846\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.315 - 0s 86us/sample - loss: 0.3133 - val_loss: 0.0847\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.241 - 0s 84us/sample - loss: 0.3202 - val_loss: 0.0846\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.251 - 0s 93us/sample - loss: 0.2830 - val_loss: 0.0849\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.265 - 0s 93us/sample - loss: 0.2740 - val_loss: 0.0838\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.240 - 0s 88us/sample - loss: 0.2681 - val_loss: 0.0832\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 108us/sample - loss: 0.2942 - val_loss: 0.0825\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.199 - 0s 98us/sample - loss: 0.2618 - val_loss: 0.0801\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.494 - 0s 93us/sample - loss: 0.2584 - val_loss: 0.0787\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.282 - 0s 93us/sample - loss: 0.2699 - val_loss: 0.0790\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 80us/sample - loss: 0.2661 - val_loss: 0.0782\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.193 - 0s 87us/sample - loss: 0.2528 - val_loss: 0.0770\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.202 - 0s 88us/sample - loss: 0.2404 - val_loss: 0.0755\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.239 - 0s 86us/sample - loss: 0.2484 - val_loss: 0.0739\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.194 - 0s 97us/sample - loss: 0.2249 - val_loss: 0.0724\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.314 - 0s 91us/sample - loss: 0.2363 - val_loss: 0.0708\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 96us/sample - loss: 0.2161 - val_loss: 0.0707\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.219 - 0s 84us/sample - loss: 0.2189 - val_loss: 0.0716\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.206 - 0s 87us/sample - loss: 0.2051 - val_loss: 0.0721\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.309 - 0s 84us/sample - loss: 0.2347 - val_loss: 0.0714\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 106us/sample - loss: 0.2293 - val_loss: 0.0708\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.315 - 0s 95us/sample - loss: 0.1828 - val_loss: 0.0693\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.245 - 0s 103us/sample - loss: 0.1947 - val_loss: 0.0685\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.200 - 0s 102us/sample - loss: 0.1977 - val_loss: 0.0660\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 97us/sample - loss: 0.1900 - val_loss: 0.0646\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.326 - 0s 98us/sample - loss: 0.1660 - val_loss: 0.0644\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.186 - 0s 100us/sample - loss: 0.1718 - val_loss: 0.0638\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 98us/sample - loss: 0.1774 - val_loss: 0.0630\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.199 - 0s 99us/sample - loss: 0.1645 - val_loss: 0.0624\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.189 - 0s 101us/sample - loss: 0.1870 - val_loss: 0.0616\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.204 - 0s 98us/sample - loss: 0.1677 - val_loss: 0.0607\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 93us/sample - loss: 0.1477 - val_loss: 0.0612\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 98us/sample - loss: 0.1383 - val_loss: 0.0604\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.194 - 0s 112us/sample - loss: 0.1649 - val_loss: 0.0594\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 105us/sample - loss: 0.1638 - val_loss: 0.0589\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 105us/sample - loss: 0.1449 - val_loss: 0.0580\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 112us/sample - loss: 0.1439 - val_loss: 0.0579\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 97us/sample - loss: 0.1478 - val_loss: 0.0575\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.180 - 0s 94us/sample - loss: 0.1562 - val_loss: 0.0567\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.174 - 0s 96us/sample - loss: 0.1348 - val_loss: 0.0567\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 88us/sample - loss: 0.1297 - val_loss: 0.0564\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.178 - 0s 90us/sample - loss: 0.1312 - val_loss: 0.0555\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.137 - 0s 90us/sample - loss: 0.1363 - val_loss: 0.0550\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 91us/sample - loss: 0.1338 - val_loss: 0.0539\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 86us/sample - loss: 0.1345 - val_loss: 0.0535\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 124us/sample - loss: 0.1145 - val_loss: 0.0525\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 83us/sample - loss: 0.1282 - val_loss: 0.0522\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 100us/sample - loss: 0.1227 - val_loss: 0.0526\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 88us/sample - loss: 0.1158 - val_loss: 0.0525\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 83us/sample - loss: 0.1024 - val_loss: 0.0524\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.109 - 0s 88us/sample - loss: 0.1048 - val_loss: 0.0518\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 90us/sample - loss: 0.1028 - val_loss: 0.0506\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 93us/sample - loss: 0.1008 - val_loss: 0.0500\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 86us/sample - loss: 0.0894 - val_loss: 0.0499\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 92us/sample - loss: 0.1018 - val_loss: 0.0496\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.221 - 0s 93us/sample - loss: 0.1054 - val_loss: 0.0489\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 86us/sample - loss: 0.1010 - val_loss: 0.0489\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.181 - 0s 86us/sample - loss: 0.0988 - val_loss: 0.0481\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 94us/sample - loss: 0.0952 - val_loss: 0.0470\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 93us/sample - loss: 0.0914 - val_loss: 0.0461\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 104us/sample - loss: 0.0883 - val_loss: 0.0456\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 96us/sample - loss: 0.0952 - val_loss: 0.0454\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0810 - val_loss: 0.0450\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 100us/sample - loss: 0.0948 - val_loss: 0.0449\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.114 - 0s 102us/sample - loss: 0.0941 - val_loss: 0.0449\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 103us/sample - loss: 0.0774 - val_loss: 0.0445\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 103us/sample - loss: 0.0821 - val_loss: 0.0436\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 111us/sample - loss: 0.0787 - val_loss: 0.0429\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 103us/sample - loss: 0.0745 - val_loss: 0.0421\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 105us/sample - loss: 0.0756 - val_loss: 0.0412\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 98us/sample - loss: 0.0725 - val_loss: 0.0405\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 104us/sample - loss: 0.0752 - val_loss: 0.0399\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 103us/sample - loss: 0.0793 - val_loss: 0.0393\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 105us/sample - loss: 0.0654 - val_loss: 0.0388\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 96us/sample - loss: 0.0757 - val_loss: 0.0387\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 100us/sample - loss: 0.0648 - val_loss: 0.0382\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 96us/sample - loss: 0.0752 - val_loss: 0.0379\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 91us/sample - loss: 0.0631 - val_loss: 0.0374\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 97us/sample - loss: 0.0660 - val_loss: 0.0373\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 93us/sample - loss: 0.0699 - val_loss: 0.0371\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 91us/sample - loss: 0.0674 - val_loss: 0.0372\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 105us/sample - loss: 0.0573 - val_loss: 0.0369\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 101us/sample - loss: 0.0618 - val_loss: 0.0364\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 100us/sample - loss: 0.0641 - val_loss: 0.0361\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 78us/sample - loss: 0.0591 - val_loss: 0.0361\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 82us/sample - loss: 0.0599 - val_loss: 0.0361\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 91us/sample - loss: 0.0508 - val_loss: 0.0356\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 81us/sample - loss: 0.0576 - val_loss: 0.0352\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0590 - val_loss: 0.0350\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 83us/sample - loss: 0.0595 - val_loss: 0.0348\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 90us/sample - loss: 0.0542 - val_loss: 0.0342\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 87us/sample - loss: 0.0604 - val_loss: 0.0341\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 83us/sample - loss: 0.0526 - val_loss: 0.0331\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 93us/sample - loss: 0.0486 - val_loss: 0.0326\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 83us/sample - loss: 0.0550 - val_loss: 0.0323\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 86us/sample - loss: 0.0492 - val_loss: 0.0324\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0493 - val_loss: 0.0324\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 97us/sample - loss: 0.0479 - val_loss: 0.0316\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 92us/sample - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 88us/sample - loss: 0.0465 - val_loss: 0.0305\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 103us/sample - loss: 0.0460 - val_loss: 0.0298\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 83us/sample - loss: 0.0437 - val_loss: 0.0296\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 85us/sample - loss: 0.0415 - val_loss: 0.0293\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0434 - val_loss: 0.0291\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0449 - val_loss: 0.0294\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.949 - 0s 875us/sample - loss: 0.7238 - val_loss: 0.5728\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.791 - 0s 118us/sample - loss: 0.6494 - val_loss: 0.5315\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.674 - 0s 110us/sample - loss: 0.6467 - val_loss: 0.4903\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.400 - 0s 95us/sample - loss: 0.6411 - val_loss: 0.4520\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.507 - 0s 99us/sample - loss: 0.5768 - val_loss: 0.4174\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.365 - 0s 104us/sample - loss: 0.5070 - val_loss: 0.3853\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.416 - 0s 93us/sample - loss: 0.4954 - val_loss: 0.3568\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.681 - 0s 91us/sample - loss: 0.4704 - val_loss: 0.3276\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.434 - 0s 95us/sample - loss: 0.4683 - val_loss: 0.3030\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.453 - 0s 93us/sample - loss: 0.4152 - val_loss: 0.2776\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.410 - 0s 96us/sample - loss: 0.3981 - val_loss: 0.2560\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.293 - 0s 103us/sample - loss: 0.3473 - val_loss: 0.2365\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.261 - 0s 100us/sample - loss: 0.3315 - val_loss: 0.2184\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.423 - 0s 98us/sample - loss: 0.3180 - val_loss: 0.2026\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.422 - 0s 103us/sample - loss: 0.2753 - val_loss: 0.1885\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.394 - 0s 98us/sample - loss: 0.2921 - val_loss: 0.1754\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.402 - 0s 96us/sample - loss: 0.2761 - val_loss: 0.1636\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.244 - 0s 98us/sample - loss: 0.2965 - val_loss: 0.1521\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.403 - 0s 100us/sample - loss: 0.2697 - val_loss: 0.1422\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.191 - 0s 98us/sample - loss: 0.2763 - val_loss: 0.1327\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.252 - 0s 96us/sample - loss: 0.2617 - val_loss: 0.1235\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.322 - 0s 98us/sample - loss: 0.2340 - val_loss: 0.1158\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.279 - 0s 96us/sample - loss: 0.2116 - val_loss: 0.1090\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.198 - 0s 113us/sample - loss: 0.2099 - val_loss: 0.1033\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.262 - 0s 127us/sample - loss: 0.2233 - val_loss: 0.0976\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.266 - 0s 115us/sample - loss: 0.2111 - val_loss: 0.0922\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 108us/sample - loss: 0.2106 - val_loss: 0.0873\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.252 - 0s 110us/sample - loss: 0.2098 - val_loss: 0.0831\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 110us/sample - loss: 0.2003 - val_loss: 0.0792\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 115us/sample - loss: 0.1859 - val_loss: 0.0764\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 110us/sample - loss: 0.1525 - val_loss: 0.0744\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.179 - 0s 99us/sample - loss: 0.1931 - val_loss: 0.0716\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 117us/sample - loss: 0.1671 - val_loss: 0.0693\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 93us/sample - loss: 0.1686 - val_loss: 0.0671\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.263 - 0s 93us/sample - loss: 0.1783 - val_loss: 0.0649\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.137 - 0s 114us/sample - loss: 0.1623 - val_loss: 0.0628\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 96us/sample - loss: 0.1583 - val_loss: 0.0610\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.157 - 0s 104us/sample - loss: 0.1421 - val_loss: 0.0595\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.244 - 0s 95us/sample - loss: 0.1562 - val_loss: 0.0582\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 94us/sample - loss: 0.1492 - val_loss: 0.0567\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.212 - 0s 89us/sample - loss: 0.1450 - val_loss: 0.0555\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 99us/sample - loss: 0.1380 - val_loss: 0.0543\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 96us/sample - loss: 0.1528 - val_loss: 0.0531\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 99us/sample - loss: 0.1225 - val_loss: 0.0522\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 103us/sample - loss: 0.1421 - val_loss: 0.0513\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 102us/sample - loss: 0.1350 - val_loss: 0.0505\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 83us/sample - loss: 0.1343 - val_loss: 0.0500\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 86us/sample - loss: 0.1200 - val_loss: 0.0491\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 81us/sample - loss: 0.1347 - val_loss: 0.0481\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 86us/sample - loss: 0.1182 - val_loss: 0.0473\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 93us/sample - loss: 0.1265 - val_loss: 0.0467\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 91us/sample - loss: 0.1228 - val_loss: 0.0462\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 88us/sample - loss: 0.1095 - val_loss: 0.0457\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 91us/sample - loss: 0.1229 - val_loss: 0.0452\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.152 - 0s 88us/sample - loss: 0.1189 - val_loss: 0.0445\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 86us/sample - loss: 0.1011 - val_loss: 0.0439\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 96us/sample - loss: 0.1004 - val_loss: 0.0435\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 87us/sample - loss: 0.0980 - val_loss: 0.0433\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 98us/sample - loss: 0.1112 - val_loss: 0.0429\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 91us/sample - loss: 0.1215 - val_loss: 0.0424\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.1066 - val_loss: 0.0417\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 88us/sample - loss: 0.0953 - val_loss: 0.0412\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 85us/sample - loss: 0.0994 - val_loss: 0.0408\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 93us/sample - loss: 0.0942 - val_loss: 0.0406\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 91us/sample - loss: 0.0916 - val_loss: 0.0404\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 94us/sample - loss: 0.0905 - val_loss: 0.0402\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 103us/sample - loss: 0.0854 - val_loss: 0.0397\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 105us/sample - loss: 0.0843 - val_loss: 0.0392\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.102 - 0s 106us/sample - loss: 0.0926 - val_loss: 0.0386\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 108us/sample - loss: 0.0768 - val_loss: 0.0382\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 99us/sample - loss: 0.0888 - val_loss: 0.0379\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 96us/sample - loss: 0.0885 - val_loss: 0.0376\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 101us/sample - loss: 0.0788 - val_loss: 0.0373\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 99us/sample - loss: 0.0778 - val_loss: 0.0371\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 99us/sample - loss: 0.0759 - val_loss: 0.0368\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 98us/sample - loss: 0.0807 - val_loss: 0.0362\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 91us/sample - loss: 0.0769 - val_loss: 0.0359\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 95us/sample - loss: 0.0801 - val_loss: 0.0355\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 97us/sample - loss: 0.0696 - val_loss: 0.0352\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 91us/sample - loss: 0.0693 - val_loss: 0.0349\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 105us/sample - loss: 0.0670 - val_loss: 0.0346\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0614 - val_loss: 0.0342\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 87us/sample - loss: 0.0715 - val_loss: 0.0340\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 99us/sample - loss: 0.0695 - val_loss: 0.0336\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 93us/sample - loss: 0.0600 - val_loss: 0.0334\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 87us/sample - loss: 0.0605 - val_loss: 0.0334\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 78us/sample - loss: 0.0537 - val_loss: 0.0333\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0669 - val_loss: 0.0330\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 88us/sample - loss: 0.0559 - val_loss: 0.0328\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 82us/sample - loss: 0.0583 - val_loss: 0.0323\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 84us/sample - loss: 0.0587 - val_loss: 0.0321\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 86us/sample - loss: 0.0542 - val_loss: 0.0320\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0557 - val_loss: 0.0317\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 103us/sample - loss: 0.0585 - val_loss: 0.0316\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 86us/sample - loss: 0.0553 - val_loss: 0.0313\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 93us/sample - loss: 0.0507 - val_loss: 0.0311\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0565 - val_loss: 0.0308\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 85us/sample - loss: 0.0504 - val_loss: 0.0304\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 95us/sample - loss: 0.0482 - val_loss: 0.0302\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 91us/sample - loss: 0.0491 - val_loss: 0.0299\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 86us/sample - loss: 0.0517 - val_loss: 0.0295\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0447 - val_loss: 0.0292\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 93us/sample - loss: 0.0479 - val_loss: 0.0289\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 92us/sample - loss: 0.0458 - val_loss: 0.0288\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0442 - val_loss: 0.0285\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 85us/sample - loss: 0.0492 - val_loss: 0.0282\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 84us/sample - loss: 0.0448 - val_loss: 0.0279\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 83us/sample - loss: 0.0481 - val_loss: 0.0277\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 81us/sample - loss: 0.0443 - val_loss: 0.0274\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 94us/sample - loss: 0.0449 - val_loss: 0.0271\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 100us/sample - loss: 0.0375 - val_loss: 0.0270\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 102us/sample - loss: 0.0431 - val_loss: 0.0267\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0428 - val_loss: 0.0265\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 110us/sample - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 108us/sample - loss: 0.0395 - val_loss: 0.0260\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 118us/sample - loss: 0.0405 - val_loss: 0.0258\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 130us/sample - loss: 0.0410 - val_loss: 0.0257\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 106us/sample - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0370 - val_loss: 0.0252\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 112us/sample - loss: 0.0370 - val_loss: 0.0249\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 107us/sample - loss: 0.0326 - val_loss: 0.0247\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 94us/sample - loss: 0.0357 - val_loss: 0.0245\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 96us/sample - loss: 0.0370 - val_loss: 0.0244\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 95us/sample - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 98us/sample - loss: 0.0336 - val_loss: 0.0241\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 94us/sample - loss: 0.0356 - val_loss: 0.0239\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0317 - val_loss: 0.0237\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 96us/sample - loss: 0.0338 - val_loss: 0.0235\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0336 - val_loss: 0.0233\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 98us/sample - loss: 0.0323 - val_loss: 0.0231\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0313 - val_loss: 0.0230\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0309 - val_loss: 0.0228\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0311 - val_loss: 0.0226\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 88us/sample - loss: 0.0302 - val_loss: 0.0224\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 89us/sample - loss: 0.0314 - val_loss: 0.0223\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 86us/sample - loss: 0.0294 - val_loss: 0.0221\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 85us/sample - loss: 0.0289 - val_loss: 0.0219\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0293 - val_loss: 0.0217\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0271 - val_loss: 0.0215\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0278 - val_loss: 0.0214\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 90us/sample - loss: 0.0269 - val_loss: 0.0213\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 87us/sample - loss: 0.0261 - val_loss: 0.0211\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 91us/sample - loss: 0.0266 - val_loss: 0.0208\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 92us/sample - loss: 0.0253 - val_loss: 0.0207\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0259 - val_loss: 0.0204\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0271 - val_loss: 0.0203\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0276 - val_loss: 0.0201\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0251 - val_loss: 0.0200\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 81us/sample - loss: 0.0242 - val_loss: 0.0199\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0255 - val_loss: 0.0197\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.869 - 0s 774us/sample - loss: 1.9626 - val_loss: 1.3089\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 2.002 - 0s 98us/sample - loss: 1.8680 - val_loss: 1.2496\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.426 - 0s 90us/sample - loss: 1.7596 - val_loss: 1.1920\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.799 - 0s 95us/sample - loss: 1.7126 - val_loss: 1.1352\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.600 - 0s 89us/sample - loss: 1.5834 - val_loss: 1.0821\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.348 - 0s 93us/sample - loss: 1.4927 - val_loss: 1.0313\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.476 - 0s 93us/sample - loss: 1.5661 - val_loss: 0.9790\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.057 - 0s 91us/sample - loss: 1.3851 - val_loss: 0.9312\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.453 - 0s 93us/sample - loss: 1.3345 - val_loss: 0.8840\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.506 - 0s 91us/sample - loss: 1.2403 - val_loss: 0.8397\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.110 - 0s 98us/sample - loss: 1.1872 - val_loss: 0.7977\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.160 - 0s 104us/sample - loss: 1.1396 - val_loss: 0.7562\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.102 - 0s 110us/sample - loss: 1.0589 - val_loss: 0.7178\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.152 - 0s 108us/sample - loss: 1.1108 - val_loss: 0.6780\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.040 - 0s 93us/sample - loss: 1.0677 - val_loss: 0.6393\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.850 - 0s 86us/sample - loss: 0.9559 - val_loss: 0.6039\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.011 - 0s 78us/sample - loss: 0.8834 - val_loss: 0.5691\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.681 - 0s 81us/sample - loss: 0.8574 - val_loss: 0.5365\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.905 - 0s 90us/sample - loss: 0.8541 - val_loss: 0.5042\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.121 - 0s 88us/sample - loss: 0.8309 - val_loss: 0.4728\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.882 - 0s 93us/sample - loss: 0.7168 - val_loss: 0.4436\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.559 - 0s 91us/sample - loss: 0.6579 - val_loss: 0.4173\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.762 - 0s 93us/sample - loss: 0.6679 - val_loss: 0.3917\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.747 - 0s 86us/sample - loss: 0.6186 - val_loss: 0.3670\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.424 - 0s 98us/sample - loss: 0.6252 - val_loss: 0.3431\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.723 - 0s 103us/sample - loss: 0.5718 - val_loss: 0.3202\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.619 - 0s 100us/sample - loss: 0.5287 - val_loss: 0.2987\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.662 - 0s 103us/sample - loss: 0.5007 - val_loss: 0.2788\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.625 - 0s 92us/sample - loss: 0.4797 - val_loss: 0.2599\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.534 - 0s 109us/sample - loss: 0.4479 - val_loss: 0.2419\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.360 - 0s 99us/sample - loss: 0.3985 - val_loss: 0.2252\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.257 - 0s 93us/sample - loss: 0.3891 - val_loss: 0.2101\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.481 - 0s 112us/sample - loss: 0.3864 - val_loss: 0.1948\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.419 - 0s 97us/sample - loss: 0.3375 - val_loss: 0.1811\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.427 - 0s 93us/sample - loss: 0.3440 - val_loss: 0.1681\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.245 - 0s 97us/sample - loss: 0.2945 - val_loss: 0.1561\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.350 - 0s 102us/sample - loss: 0.2942 - val_loss: 0.1450\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.250 - 0s 93us/sample - loss: 0.2767 - val_loss: 0.1341\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.113 - 0s 92us/sample - loss: 0.2595 - val_loss: 0.1239\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 90us/sample - loss: 0.2474 - val_loss: 0.1147\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 91us/sample - loss: 0.2254 - val_loss: 0.1060\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 96us/sample - loss: 0.2126 - val_loss: 0.0984\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.210 - 0s 94us/sample - loss: 0.2056 - val_loss: 0.0913\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 93us/sample - loss: 0.2019 - val_loss: 0.0843\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 102us/sample - loss: 0.1964 - val_loss: 0.0778\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 97us/sample - loss: 0.1804 - val_loss: 0.0719\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.225 - 0s 81us/sample - loss: 0.1668 - val_loss: 0.0667\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.213 - 0s 86us/sample - loss: 0.1664 - val_loss: 0.0619\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 88us/sample - loss: 0.1647 - val_loss: 0.0576\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.145 - 0s 85us/sample - loss: 0.1598 - val_loss: 0.0536\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 86us/sample - loss: 0.1337 - val_loss: 0.0500\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 89us/sample - loss: 0.1203 - val_loss: 0.0471\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 91us/sample - loss: 0.1266 - val_loss: 0.0443\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 91us/sample - loss: 0.1197 - val_loss: 0.0417\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 89us/sample - loss: 0.1265 - val_loss: 0.0393\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 88us/sample - loss: 0.1193 - val_loss: 0.0368\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 89us/sample - loss: 0.1228 - val_loss: 0.0348\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 82us/sample - loss: 0.1067 - val_loss: 0.0330\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 80us/sample - loss: 0.1122 - val_loss: 0.0315\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 95us/sample - loss: 0.1091 - val_loss: 0.0300\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 88us/sample - loss: 0.0952 - val_loss: 0.0286\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 93us/sample - loss: 0.1018 - val_loss: 0.0276\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 90us/sample - loss: 0.0950 - val_loss: 0.0267\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 103us/sample - loss: 0.1014 - val_loss: 0.0257\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 100us/sample - loss: 0.0924 - val_loss: 0.0248\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 91us/sample - loss: 0.0910 - val_loss: 0.0242\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 99us/sample - loss: 0.0792 - val_loss: 0.0237\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 91us/sample - loss: 0.0896 - val_loss: 0.0232\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 108us/sample - loss: 0.0892 - val_loss: 0.0228\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 111us/sample - loss: 0.0822 - val_loss: 0.0225\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 108us/sample - loss: 0.0904 - val_loss: 0.0222\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 88us/sample - loss: 0.0803 - val_loss: 0.0219\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 102us/sample - loss: 0.0807 - val_loss: 0.0216\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.186 - 0s 96us/sample - loss: 0.0864 - val_loss: 0.0214\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 96us/sample - loss: 0.0793 - val_loss: 0.0212\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 88us/sample - loss: 0.0831 - val_loss: 0.0210\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 104us/sample - loss: 0.0737 - val_loss: 0.0209\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 107us/sample - loss: 0.0772 - val_loss: 0.0208\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 113us/sample - loss: 0.0765 - val_loss: 0.0207\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 96us/sample - loss: 0.0706 - val_loss: 0.0206\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 103us/sample - loss: 0.0772 - val_loss: 0.0205\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 107us/sample - loss: 0.0749 - val_loss: 0.0204\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 117us/sample - loss: 0.0724 - val_loss: 0.0203\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 110us/sample - loss: 0.0699 - val_loss: 0.0202\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 99us/sample - loss: 0.0827 - val_loss: 0.0201\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 92us/sample - loss: 0.0706 - val_loss: 0.0201\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 96us/sample - loss: 0.0709 - val_loss: 0.0200\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0657 - val_loss: 0.0199\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 88us/sample - loss: 0.0618 - val_loss: 0.0199\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 78us/sample - loss: 0.0640 - val_loss: 0.0198\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 109us/sample - loss: 0.0668 - val_loss: 0.0197\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 84us/sample - loss: 0.0734 - val_loss: 0.0196\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 86us/sample - loss: 0.0671 - val_loss: 0.0196\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 91us/sample - loss: 0.0687 - val_loss: 0.0195\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 81us/sample - loss: 0.0601 - val_loss: 0.0194\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 86us/sample - loss: 0.0661 - val_loss: 0.0194\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 89us/sample - loss: 0.0692 - val_loss: 0.0193\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 83us/sample - loss: 0.0651 - val_loss: 0.0192\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 93us/sample - loss: 0.0612 - val_loss: 0.0191\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0591 - val_loss: 0.0191\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 88us/sample - loss: 0.0640 - val_loss: 0.0190\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 91us/sample - loss: 0.0562 - val_loss: 0.0189\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 88us/sample - loss: 0.0628 - val_loss: 0.0188\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 84us/sample - loss: 0.0638 - val_loss: 0.0188\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 86us/sample - loss: 0.0573 - val_loss: 0.0187\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0626 - val_loss: 0.0186\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 88us/sample - loss: 0.0614 - val_loss: 0.0185\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 108us/sample - loss: 0.0591 - val_loss: 0.0184\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 93us/sample - loss: 0.0602 - val_loss: 0.0184\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0498 - val_loss: 0.0183\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 91us/sample - loss: 0.0561 - val_loss: 0.0182\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 94us/sample - loss: 0.0593 - val_loss: 0.0181\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 109us/sample - loss: 0.0564 - val_loss: 0.0180\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 105us/sample - loss: 0.0576 - val_loss: 0.0179\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 100us/sample - loss: 0.0549 - val_loss: 0.0178\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 101us/sample - loss: 0.0590 - val_loss: 0.0177\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 86us/sample - loss: 0.0522 - val_loss: 0.0176\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 91us/sample - loss: 0.0519 - val_loss: 0.0175\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 98us/sample - loss: 0.0558 - val_loss: 0.0174\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 89us/sample - loss: 0.0519 - val_loss: 0.0173\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 100us/sample - loss: 0.0527 - val_loss: 0.0172\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 95us/sample - loss: 0.0528 - val_loss: 0.0171\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 103us/sample - loss: 0.0450 - val_loss: 0.0170\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 105us/sample - loss: 0.0538 - val_loss: 0.0169\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 106us/sample - loss: 0.0523 - val_loss: 0.0168\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 98us/sample - loss: 0.0498 - val_loss: 0.0166\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 91us/sample - loss: 0.0475 - val_loss: 0.0166\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 89us/sample - loss: 0.0424 - val_loss: 0.0165\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 98us/sample - loss: 0.0469 - val_loss: 0.0164\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 105us/sample - loss: 0.0465 - val_loss: 0.0162\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0454 - val_loss: 0.0161\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0425 - val_loss: 0.0160\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0453 - val_loss: 0.0160\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 88us/sample - loss: 0.0454 - val_loss: 0.0158\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 82us/sample - loss: 0.0452 - val_loss: 0.0157\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 83us/sample - loss: 0.0456 - val_loss: 0.0156\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 147us/sample - loss: 0.0452 - val_loss: 0.0328\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 132us/sample - loss: 0.0471 - val_loss: 0.0327\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 100us/sample - loss: 0.0447 - val_loss: 0.0324\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0452 - val_loss: 0.0320\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 110us/sample - loss: 0.0469 - val_loss: 0.0317\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 99us/sample - loss: 0.0451 - val_loss: 0.0315\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 146us/sample - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 128us/sample - loss: 0.0403 - val_loss: 0.0310\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 127us/sample - loss: 0.0418 - val_loss: 0.0306\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 127us/sample - loss: 0.0412 - val_loss: 0.0303\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 108us/sample - loss: 0.0399 - val_loss: 0.0300\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 118us/sample - loss: 0.0401 - val_loss: 0.0297\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 113us/sample - loss: 0.0391 - val_loss: 0.0296\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 125us/sample - loss: 0.0394 - val_loss: 0.0294\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 130us/sample - loss: 0.0390 - val_loss: 0.0291\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 103us/sample - loss: 0.0392 - val_loss: 0.0289\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 118us/sample - loss: 0.0430 - val_loss: 0.0288\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 115us/sample - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 110us/sample - loss: 0.0377 - val_loss: 0.0281\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 140us/sample - loss: 0.0350 - val_loss: 0.0279\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 167us/sample - loss: 0.0378 - val_loss: 0.0276\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.034 - 0s 194us/sample - loss: 0.0348 - val_loss: 0.0273\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 169us/sample - loss: 0.0347 - val_loss: 0.0271\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 137us/sample - loss: 0.0346 - val_loss: 0.0268\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 118us/sample - loss: 0.0354 - val_loss: 0.0268\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 125us/sample - loss: 0.0341 - val_loss: 0.0266\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 130us/sample - loss: 0.0336 - val_loss: 0.0264\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0319 - val_loss: 0.0261\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 120us/sample - loss: 0.0330 - val_loss: 0.0258\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 118us/sample - loss: 0.0333 - val_loss: 0.0257\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 124us/sample - loss: 0.0326 - val_loss: 0.0255\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0322 - val_loss: 0.0254\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 113us/sample - loss: 0.0318 - val_loss: 0.0253\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 108us/sample - loss: 0.0299 - val_loss: 0.0250\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0294 - val_loss: 0.0247\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 102us/sample - loss: 0.0312 - val_loss: 0.0245\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0283 - val_loss: 0.0243\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 96us/sample - loss: 0.0292 - val_loss: 0.0241\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 115us/sample - loss: 0.0300 - val_loss: 0.0239\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 120us/sample - loss: 0.0289 - val_loss: 0.0237\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 100us/sample - loss: 0.0296 - val_loss: 0.0235\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 172us/sample - loss: 0.0275 - val_loss: 0.0231\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.026 - 0s 223us/sample - loss: 0.0274 - val_loss: 0.0230\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - ETA: 0s - loss: 0.025 - 0s 206us/sample - loss: 0.0260 - val_loss: 0.0229\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.025 - 0s 216us/sample - loss: 0.0249 - val_loss: 0.0227\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 169us/sample - loss: 0.0264 - val_loss: 0.0225\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - ETA: 0s - loss: 0.025 - 0s 218us/sample - loss: 0.0263 - val_loss: 0.0223\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 138us/sample - loss: 0.0250 - val_loss: 0.0220\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 163us/sample - loss: 0.0255 - val_loss: 0.0218\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 169us/sample - loss: 0.0271 - val_loss: 0.0218\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 169us/sample - loss: 0.0249 - val_loss: 0.0216\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 159us/sample - loss: 0.0255 - val_loss: 0.0215\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 167us/sample - loss: 0.0226 - val_loss: 0.0213\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 145us/sample - loss: 0.0236 - val_loss: 0.0210\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - ETA: 0s - loss: 0.022 - 0s 221us/sample - loss: 0.0221 - val_loss: 0.0208\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - ETA: 0s - loss: 0.024 - 0s 248us/sample - loss: 0.0229 - val_loss: 0.0205\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - ETA: 0s - loss: 0.022 - 0s 196us/sample - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 157us/sample - loss: 0.0228 - val_loss: 0.0201\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 166us/sample - loss: 0.0224 - val_loss: 0.0199\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 162us/sample - loss: 0.0224 - val_loss: 0.0197\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 149us/sample - loss: 0.0220 - val_loss: 0.0195\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 154us/sample - loss: 0.0207 - val_loss: 0.0192\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 159us/sample - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 167us/sample - loss: 0.0199 - val_loss: 0.0188\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - ETA: 0s - loss: 0.020 - 0s 203us/sample - loss: 0.0208 - val_loss: 0.0186\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.021 - 0s 213us/sample - loss: 0.0200 - val_loss: 0.0184\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 135us/sample - loss: 0.0210 - val_loss: 0.0182\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 146us/sample - loss: 0.0197 - val_loss: 0.0180\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 135us/sample - loss: 0.0203 - val_loss: 0.0178\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 135us/sample - loss: 0.0200 - val_loss: 0.0176\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0192 - val_loss: 0.0173\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 154us/sample - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 108us/sample - loss: 0.0193 - val_loss: 0.0170\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0192 - val_loss: 0.0168\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0180 - val_loss: 0.0166\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0177 - val_loss: 0.0164\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0162\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 135us/sample - loss: 0.0170 - val_loss: 0.0160\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0180 - val_loss: 0.0158\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0170 - val_loss: 0.0157\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 79us/sample - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0161 - val_loss: 0.0147\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 101us/sample - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0154 - val_loss: 0.0143\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0157 - val_loss: 0.0141\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0140\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 110us/sample - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 119us/sample - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0140 - val_loss: 0.0128\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 108us/sample - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 117us/sample - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 111us/sample - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 132us/sample - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 104us/sample - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0100\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 1.525 - 0s 810us/sample - loss: 1.3355 - val_loss: 1.1781\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.059 - 0s 115us/sample - loss: 1.3421 - val_loss: 1.1109\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.165 - 0s 103us/sample - loss: 1.2602 - val_loss: 1.0465\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.583 - 0s 113us/sample - loss: 1.1338 - val_loss: 0.9899\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.914 - 0s 96us/sample - loss: 1.1150 - val_loss: 0.9349\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.010 - 0s 88us/sample - loss: 1.0627 - val_loss: 0.8823\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.007 - 0s 101us/sample - loss: 1.0922 - val_loss: 0.8312\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.152 - 0s 82us/sample - loss: 0.9836 - val_loss: 0.7837\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.951 - 0s 103us/sample - loss: 0.9127 - val_loss: 0.7393\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 1.016 - 0s 120us/sample - loss: 0.8415 - val_loss: 0.6983\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.711 - 0s 100us/sample - loss: 0.8031 - val_loss: 0.6592\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.635 - 0s 113us/sample - loss: 0.7858 - val_loss: 0.6215\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.913 - 0s 108us/sample - loss: 0.7243 - val_loss: 0.5848\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.657 - 0s 96us/sample - loss: 0.7177 - val_loss: 0.5503\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.569 - 0s 97us/sample - loss: 0.7045 - val_loss: 0.5156\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.713 - 0s 83us/sample - loss: 0.6488 - val_loss: 0.4833\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.565 - 0s 89us/sample - loss: 0.5937 - val_loss: 0.4538\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.515 - 0s 98us/sample - loss: 0.5556 - val_loss: 0.4262\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.533 - 0s 101us/sample - loss: 0.5626 - val_loss: 0.4004\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.517 - 0s 118us/sample - loss: 0.5266 - val_loss: 0.3760\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.477 - 0s 105us/sample - loss: 0.4977 - val_loss: 0.3536\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.435 - 0s 125us/sample - loss: 0.4709 - val_loss: 0.3320\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.472 - 0s 114us/sample - loss: 0.4729 - val_loss: 0.3102\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.401 - 0s 93us/sample - loss: 0.4038 - val_loss: 0.2900\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.556 - 0s 86us/sample - loss: 0.4054 - val_loss: 0.2722\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.387 - 0s 135us/sample - loss: 0.3634 - val_loss: 0.2553\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.472 - 0s 123us/sample - loss: 0.3794 - val_loss: 0.2387\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.294 - 0s 120us/sample - loss: 0.3676 - val_loss: 0.2243\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.303 - 0s 120us/sample - loss: 0.3296 - val_loss: 0.2097\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.248 - 0s 109us/sample - loss: 0.3412 - val_loss: 0.1958\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.322 - 0s 104us/sample - loss: 0.3355 - val_loss: 0.1836\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.244 - 0s 104us/sample - loss: 0.2893 - val_loss: 0.1709\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.255 - 0s 100us/sample - loss: 0.2641 - val_loss: 0.1600\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 93us/sample - loss: 0.3271 - val_loss: 0.1492\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.234 - 0s 117us/sample - loss: 0.2754 - val_loss: 0.1391\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.367 - 0s 105us/sample - loss: 0.2522 - val_loss: 0.1301\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.297 - 0s 105us/sample - loss: 0.2543 - val_loss: 0.1221\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.259 - 0s 105us/sample - loss: 0.2524 - val_loss: 0.1154\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.203 - 0s 108us/sample - loss: 0.2441 - val_loss: 0.1082\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 103us/sample - loss: 0.2223 - val_loss: 0.1026\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.154 - 0s 105us/sample - loss: 0.2338 - val_loss: 0.0977\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.331 - 0s 100us/sample - loss: 0.2231 - val_loss: 0.0930\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 100us/sample - loss: 0.2203 - val_loss: 0.0885\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.335 - 0s 105us/sample - loss: 0.2239 - val_loss: 0.0841\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.201 - 0s 130us/sample - loss: 0.1848 - val_loss: 0.0796\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 120us/sample - loss: 0.1818 - val_loss: 0.0759\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.300 - 0s 115us/sample - loss: 0.1954 - val_loss: 0.0722\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.256 - 0s 103us/sample - loss: 0.1982 - val_loss: 0.0691\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.160 - 0s 103us/sample - loss: 0.1901 - val_loss: 0.0664\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.227 - 0s 99us/sample - loss: 0.1887 - val_loss: 0.0636\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.171 - 0s 86us/sample - loss: 0.1807 - val_loss: 0.0614\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.249 - 0s 87us/sample - loss: 0.1755 - val_loss: 0.0594\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 98us/sample - loss: 0.1663 - val_loss: 0.0575\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.309 - 0s 91us/sample - loss: 0.1711 - val_loss: 0.0552\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 93us/sample - loss: 0.1800 - val_loss: 0.0531\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.173 - 0s 103us/sample - loss: 0.1784 - val_loss: 0.0517\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 86us/sample - loss: 0.1733 - val_loss: 0.0505\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 96us/sample - loss: 0.1501 - val_loss: 0.0497\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 96us/sample - loss: 0.1618 - val_loss: 0.0487\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 96us/sample - loss: 0.1533 - val_loss: 0.0480\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.247 - 0s 89us/sample - loss: 0.1469 - val_loss: 0.0471\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.144 - 0s 95us/sample - loss: 0.1455 - val_loss: 0.0463\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.299 - 0s 85us/sample - loss: 0.1557 - val_loss: 0.0455\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.153 - 0s 93us/sample - loss: 0.1567 - val_loss: 0.0448\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.128 - 0s 88us/sample - loss: 0.1542 - val_loss: 0.0440\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 83us/sample - loss: 0.1551 - val_loss: 0.0431\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.215 - 0s 93us/sample - loss: 0.1460 - val_loss: 0.0422\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 83us/sample - loss: 0.1324 - val_loss: 0.0414\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.218 - 0s 88us/sample - loss: 0.1425 - val_loss: 0.0409\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.153 - 0s 103us/sample - loss: 0.1342 - val_loss: 0.0403\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.184 - 0s 83us/sample - loss: 0.1600 - val_loss: 0.0399\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 84us/sample - loss: 0.1509 - val_loss: 0.0398\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 95us/sample - loss: 0.1443 - val_loss: 0.0396\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.137 - 0s 113us/sample - loss: 0.1469 - val_loss: 0.0391\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.238 - 0s 109us/sample - loss: 0.1299 - val_loss: 0.0386\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 112us/sample - loss: 0.1195 - val_loss: 0.0380\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 110us/sample - loss: 0.1264 - val_loss: 0.0376\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 130us/sample - loss: 0.1283 - val_loss: 0.0374\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 118us/sample - loss: 0.1273 - val_loss: 0.0370\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 117us/sample - loss: 0.1306 - val_loss: 0.0366\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 110us/sample - loss: 0.1121 - val_loss: 0.0363\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.117 - 0s 103us/sample - loss: 0.1167 - val_loss: 0.0357\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 146us/sample - loss: 0.1202 - val_loss: 0.0357\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 125us/sample - loss: 0.1141 - val_loss: 0.0355\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 127us/sample - loss: 0.1199 - val_loss: 0.0349\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 123us/sample - loss: 0.1007 - val_loss: 0.0344\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 112us/sample - loss: 0.1137 - val_loss: 0.0343\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 142us/sample - loss: 0.1041 - val_loss: 0.0341\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.132 - 0s 115us/sample - loss: 0.0939 - val_loss: 0.0341\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 113us/sample - loss: 0.1067 - val_loss: 0.0339\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 115us/sample - loss: 0.1053 - val_loss: 0.0337\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 96us/sample - loss: 0.0923 - val_loss: 0.0336\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 93us/sample - loss: 0.0938 - val_loss: 0.0336\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 154us/sample - loss: 0.0929 - val_loss: 0.0332\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 127us/sample - loss: 0.0854 - val_loss: 0.0330\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.176 - 0s 115us/sample - loss: 0.1034 - val_loss: 0.0328\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 115us/sample - loss: 0.1009 - val_loss: 0.0325\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 122us/sample - loss: 0.0875 - val_loss: 0.0325\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 94us/sample - loss: 0.0882 - val_loss: 0.0322\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 97us/sample - loss: 0.0842 - val_loss: 0.0322\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 103us/sample - loss: 0.0879 - val_loss: 0.0321\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 96us/sample - loss: 0.0890 - val_loss: 0.0321\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 100us/sample - loss: 0.0817 - val_loss: 0.0318\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 116us/sample - loss: 0.0833 - val_loss: 0.0317\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 98us/sample - loss: 0.0792 - val_loss: 0.0314\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 100us/sample - loss: 0.0886 - val_loss: 0.0311\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 98us/sample - loss: 0.0890 - val_loss: 0.0311\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 113us/sample - loss: 0.0775 - val_loss: 0.0310\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 98us/sample - loss: 0.0803 - val_loss: 0.0310\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 96us/sample - loss: 0.0757 - val_loss: 0.0308\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 115us/sample - loss: 0.0786 - val_loss: 0.0307\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0778 - val_loss: 0.0306\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 96us/sample - loss: 0.0709 - val_loss: 0.0301\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 99us/sample - loss: 0.0719 - val_loss: 0.0298\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 102us/sample - loss: 0.0730 - val_loss: 0.0298\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 98us/sample - loss: 0.0732 - val_loss: 0.0296\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 103us/sample - loss: 0.0720 - val_loss: 0.0293\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 113us/sample - loss: 0.0653 - val_loss: 0.0292\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 105us/sample - loss: 0.0700 - val_loss: 0.0292\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 125us/sample - loss: 0.0628 - val_loss: 0.0290\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 122us/sample - loss: 0.0677 - val_loss: 0.0291\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 113us/sample - loss: 0.0635 - val_loss: 0.0291\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 118us/sample - loss: 0.0615 - val_loss: 0.0291\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 110us/sample - loss: 0.0594 - val_loss: 0.0288\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 104us/sample - loss: 0.0544 - val_loss: 0.0287\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 99us/sample - loss: 0.0570 - val_loss: 0.0284\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 115us/sample - loss: 0.0609 - val_loss: 0.0281\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 135us/sample - loss: 0.0607 - val_loss: 0.0278\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 118us/sample - loss: 0.0563 - val_loss: 0.0277\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 110us/sample - loss: 0.0604 - val_loss: 0.0274\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 97us/sample - loss: 0.0589 - val_loss: 0.0272\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 96us/sample - loss: 0.0521 - val_loss: 0.0270\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 96us/sample - loss: 0.0531 - val_loss: 0.0272\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 91us/sample - loss: 0.0556 - val_loss: 0.0270\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 95us/sample - loss: 0.0517 - val_loss: 0.0269\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 115us/sample - loss: 0.0498 - val_loss: 0.0267\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.0496 - val_loss: 0.0265\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 99us/sample - loss: 0.0463 - val_loss: 0.0262\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 102us/sample - loss: 0.0525 - val_loss: 0.0262\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 115us/sample - loss: 0.0469 - val_loss: 0.0260\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 125us/sample - loss: 0.0501 - val_loss: 0.0259\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 114us/sample - loss: 0.0506 - val_loss: 0.0258\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 113us/sample - loss: 0.0474 - val_loss: 0.0257\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0503 - val_loss: 0.0256\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 88us/sample - loss: 0.0466 - val_loss: 0.0256\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 96us/sample - loss: 0.0459 - val_loss: 0.0253\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 86us/sample - loss: 0.0485 - val_loss: 0.0252\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0400 - val_loss: 0.0249\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 105us/sample - loss: 0.0440 - val_loss: 0.0246\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 86us/sample - loss: 0.0428 - val_loss: 0.0245\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.796 - 0s 897us/sample - loss: 0.7241 - val_loss: 0.4433\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.745 - 0s 110us/sample - loss: 0.6979 - val_loss: 0.4115\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.551 - 0s 118us/sample - loss: 0.6741 - val_loss: 0.3820\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.625 - 0s 108us/sample - loss: 0.6382 - val_loss: 0.3546\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.737 - 0s 132us/sample - loss: 0.5723 - val_loss: 0.3289\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.511 - ETA: 0s - loss: 0.563 - 0s 216us/sample - loss: 0.5654 - val_loss: 0.3047\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.609 - 0s 166us/sample - loss: 0.5272 - val_loss: 0.2815\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.571 - ETA: 0s - loss: 0.476 - 0s 208us/sample - loss: 0.4748 - val_loss: 0.2605\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.477 - ETA: 0s - loss: 0.452 - 0s 221us/sample - loss: 0.4397 - val_loss: 0.2409\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.408 - 0s 174us/sample - loss: 0.4597 - val_loss: 0.2221\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.512 - 0s 172us/sample - loss: 0.4230 - val_loss: 0.2035\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.340 - 0s 152us/sample - loss: 0.3600 - val_loss: 0.1875\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.398 - 0s 142us/sample - loss: 0.3956 - val_loss: 0.1720\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.375 - 0s 157us/sample - loss: 0.3582 - val_loss: 0.1575\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.291 - 0s 164us/sample - loss: 0.3102 - val_loss: 0.1445\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.241 - 0s 129us/sample - loss: 0.3081 - val_loss: 0.1326\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 162us/sample - loss: 0.2980 - val_loss: 0.1215\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.362 - 0s 135us/sample - loss: 0.3004 - val_loss: 0.1111\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.174 - 0s 108us/sample - loss: 0.2650 - val_loss: 0.1014\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.271 - 0s 120us/sample - loss: 0.2598 - val_loss: 0.0924\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.217 - 0s 171us/sample - loss: 0.2360 - val_loss: 0.0843\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.223 - 0s 171us/sample - loss: 0.2103 - val_loss: 0.0769\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 147us/sample - loss: 0.2002 - val_loss: 0.0709\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.284 - 0s 152us/sample - loss: 0.2007 - val_loss: 0.0653\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.150 - 0s 172us/sample - loss: 0.1912 - val_loss: 0.0602\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.254 - 0s 146us/sample - loss: 0.1940 - val_loss: 0.0557\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.187 - 0s 123us/sample - loss: 0.1896 - val_loss: 0.0516\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 127us/sample - loss: 0.1527 - val_loss: 0.0483\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 105us/sample - loss: 0.1645 - val_loss: 0.0452\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.189 - 0s 103us/sample - loss: 0.1468 - val_loss: 0.0426\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 93us/sample - loss: 0.1497 - val_loss: 0.0404\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 100us/sample - loss: 0.1535 - val_loss: 0.0384\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.174 - 0s 126us/sample - loss: 0.1344 - val_loss: 0.0367\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.121 - 0s 105us/sample - loss: 0.1370 - val_loss: 0.0353\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 113us/sample - loss: 0.1203 - val_loss: 0.0343\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 112us/sample - loss: 0.1197 - val_loss: 0.0334\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.130 - 0s 154us/sample - loss: 0.1257 - val_loss: 0.0327\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 120us/sample - loss: 0.1170 - val_loss: 0.0322\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 125us/sample - loss: 0.1073 - val_loss: 0.0318\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 108us/sample - loss: 0.1047 - val_loss: 0.0315\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 130us/sample - loss: 0.1108 - val_loss: 0.0313\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 105us/sample - loss: 0.1115 - val_loss: 0.0311\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 110us/sample - loss: 0.0905 - val_loss: 0.0310\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 120us/sample - loss: 0.1007 - val_loss: 0.0309\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.135 - 0s 118us/sample - loss: 0.0945 - val_loss: 0.0308\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.112 - 0s 108us/sample - loss: 0.0999 - val_loss: 0.0308\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 113us/sample - loss: 0.1042 - val_loss: 0.0309\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.091 - 0s 113us/sample - loss: 0.0995 - val_loss: 0.0308\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.082 - 0s 140us/sample - loss: 0.0895 - val_loss: 0.0308\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 106us/sample - loss: 0.0976 - val_loss: 0.0308\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 91us/sample - loss: 0.0851 - val_loss: 0.0308\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.139 - 0s 95us/sample - loss: 0.0947 - val_loss: 0.0307\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.128 - 0s 83us/sample - loss: 0.0862 - val_loss: 0.0307\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 96us/sample - loss: 0.0925 - val_loss: 0.0309\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 95us/sample - loss: 0.0805 - val_loss: 0.0310\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 97us/sample - loss: 0.0764 - val_loss: 0.0311\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 108us/sample - loss: 0.0917 - val_loss: 0.0311\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 105us/sample - loss: 0.0842 - val_loss: 0.0312\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 110us/sample - loss: 0.0810 - val_loss: 0.0312\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 108us/sample - loss: 0.0873 - val_loss: 0.0313\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 86us/sample - loss: 0.0786 - val_loss: 0.0314\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 85us/sample - loss: 0.0764 - val_loss: 0.0312\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 88us/sample - loss: 0.0758 - val_loss: 0.0312\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 91us/sample - loss: 0.0729 - val_loss: 0.0313\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0745 - val_loss: 0.0312\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 96us/sample - loss: 0.0713 - val_loss: 0.0313\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 102us/sample - loss: 0.0756 - val_loss: 0.0311\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 99us/sample - loss: 0.0612 - val_loss: 0.0310\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 100us/sample - loss: 0.0729 - val_loss: 0.0305\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0669 - val_loss: 0.0304\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 98us/sample - loss: 0.0659 - val_loss: 0.0302\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 105us/sample - loss: 0.0606 - val_loss: 0.0301\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 135us/sample - loss: 0.0633 - val_loss: 0.0302\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 135us/sample - loss: 0.0590 - val_loss: 0.0299\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 108us/sample - loss: 0.0671 - val_loss: 0.0298\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 105us/sample - loss: 0.0678 - val_loss: 0.0296\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 109us/sample - loss: 0.0569 - val_loss: 0.0294\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.077 - 0s 99us/sample - loss: 0.0675 - val_loss: 0.0292\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0554 - val_loss: 0.0288\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 113us/sample - loss: 0.0584 - val_loss: 0.0286\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 104us/sample - loss: 0.0598 - val_loss: 0.0284\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 107us/sample - loss: 0.0589 - val_loss: 0.0283\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 115us/sample - loss: 0.0587 - val_loss: 0.0279\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 118us/sample - loss: 0.0581 - val_loss: 0.0274\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 109us/sample - loss: 0.0498 - val_loss: 0.0271\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 113us/sample - loss: 0.0580 - val_loss: 0.0269\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 118us/sample - loss: 0.0525 - val_loss: 0.0268\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 109us/sample - loss: 0.0548 - val_loss: 0.0268\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 125us/sample - loss: 0.0547 - val_loss: 0.0267\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 116us/sample - loss: 0.0489 - val_loss: 0.0266\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 115us/sample - loss: 0.0571 - val_loss: 0.0264\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 122us/sample - loss: 0.0487 - val_loss: 0.0263\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 101us/sample - loss: 0.0515 - val_loss: 0.0261\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 103us/sample - loss: 0.0462 - val_loss: 0.0259\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 130us/sample - loss: 0.0517 - val_loss: 0.0256\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 110us/sample - loss: 0.0446 - val_loss: 0.0254\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 104us/sample - loss: 0.0488 - val_loss: 0.0249\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 113us/sample - loss: 0.0461 - val_loss: 0.0246\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 98us/sample - loss: 0.0457 - val_loss: 0.0243\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 100us/sample - loss: 0.0455 - val_loss: 0.0241\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 78us/sample - loss: 0.0452 - val_loss: 0.0241\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 81us/sample - loss: 0.0481 - val_loss: 0.0239\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 94us/sample - loss: 0.0450 - val_loss: 0.0236\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 113us/sample - loss: 0.0399 - val_loss: 0.0234\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 107us/sample - loss: 0.0404 - val_loss: 0.0232\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 147us/sample - loss: 0.0405 - val_loss: 0.0230\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 179us/sample - loss: 0.0421 - val_loss: 0.0226\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - ETA: 0s - loss: 0.038 - 0s 213us/sample - loss: 0.0389 - val_loss: 0.0221\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 145us/sample - loss: 0.0402 - val_loss: 0.0218\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 124us/sample - loss: 0.0388 - val_loss: 0.0216\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 103us/sample - loss: 0.0413 - val_loss: 0.0213\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 119us/sample - loss: 0.0382 - val_loss: 0.0211\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 101us/sample - loss: 0.0358 - val_loss: 0.0209\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0366 - val_loss: 0.0207\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 88us/sample - loss: 0.0337 - val_loss: 0.0205\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 117us/sample - loss: 0.0330 - val_loss: 0.0202\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 108us/sample - loss: 0.0360 - val_loss: 0.0201\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 110us/sample - loss: 0.0315 - val_loss: 0.0198\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0347 - val_loss: 0.0196\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 125us/sample - loss: 0.0315 - val_loss: 0.0193\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 149us/sample - loss: 0.0339 - val_loss: 0.0191\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 117us/sample - loss: 0.0306 - val_loss: 0.0188\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 114us/sample - loss: 0.0357 - val_loss: 0.0185\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 108us/sample - loss: 0.0317 - val_loss: 0.0183\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 102us/sample - loss: 0.0319 - val_loss: 0.0182\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 115us/sample - loss: 0.0352 - val_loss: 0.0178\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0309 - val_loss: 0.0173\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 118us/sample - loss: 0.0291 - val_loss: 0.0171\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 108us/sample - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0299 - val_loss: 0.0167\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 103us/sample - loss: 0.0286 - val_loss: 0.0165\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 123us/sample - loss: 0.0277 - val_loss: 0.0162\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 128us/sample - loss: 0.0270 - val_loss: 0.0161\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 103us/sample - loss: 0.0243 - val_loss: 0.0159\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0279 - val_loss: 0.0157\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 92us/sample - loss: 0.0289 - val_loss: 0.0155\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0271 - val_loss: 0.0153\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0230 - val_loss: 0.0151\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 101us/sample - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 118us/sample - loss: 0.0240 - val_loss: 0.0149\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 105us/sample - loss: 0.0271 - val_loss: 0.0147\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0258 - val_loss: 0.0145\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0237 - val_loss: 0.0144\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0244 - val_loss: 0.0143\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0219 - val_loss: 0.0142\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 120us/sample - loss: 0.0252 - val_loss: 0.0141\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0236 - val_loss: 0.0140\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0213 - val_loss: 0.0138\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0234 - val_loss: 0.0136\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 2s - loss: 0.827 - 0s 848us/sample - loss: 0.8688 - val_loss: 0.2919\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.797 - 0s 103us/sample - loss: 0.8463 - val_loss: 0.2700\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.832 - 0s 96us/sample - loss: 0.8143 - val_loss: 0.2492\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.903 - 0s 98us/sample - loss: 0.8093 - val_loss: 0.2295\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.727 - 0s 102us/sample - loss: 0.7688 - val_loss: 0.2113\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.798 - 0s 91us/sample - loss: 0.7500 - val_loss: 0.1947\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.756 - 0s 102us/sample - loss: 0.6644 - val_loss: 0.1811\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.493 - 0s 111us/sample - loss: 0.6856 - val_loss: 0.1677\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.610 - 0s 113us/sample - loss: 0.6504 - val_loss: 0.1550\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.489 - 0s 110us/sample - loss: 0.6230 - val_loss: 0.1433\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.445 - 0s 98us/sample - loss: 0.6036 - val_loss: 0.1328\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.462 - 0s 95us/sample - loss: 0.6066 - val_loss: 0.1215\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.570 - 0s 105us/sample - loss: 0.6072 - val_loss: 0.1103\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.546 - 0s 99us/sample - loss: 0.5545 - val_loss: 0.0999\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.562 - 0s 86us/sample - loss: 0.5288 - val_loss: 0.0910\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.464 - 0s 98us/sample - loss: 0.5536 - val_loss: 0.0834\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.450 - 0s 92us/sample - loss: 0.5137 - val_loss: 0.0769\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.471 - 0s 83us/sample - loss: 0.5015 - val_loss: 0.0711\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.583 - 0s 88us/sample - loss: 0.4459 - val_loss: 0.0660\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.506 - 0s 108us/sample - loss: 0.4915 - val_loss: 0.0615\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.290 - 0s 98us/sample - loss: 0.4659 - val_loss: 0.0573\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.483 - 0s 113us/sample - loss: 0.4323 - val_loss: 0.0529\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.455 - 0s 81us/sample - loss: 0.4350 - val_loss: 0.0492\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.654 - 0s 102us/sample - loss: 0.4336 - val_loss: 0.0469\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.317 - 0s 98us/sample - loss: 0.4356 - val_loss: 0.0446\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.510 - 0s 110us/sample - loss: 0.4127 - val_loss: 0.0423\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.483 - 0s 88us/sample - loss: 0.3870 - val_loss: 0.0401\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.295 - 0s 91us/sample - loss: 0.3238 - val_loss: 0.0377\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.235 - 0s 92us/sample - loss: 0.4017 - val_loss: 0.0358\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.319 - 0s 95us/sample - loss: 0.3843 - val_loss: 0.0348\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.424 - 0s 100us/sample - loss: 0.4089 - val_loss: 0.0337\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.422 - 0s 98us/sample - loss: 0.4195 - val_loss: 0.0331\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.533 - 0s 96us/sample - loss: 0.3662 - val_loss: 0.0322\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.493 - 0s 85us/sample - loss: 0.3719 - val_loss: 0.0317\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.242 - 0s 88us/sample - loss: 0.3671 - val_loss: 0.0311\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.280 - 0s 81us/sample - loss: 0.3356 - val_loss: 0.0302\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.219 - 0s 102us/sample - loss: 0.3619 - val_loss: 0.0297\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.474 - 0s 98us/sample - loss: 0.3425 - val_loss: 0.0291\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.311 - 0s 93us/sample - loss: 0.3339 - val_loss: 0.0286\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.542 - 0s 108us/sample - loss: 0.3196 - val_loss: 0.0283\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.386 - 0s 110us/sample - loss: 0.3060 - val_loss: 0.0279\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.313 - 0s 126us/sample - loss: 0.3138 - val_loss: 0.0275\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.355 - 0s 110us/sample - loss: 0.3219 - val_loss: 0.0272\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 130us/sample - loss: 0.2905 - val_loss: 0.0270\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.314 - 0s 116us/sample - loss: 0.3232 - val_loss: 0.0269\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.333 - 0s 105us/sample - loss: 0.3088 - val_loss: 0.0268\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.302 - 0s 123us/sample - loss: 0.2793 - val_loss: 0.0266\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.342 - 0s 98us/sample - loss: 0.2795 - val_loss: 0.0265\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.369 - 0s 110us/sample - loss: 0.2968 - val_loss: 0.0263\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 118us/sample - loss: 0.2914 - val_loss: 0.0262\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.334 - 0s 115us/sample - loss: 0.2924 - val_loss: 0.0261\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 125us/sample - loss: 0.2764 - val_loss: 0.0260\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.252 - 0s 113us/sample - loss: 0.2471 - val_loss: 0.0258\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.363 - 0s 115us/sample - loss: 0.2795 - val_loss: 0.0257\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.231 - 0s 110us/sample - loss: 0.2484 - val_loss: 0.0256\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.315 - 0s 108us/sample - loss: 0.2628 - val_loss: 0.0254\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.265 - 0s 118us/sample - loss: 0.2619 - val_loss: 0.0253\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.247 - 0s 133us/sample - loss: 0.2397 - val_loss: 0.0252\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.369 - 0s 113us/sample - loss: 0.2658 - val_loss: 0.0251\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.168 - 0s 110us/sample - loss: 0.2390 - val_loss: 0.0250\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.235 - 0s 114us/sample - loss: 0.2257 - val_loss: 0.0249\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.232 - 0s 105us/sample - loss: 0.2254 - val_loss: 0.0248\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.287 - 0s 100us/sample - loss: 0.2368 - val_loss: 0.0247\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.256 - 0s 96us/sample - loss: 0.2257 - val_loss: 0.0246\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 110us/sample - loss: 0.2156 - val_loss: 0.0245\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.165 - 0s 96us/sample - loss: 0.2056 - val_loss: 0.0244\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 102us/sample - loss: 0.2143 - val_loss: 0.0243\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.312 - 0s 125us/sample - loss: 0.2089 - val_loss: 0.0242\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.156 - 0s 115us/sample - loss: 0.2201 - val_loss: 0.0241\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.271 - 0s 118us/sample - loss: 0.2040 - val_loss: 0.0240\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.251 - 0s 110us/sample - loss: 0.1943 - val_loss: 0.0239\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 101us/sample - loss: 0.1845 - val_loss: 0.0239\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.214 - 0s 99us/sample - loss: 0.1968 - val_loss: 0.0238\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.153 - 0s 100us/sample - loss: 0.2033 - val_loss: 0.0237\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 94us/sample - loss: 0.1875 - val_loss: 0.0236\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.143 - 0s 103us/sample - loss: 0.1727 - val_loss: 0.0235\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.253 - 0s 97us/sample - loss: 0.1629 - val_loss: 0.0234\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 96us/sample - loss: 0.1865 - val_loss: 0.0234\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 105us/sample - loss: 0.1734 - val_loss: 0.0233\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 96us/sample - loss: 0.1749 - val_loss: 0.0232\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 84us/sample - loss: 0.1699 - val_loss: 0.0231\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 105us/sample - loss: 0.1715 - val_loss: 0.0231\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 103us/sample - loss: 0.1584 - val_loss: 0.0229\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 118us/sample - loss: 0.1458 - val_loss: 0.0229\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 98us/sample - loss: 0.1446 - val_loss: 0.0229\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 103us/sample - loss: 0.1445 - val_loss: 0.0229\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.188 - 0s 96us/sample - loss: 0.1625 - val_loss: 0.0229\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 122us/sample - loss: 0.1508 - val_loss: 0.0228\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 118us/sample - loss: 0.1543 - val_loss: 0.0228\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.160 - 0s 102us/sample - loss: 0.1481 - val_loss: 0.0226\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 93us/sample - loss: 0.1414 - val_loss: 0.0226\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.170 - 0s 99us/sample - loss: 0.1454 - val_loss: 0.0225\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.298 - 0s 100us/sample - loss: 0.1514 - val_loss: 0.0223\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.186 - 0s 95us/sample - loss: 0.1386 - val_loss: 0.0222\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 96us/sample - loss: 0.1357 - val_loss: 0.0222\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 90us/sample - loss: 0.1294 - val_loss: 0.0221\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.138 - 0s 130us/sample - loss: 0.1218 - val_loss: 0.0221\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.189 - 0s 105us/sample - loss: 0.1311 - val_loss: 0.0220\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.159 - 0s 98us/sample - loss: 0.1427 - val_loss: 0.0219\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.134 - 0s 93us/sample - loss: 0.1253 - val_loss: 0.0219\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 93us/sample - loss: 0.1292 - val_loss: 0.0219\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.191 - 0s 93us/sample - loss: 0.1263 - val_loss: 0.0218\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.146 - 0s 94us/sample - loss: 0.1219 - val_loss: 0.0217\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 108us/sample - loss: 0.1046 - val_loss: 0.0217\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.141 - 0s 93us/sample - loss: 0.1167 - val_loss: 0.0217\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.163 - 0s 96us/sample - loss: 0.1196 - val_loss: 0.0215\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 100us/sample - loss: 0.1089 - val_loss: 0.0215\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.111 - 0s 88us/sample - loss: 0.1206 - val_loss: 0.0213\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.136 - 0s 83us/sample - loss: 0.1083 - val_loss: 0.0212\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 83us/sample - loss: 0.1093 - val_loss: 0.0211\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 106us/sample - loss: 0.0986 - val_loss: 0.0211\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 90us/sample - loss: 0.1093 - val_loss: 0.0210\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 81us/sample - loss: 0.0999 - val_loss: 0.0209\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 83us/sample - loss: 0.0895 - val_loss: 0.0209\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 93us/sample - loss: 0.0922 - val_loss: 0.0208\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 86us/sample - loss: 0.1042 - val_loss: 0.0208\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 83us/sample - loss: 0.0965 - val_loss: 0.0207\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 105us/sample - loss: 0.1035 - val_loss: 0.0204\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 84us/sample - loss: 0.0938 - val_loss: 0.0203\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 86us/sample - loss: 0.0838 - val_loss: 0.0202\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.104 - 0s 91us/sample - loss: 0.0914 - val_loss: 0.0201\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 83us/sample - loss: 0.0886 - val_loss: 0.0200\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.100 - 0s 84us/sample - loss: 0.0853 - val_loss: 0.0198\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.0792 - val_loss: 0.0197\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 96us/sample - loss: 0.0884 - val_loss: 0.0196\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 97us/sample - loss: 0.0835 - val_loss: 0.0196\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 88us/sample - loss: 0.0770 - val_loss: 0.0196\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.080 - 0s 108us/sample - loss: 0.0816 - val_loss: 0.0195\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 82us/sample - loss: 0.0773 - val_loss: 0.0195\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.106 - 0s 83us/sample - loss: 0.0824 - val_loss: 0.0197\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.092 - 0s 86us/sample - loss: 0.0783 - val_loss: 0.0198\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 108us/sample - loss: 0.0746 - val_loss: 0.0197\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 92us/sample - loss: 0.0757 - val_loss: 0.0197\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 98us/sample - loss: 0.0701 - val_loss: 0.0196\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 103us/sample - loss: 0.0708 - val_loss: 0.0195\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 94us/sample - loss: 0.0695 - val_loss: 0.0192\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 98us/sample - loss: 0.0709 - val_loss: 0.0192\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 98us/sample - loss: 0.0662 - val_loss: 0.0190\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 105us/sample - loss: 0.0698 - val_loss: 0.0190\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 108us/sample - loss: 0.0621 - val_loss: 0.0189\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 115us/sample - loss: 0.0633 - val_loss: 0.0191\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 108us/sample - loss: 0.0625 - val_loss: 0.0190\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 120us/sample - loss: 0.0653 - val_loss: 0.0190\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 94us/sample - loss: 0.0552 - val_loss: 0.0191\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.072 - 0s 108us/sample - loss: 0.0629 - val_loss: 0.0194\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 96us/sample - loss: 0.0570 - val_loss: 0.0196\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 95us/sample - loss: 0.0604 - val_loss: 0.0198\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 99us/sample - loss: 0.0585 - val_loss: 0.0197\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 96us/sample - loss: 0.0561 - val_loss: 0.0196\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 96us/sample - loss: 0.0561 - val_loss: 0.0195\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.216 - 0s 690us/sample - loss: 0.2401 - val_loss: 0.1528\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.218 - 0s 93us/sample - loss: 0.2160 - val_loss: 0.1388\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.170 - 0s 88us/sample - loss: 0.2023 - val_loss: 0.1265\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.145 - 0s 96us/sample - loss: 0.1926 - val_loss: 0.1161\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.197 - 0s 100us/sample - loss: 0.1758 - val_loss: 0.1064\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 93us/sample - loss: 0.1634 - val_loss: 0.0979\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.137 - 0s 96us/sample - loss: 0.1634 - val_loss: 0.0899\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.176 - 0s 101us/sample - loss: 0.1480 - val_loss: 0.0833\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 110us/sample - loss: 0.1303 - val_loss: 0.0781\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 98us/sample - loss: 0.1322 - val_loss: 0.0735\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 93us/sample - loss: 0.1291 - val_loss: 0.0695\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 98us/sample - loss: 0.1171 - val_loss: 0.0663\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 96us/sample - loss: 0.1273 - val_loss: 0.0632\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.110 - 0s 91us/sample - loss: 0.1173 - val_loss: 0.0602\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.155 - 0s 95us/sample - loss: 0.1153 - val_loss: 0.0578\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.099 - 0s 110us/sample - loss: 0.1030 - val_loss: 0.0557\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 100us/sample - loss: 0.1028 - val_loss: 0.0538\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.108 - 0s 97us/sample - loss: 0.1012 - val_loss: 0.0521\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 105us/sample - loss: 0.0848 - val_loss: 0.0502\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.094 - 0s 99us/sample - loss: 0.0921 - val_loss: 0.0488\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 99us/sample - loss: 0.0889 - val_loss: 0.0475\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 105us/sample - loss: 0.0842 - val_loss: 0.0461\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 93us/sample - loss: 0.0810 - val_loss: 0.0448\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 92us/sample - loss: 0.0835 - val_loss: 0.0436\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0846 - val_loss: 0.0425\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 96us/sample - loss: 0.0810 - val_loss: 0.0414\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 100us/sample - loss: 0.0771 - val_loss: 0.0403\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 106us/sample - loss: 0.0733 - val_loss: 0.0392\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.060 - 0s 101us/sample - loss: 0.0730 - val_loss: 0.0382\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 93us/sample - loss: 0.0688 - val_loss: 0.0370\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 83us/sample - loss: 0.0711 - val_loss: 0.0361\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 93us/sample - loss: 0.0703 - val_loss: 0.0351\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 83us/sample - loss: 0.0626 - val_loss: 0.0343\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 87us/sample - loss: 0.0630 - val_loss: 0.0334\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 91us/sample - loss: 0.0624 - val_loss: 0.0325\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 86us/sample - loss: 0.0578 - val_loss: 0.0318\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0565 - val_loss: 0.0312\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 83us/sample - loss: 0.0507 - val_loss: 0.0305\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0544 - val_loss: 0.0298\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0551 - val_loss: 0.0292\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 81us/sample - loss: 0.0538 - val_loss: 0.0288\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 83us/sample - loss: 0.0548 - val_loss: 0.0283\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 95us/sample - loss: 0.0518 - val_loss: 0.0278\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 95us/sample - loss: 0.0528 - val_loss: 0.0273\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0502 - val_loss: 0.0268\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 97us/sample - loss: 0.0461 - val_loss: 0.0263\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 86us/sample - loss: 0.0524 - val_loss: 0.0257\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 83us/sample - loss: 0.0468 - val_loss: 0.0253\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 92us/sample - loss: 0.0489 - val_loss: 0.0249\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 80us/sample - loss: 0.0446 - val_loss: 0.0246\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 91us/sample - loss: 0.0482 - val_loss: 0.0243\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 81us/sample - loss: 0.0484 - val_loss: 0.0238\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 86us/sample - loss: 0.0483 - val_loss: 0.0234\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.049 - 0s 125us/sample - loss: 0.0437 - val_loss: 0.0230\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 108us/sample - loss: 0.0470 - val_loss: 0.0226\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 98us/sample - loss: 0.0429 - val_loss: 0.0223\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 104us/sample - loss: 0.0425 - val_loss: 0.0219\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 96us/sample - loss: 0.0390 - val_loss: 0.0217\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0392 - val_loss: 0.0213\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 96us/sample - loss: 0.0374 - val_loss: 0.0210\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 117us/sample - loss: 0.0391 - val_loss: 0.0208\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 113us/sample - loss: 0.0399 - val_loss: 0.0205\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 123us/sample - loss: 0.0380 - val_loss: 0.0202\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 110us/sample - loss: 0.0378 - val_loss: 0.0199\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 100us/sample - loss: 0.0375 - val_loss: 0.0197\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 113us/sample - loss: 0.0350 - val_loss: 0.0195\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 117us/sample - loss: 0.0353 - val_loss: 0.0193\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0366 - val_loss: 0.0190\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 120us/sample - loss: 0.0327 - val_loss: 0.0188\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.047 - 0s 99us/sample - loss: 0.0367 - val_loss: 0.0186\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0357 - val_loss: 0.0184\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 105us/sample - loss: 0.0362 - val_loss: 0.0183\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 115us/sample - loss: 0.0348 - val_loss: 0.0181\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 120us/sample - loss: 0.0342 - val_loss: 0.0179\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 115us/sample - loss: 0.0321 - val_loss: 0.0177\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 120us/sample - loss: 0.0320 - val_loss: 0.0175\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0320 - val_loss: 0.0174\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 101us/sample - loss: 0.0318 - val_loss: 0.0172\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0330 - val_loss: 0.0170\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0318 - val_loss: 0.0169\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 101us/sample - loss: 0.0321 - val_loss: 0.0168\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0315 - val_loss: 0.0167\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 97us/sample - loss: 0.0306 - val_loss: 0.0165\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 117us/sample - loss: 0.0298 - val_loss: 0.0163\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0307 - val_loss: 0.0163\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 96us/sample - loss: 0.0303 - val_loss: 0.0161\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 111us/sample - loss: 0.0277 - val_loss: 0.0160\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 115us/sample - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 110us/sample - loss: 0.0269 - val_loss: 0.0157\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0278 - val_loss: 0.0155\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0258 - val_loss: 0.0153\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0298 - val_loss: 0.0152\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 118us/sample - loss: 0.0261 - val_loss: 0.0152\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 104us/sample - loss: 0.0266 - val_loss: 0.0150\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 103us/sample - loss: 0.0283 - val_loss: 0.0149\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0273 - val_loss: 0.0148\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0271 - val_loss: 0.0147\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0250 - val_loss: 0.0146\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 119us/sample - loss: 0.0253 - val_loss: 0.0146\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 127us/sample - loss: 0.0258 - val_loss: 0.0145\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 135us/sample - loss: 0.0254 - val_loss: 0.0144\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 115us/sample - loss: 0.0237 - val_loss: 0.0143\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0252 - val_loss: 0.0142\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 108us/sample - loss: 0.0250 - val_loss: 0.0141\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 96us/sample - loss: 0.0255 - val_loss: 0.0140\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 96us/sample - loss: 0.0255 - val_loss: 0.0139\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0243 - val_loss: 0.0138\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0234 - val_loss: 0.0138\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 101us/sample - loss: 0.0263 - val_loss: 0.0137\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 125us/sample - loss: 0.0233 - val_loss: 0.0136\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 123us/sample - loss: 0.0239 - val_loss: 0.0135\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 118us/sample - loss: 0.0233 - val_loss: 0.0135\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0245 - val_loss: 0.0134\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0225 - val_loss: 0.0134\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 127us/sample - loss: 0.0209 - val_loss: 0.0133\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 147us/sample - loss: 0.0212 - val_loss: 0.0132\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 120us/sample - loss: 0.0207 - val_loss: 0.0131\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0206 - val_loss: 0.0130\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0130\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 132us/sample - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 126us/sample - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0193 - val_loss: 0.0127\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0127\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0214 - val_loss: 0.0126\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 107us/sample - loss: 0.0195 - val_loss: 0.0125\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0195 - val_loss: 0.0124\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0195 - val_loss: 0.0124\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 83us/sample - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 110us/sample - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 113us/sample - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0178 - val_loss: 0.0118\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 99us/sample - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0164 - val_loss: 0.0114\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 92us/sample - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 117us/sample - loss: 0.0161 - val_loss: 0.0113\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.524 - 0s 761us/sample - loss: 0.4909 - val_loss: 0.3333\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.396 - 0s 95us/sample - loss: 0.4590 - val_loss: 0.3037\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.416 - 0s 88us/sample - loss: 0.3885 - val_loss: 0.2796\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.634 - 0s 96us/sample - loss: 0.4473 - val_loss: 0.2594\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.429 - 0s 93us/sample - loss: 0.3754 - val_loss: 0.2429\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.360 - 0s 86us/sample - loss: 0.3564 - val_loss: 0.2281\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.365 - 0s 91us/sample - loss: 0.3407 - val_loss: 0.2158\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.167 - 0s 100us/sample - loss: 0.3359 - val_loss: 0.2048\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.508 - 0s 105us/sample - loss: 0.3437 - val_loss: 0.1946\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.327 - 0s 96us/sample - loss: 0.3414 - val_loss: 0.1862\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.422 - 0s 105us/sample - loss: 0.3413 - val_loss: 0.1778\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.346 - 0s 91us/sample - loss: 0.2846 - val_loss: 0.1715\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.228 - 0s 86us/sample - loss: 0.2994 - val_loss: 0.1659\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.241 - 0s 84us/sample - loss: 0.2990 - val_loss: 0.1607\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.258 - 0s 91us/sample - loss: 0.3037 - val_loss: 0.1573\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.264 - 0s 91us/sample - loss: 0.2737 - val_loss: 0.1527\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.289 - 0s 85us/sample - loss: 0.2612 - val_loss: 0.1494\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.402 - 0s 88us/sample - loss: 0.2800 - val_loss: 0.1462\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.192 - 0s 100us/sample - loss: 0.2534 - val_loss: 0.1435\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.274 - 0s 105us/sample - loss: 0.2466 - val_loss: 0.1415\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.215 - 0s 93us/sample - loss: 0.2422 - val_loss: 0.1390\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.195 - 0s 103us/sample - loss: 0.2264 - val_loss: 0.1363\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.242 - 0s 93us/sample - loss: 0.2157 - val_loss: 0.1337\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.180 - 0s 98us/sample - loss: 0.2182 - val_loss: 0.1311\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 96us/sample - loss: 0.1972 - val_loss: 0.1291\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.228 - 0s 102us/sample - loss: 0.1960 - val_loss: 0.1271\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.219 - 0s 105us/sample - loss: 0.2004 - val_loss: 0.1251\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.241 - 0s 110us/sample - loss: 0.2061 - val_loss: 0.1218\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.204 - 0s 98us/sample - loss: 0.1904 - val_loss: 0.1207\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.178 - 0s 93us/sample - loss: 0.1853 - val_loss: 0.1187\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 96us/sample - loss: 0.1797 - val_loss: 0.1171\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.181 - 0s 98us/sample - loss: 0.1789 - val_loss: 0.1141\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.227 - 0s 98us/sample - loss: 0.1791 - val_loss: 0.1127\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.161 - 0s 88us/sample - loss: 0.1647 - val_loss: 0.1112\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.175 - 0s 103us/sample - loss: 0.1680 - val_loss: 0.1095\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.119 - 0s 127us/sample - loss: 0.1497 - val_loss: 0.1081\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.147 - 0s 111us/sample - loss: 0.1582 - val_loss: 0.1067\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.203 - 0s 113us/sample - loss: 0.1516 - val_loss: 0.1056\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.162 - 0s 105us/sample - loss: 0.1395 - val_loss: 0.1049\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.183 - 0s 122us/sample - loss: 0.1475 - val_loss: 0.1038\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.151 - 0s 103us/sample - loss: 0.1421 - val_loss: 0.1022\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.226 - 0s 100us/sample - loss: 0.1487 - val_loss: 0.1003\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.215 - 0s 113us/sample - loss: 0.1470 - val_loss: 0.0989\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.145 - 0s 110us/sample - loss: 0.1343 - val_loss: 0.0972\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.164 - 0s 112us/sample - loss: 0.1430 - val_loss: 0.0968\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.207 - 0s 108us/sample - loss: 0.1345 - val_loss: 0.0961\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.116 - 0s 106us/sample - loss: 0.1192 - val_loss: 0.0949\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 105us/sample - loss: 0.1157 - val_loss: 0.0943\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 100us/sample - loss: 0.1099 - val_loss: 0.0939\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.140 - 0s 110us/sample - loss: 0.1089 - val_loss: 0.0925\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 100us/sample - loss: 0.1141 - val_loss: 0.0908\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.122 - 0s 100us/sample - loss: 0.1062 - val_loss: 0.0897\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.095 - 0s 96us/sample - loss: 0.1165 - val_loss: 0.0883\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 98us/sample - loss: 0.1079 - val_loss: 0.0871\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 105us/sample - loss: 0.0966 - val_loss: 0.0859\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 110us/sample - loss: 0.1001 - val_loss: 0.0853\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 113us/sample - loss: 0.0920 - val_loss: 0.0855\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.055 - 0s 118us/sample - loss: 0.0906 - val_loss: 0.0848\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 93us/sample - loss: 0.0911 - val_loss: 0.0844\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 95us/sample - loss: 0.0910 - val_loss: 0.0833\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.066 - 0s 98us/sample - loss: 0.0852 - val_loss: 0.0811\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 103us/sample - loss: 0.0837 - val_loss: 0.0796\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.097 - 0s 101us/sample - loss: 0.0887 - val_loss: 0.0788\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.084 - 0s 96us/sample - loss: 0.0825 - val_loss: 0.0779\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.089 - 0s 94us/sample - loss: 0.0755 - val_loss: 0.0769\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.087 - 0s 120us/sample - loss: 0.0764 - val_loss: 0.0761\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 113us/sample - loss: 0.0752 - val_loss: 0.0747\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 125us/sample - loss: 0.0782 - val_loss: 0.0738\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.073 - 0s 115us/sample - loss: 0.0683 - val_loss: 0.0725\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.085 - 0s 115us/sample - loss: 0.0699 - val_loss: 0.0712\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 115us/sample - loss: 0.0662 - val_loss: 0.0706\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.074 - 0s 108us/sample - loss: 0.0672 - val_loss: 0.0696\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.112 - 0s 113us/sample - loss: 0.0610 - val_loss: 0.0684\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 135us/sample - loss: 0.0622 - val_loss: 0.0675\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 127us/sample - loss: 0.0581 - val_loss: 0.0666\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 123us/sample - loss: 0.0583 - val_loss: 0.0661\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.033 - 0s 106us/sample - loss: 0.0535 - val_loss: 0.0641\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0600 - val_loss: 0.0629\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.027 - 0s 92us/sample - loss: 0.0556 - val_loss: 0.0622\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 110us/sample - loss: 0.0546 - val_loss: 0.0612\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 108us/sample - loss: 0.0476 - val_loss: 0.0602\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 99us/sample - loss: 0.0519 - val_loss: 0.0591\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 108us/sample - loss: 0.0517 - val_loss: 0.0580\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 105us/sample - loss: 0.0481 - val_loss: 0.0573\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 91us/sample - loss: 0.0482 - val_loss: 0.0564\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0463 - val_loss: 0.0555\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 108us/sample - loss: 0.0470 - val_loss: 0.0545\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 95us/sample - loss: 0.0444 - val_loss: 0.0541\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 102us/sample - loss: 0.0382 - val_loss: 0.0529\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 105us/sample - loss: 0.0388 - val_loss: 0.0519\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 91us/sample - loss: 0.0407 - val_loss: 0.0509\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 84us/sample - loss: 0.0409 - val_loss: 0.0500\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 96us/sample - loss: 0.0372 - val_loss: 0.0488\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 88us/sample - loss: 0.0376 - val_loss: 0.0481\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 88us/sample - loss: 0.0375 - val_loss: 0.0473\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 91us/sample - loss: 0.0370 - val_loss: 0.0465\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 83us/sample - loss: 0.0331 - val_loss: 0.0457\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 85us/sample - loss: 0.0346 - val_loss: 0.0449\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0328 - val_loss: 0.0443\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0323 - val_loss: 0.0437\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0313 - val_loss: 0.0429\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 81us/sample - loss: 0.0322 - val_loss: 0.0423\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 90us/sample - loss: 0.0328 - val_loss: 0.0417\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 81us/sample - loss: 0.0299 - val_loss: 0.0409\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 93us/sample - loss: 0.0299 - val_loss: 0.0401\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 87us/sample - loss: 0.0285 - val_loss: 0.0393\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 82us/sample - loss: 0.0307 - val_loss: 0.0387\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0270 - val_loss: 0.0379\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0283 - val_loss: 0.0372\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0275 - val_loss: 0.0366\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 88us/sample - loss: 0.0264 - val_loss: 0.0363\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0274 - val_loss: 0.0358\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0269 - val_loss: 0.0354\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0253 - val_loss: 0.0349\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 102us/sample - loss: 0.0261 - val_loss: 0.0343\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - 0s 110us/sample - loss: 0.0240 - val_loss: 0.0338\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 96us/sample - loss: 0.0233 - val_loss: 0.0333\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0232 - val_loss: 0.0327\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 107us/sample - loss: 0.0231 - val_loss: 0.0321\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0211 - val_loss: 0.0316\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 92us/sample - loss: 0.0222 - val_loss: 0.0312\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 100us/sample - loss: 0.0224 - val_loss: 0.0308\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0217 - val_loss: 0.0304\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0219 - val_loss: 0.0301\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0204 - val_loss: 0.0295\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0208 - val_loss: 0.0291\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0207 - val_loss: 0.0288\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0195 - val_loss: 0.0283\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 100us/sample - loss: 0.0224 - val_loss: 0.0280\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 123us/sample - loss: 0.0190 - val_loss: 0.0275\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0186 - val_loss: 0.0272\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 103us/sample - loss: 0.0189 - val_loss: 0.0269\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0189 - val_loss: 0.0265\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0180 - val_loss: 0.0261\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.023 - 0s 108us/sample - loss: 0.0187 - val_loss: 0.0256\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.021 - 0s 105us/sample - loss: 0.0187 - val_loss: 0.0252\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0169 - val_loss: 0.0249\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.020 - 0s 119us/sample - loss: 0.0175 - val_loss: 0.0246\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0168 - val_loss: 0.0242\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 127us/sample - loss: 0.0169 - val_loss: 0.0239\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0169 - val_loss: 0.0237\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0161 - val_loss: 0.0234\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.009 - 0s 156us/sample - loss: 0.0165 - val_loss: 0.0231\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.015 - 0s 211us/sample - loss: 0.0156 - val_loss: 0.0228\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 132us/sample - loss: 0.0165 - val_loss: 0.0225\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.018 - 0s 142us/sample - loss: 0.0169 - val_loss: 0.0222\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.014 - 0s 132us/sample - loss: 0.0155 - val_loss: 0.0220\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.016 - 0s 140us/sample - loss: 0.0164 - val_loss: 0.0218\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0156 - val_loss: 0.0215\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0147 - val_loss: 0.0212\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.779 - 0s 799us/sample - loss: 0.6315 - val_loss: 0.3907\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.495 - 0s 95us/sample - loss: 0.5730 - val_loss: 0.3591\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.784 - 0s 115us/sample - loss: 0.5524 - val_loss: 0.3294\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.439 - 0s 98us/sample - loss: 0.5146 - val_loss: 0.3007\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.540 - 0s 96us/sample - loss: 0.4604 - val_loss: 0.2747\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.676 - 0s 108us/sample - loss: 0.4667 - val_loss: 0.2494\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.362 - 0s 93us/sample - loss: 0.4249 - val_loss: 0.2273\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.312 - 0s 107us/sample - loss: 0.3971 - val_loss: 0.2080\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.434 - 0s 110us/sample - loss: 0.3729 - val_loss: 0.1886\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.374 - 0s 101us/sample - loss: 0.3671 - val_loss: 0.1715\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.344 - 0s 86us/sample - loss: 0.3497 - val_loss: 0.1540\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.354 - 0s 93us/sample - loss: 0.2948 - val_loss: 0.1399\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.303 - 0s 84us/sample - loss: 0.2811 - val_loss: 0.1276\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.337 - 0s 86us/sample - loss: 0.2912 - val_loss: 0.1167\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.244 - 0s 98us/sample - loss: 0.2596 - val_loss: 0.1063\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.368 - 0s 83us/sample - loss: 0.2507 - val_loss: 0.0965\n",
      "Epoch 17/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.336 - 0s 88us/sample - loss: 0.2529 - val_loss: 0.0884\n",
      "Epoch 18/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.273 - 0s 95us/sample - loss: 0.2539 - val_loss: 0.0807\n",
      "Epoch 19/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.169 - 0s 86us/sample - loss: 0.2162 - val_loss: 0.0738\n",
      "Epoch 20/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.194 - 0s 101us/sample - loss: 0.2330 - val_loss: 0.0687\n",
      "Epoch 21/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.189 - 0s 88us/sample - loss: 0.2092 - val_loss: 0.0639\n",
      "Epoch 22/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.173 - 0s 92us/sample - loss: 0.1934 - val_loss: 0.0590\n",
      "Epoch 23/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.154 - 0s 108us/sample - loss: 0.2025 - val_loss: 0.0546\n",
      "Epoch 24/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.189 - 0s 86us/sample - loss: 0.1823 - val_loss: 0.0507\n",
      "Epoch 25/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 85us/sample - loss: 0.1818 - val_loss: 0.0470\n",
      "Epoch 26/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.188 - 0s 81us/sample - loss: 0.1868 - val_loss: 0.0445\n",
      "Epoch 27/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.240 - 0s 98us/sample - loss: 0.1843 - val_loss: 0.0427\n",
      "Epoch 28/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.208 - 0s 83us/sample - loss: 0.1779 - val_loss: 0.0412\n",
      "Epoch 29/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.174 - 0s 86us/sample - loss: 0.1574 - val_loss: 0.0397\n",
      "Epoch 30/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.260 - 0s 87us/sample - loss: 0.1741 - val_loss: 0.0381\n",
      "Epoch 31/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.243 - 0s 86us/sample - loss: 0.1644 - val_loss: 0.0368\n",
      "Epoch 32/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.200 - 0s 101us/sample - loss: 0.1610 - val_loss: 0.0354\n",
      "Epoch 33/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.185 - 0s 105us/sample - loss: 0.1562 - val_loss: 0.0344\n",
      "Epoch 34/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.149 - 0s 113us/sample - loss: 0.1597 - val_loss: 0.0337\n",
      "Epoch 35/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.148 - 0s 127us/sample - loss: 0.1524 - val_loss: 0.0330\n",
      "Epoch 36/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.152 - 0s 110us/sample - loss: 0.1565 - val_loss: 0.0324\n",
      "Epoch 37/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.125 - 0s 96us/sample - loss: 0.1445 - val_loss: 0.0317\n",
      "Epoch 38/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 92us/sample - loss: 0.1449 - val_loss: 0.0310\n",
      "Epoch 39/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 108us/sample - loss: 0.1409 - val_loss: 0.0302\n",
      "Epoch 40/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 91us/sample - loss: 0.1356 - val_loss: 0.0296\n",
      "Epoch 41/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.126 - 0s 100us/sample - loss: 0.1419 - val_loss: 0.0290\n",
      "Epoch 42/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.143 - 0s 105us/sample - loss: 0.1268 - val_loss: 0.0284\n",
      "Epoch 43/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 106us/sample - loss: 0.1213 - val_loss: 0.0279\n",
      "Epoch 44/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.118 - 0s 99us/sample - loss: 0.1106 - val_loss: 0.0274\n",
      "Epoch 45/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.107 - 0s 106us/sample - loss: 0.1373 - val_loss: 0.0271\n",
      "Epoch 46/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.139 - 0s 98us/sample - loss: 0.1214 - val_loss: 0.0266\n",
      "Epoch 47/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 101us/sample - loss: 0.1148 - val_loss: 0.0261\n",
      "Epoch 48/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.142 - 0s 112us/sample - loss: 0.1141 - val_loss: 0.0258\n",
      "Epoch 49/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.093 - 0s 98us/sample - loss: 0.1236 - val_loss: 0.0254\n",
      "Epoch 50/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 98us/sample - loss: 0.1146 - val_loss: 0.0250\n",
      "Epoch 51/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 92us/sample - loss: 0.0994 - val_loss: 0.0246\n",
      "Epoch 52/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 108us/sample - loss: 0.1156 - val_loss: 0.0242\n",
      "Epoch 53/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.129 - 0s 96us/sample - loss: 0.1067 - val_loss: 0.0238\n",
      "Epoch 54/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.131 - 0s 108us/sample - loss: 0.0937 - val_loss: 0.0235\n",
      "Epoch 55/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 100us/sample - loss: 0.0956 - val_loss: 0.0232\n",
      "Epoch 56/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.120 - 0s 103us/sample - loss: 0.1011 - val_loss: 0.0230\n",
      "Epoch 57/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 91us/sample - loss: 0.0970 - val_loss: 0.0226\n",
      "Epoch 58/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.127 - 0s 86us/sample - loss: 0.1016 - val_loss: 0.0224\n",
      "Epoch 59/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 93us/sample - loss: 0.0887 - val_loss: 0.0221\n",
      "Epoch 60/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 98us/sample - loss: 0.0841 - val_loss: 0.0218\n",
      "Epoch 61/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.081 - 0s 91us/sample - loss: 0.0979 - val_loss: 0.0216\n",
      "Epoch 62/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.143 - 0s 91us/sample - loss: 0.0899 - val_loss: 0.0214\n",
      "Epoch 63/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.101 - 0s 88us/sample - loss: 0.0938 - val_loss: 0.0212\n",
      "Epoch 64/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 91us/sample - loss: 0.0901 - val_loss: 0.0210\n",
      "Epoch 65/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 86us/sample - loss: 0.0857 - val_loss: 0.0209\n",
      "Epoch 66/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.103 - 0s 83us/sample - loss: 0.0864 - val_loss: 0.0207\n",
      "Epoch 67/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.123 - 0s 90us/sample - loss: 0.0823 - val_loss: 0.0206\n",
      "Epoch 68/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.088 - 0s 89us/sample - loss: 0.0839 - val_loss: 0.0204\n",
      "Epoch 69/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 98us/sample - loss: 0.0843 - val_loss: 0.0202\n",
      "Epoch 70/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.075 - 0s 89us/sample - loss: 0.0797 - val_loss: 0.0201\n",
      "Epoch 71/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.096 - 0s 86us/sample - loss: 0.0717 - val_loss: 0.0199\n",
      "Epoch 72/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 93us/sample - loss: 0.0767 - val_loss: 0.0198\n",
      "Epoch 73/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.098 - 0s 90us/sample - loss: 0.0802 - val_loss: 0.0197\n",
      "Epoch 74/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0801 - val_loss: 0.0196\n",
      "Epoch 75/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.0729 - val_loss: 0.0195\n",
      "Epoch 76/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 85us/sample - loss: 0.0727 - val_loss: 0.0194\n",
      "Epoch 77/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.105 - 0s 85us/sample - loss: 0.0792 - val_loss: 0.0193\n",
      "Epoch 78/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.068 - 0s 98us/sample - loss: 0.0721 - val_loss: 0.0192\n",
      "Epoch 79/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.056 - 0s 81us/sample - loss: 0.0719 - val_loss: 0.0190\n",
      "Epoch 80/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.090 - 0s 86us/sample - loss: 0.0668 - val_loss: 0.0189\n",
      "Epoch 81/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0668 - val_loss: 0.0188\n",
      "Epoch 82/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 96us/sample - loss: 0.0657 - val_loss: 0.0187\n",
      "Epoch 83/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 96us/sample - loss: 0.0589 - val_loss: 0.0186\n",
      "Epoch 84/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.071 - 0s 103us/sample - loss: 0.0655 - val_loss: 0.0185\n",
      "Epoch 85/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.083 - 0s 105us/sample - loss: 0.0665 - val_loss: 0.0184\n",
      "Epoch 86/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.070 - 0s 111us/sample - loss: 0.0678 - val_loss: 0.0183\n",
      "Epoch 87/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.067 - 0s 103us/sample - loss: 0.0614 - val_loss: 0.0183\n",
      "Epoch 88/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.086 - 0s 105us/sample - loss: 0.0651 - val_loss: 0.0182\n",
      "Epoch 89/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 113us/sample - loss: 0.0614 - val_loss: 0.0181\n",
      "Epoch 90/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 118us/sample - loss: 0.0618 - val_loss: 0.0180\n",
      "Epoch 91/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.065 - 0s 108us/sample - loss: 0.0567 - val_loss: 0.0180\n",
      "Epoch 92/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 123us/sample - loss: 0.0588 - val_loss: 0.0179\n",
      "Epoch 93/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.040 - 0s 103us/sample - loss: 0.0573 - val_loss: 0.0178\n",
      "Epoch 94/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.069 - 0s 97us/sample - loss: 0.0582 - val_loss: 0.0177\n",
      "Epoch 95/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.058 - 0s 97us/sample - loss: 0.0592 - val_loss: 0.0176\n",
      "Epoch 96/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.061 - 0s 100us/sample - loss: 0.0553 - val_loss: 0.0175\n",
      "Epoch 97/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.053 - 0s 100us/sample - loss: 0.0578 - val_loss: 0.0174\n",
      "Epoch 98/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0582 - val_loss: 0.0174\n",
      "Epoch 99/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.078 - 0s 98us/sample - loss: 0.0556 - val_loss: 0.0173\n",
      "Epoch 100/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.048 - 0s 103us/sample - loss: 0.0523 - val_loss: 0.0173\n",
      "Epoch 101/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.062 - 0s 100us/sample - loss: 0.0551 - val_loss: 0.0172\n",
      "Epoch 102/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.079 - 0s 96us/sample - loss: 0.0552 - val_loss: 0.0171\n",
      "Epoch 103/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.063 - 0s 108us/sample - loss: 0.0592 - val_loss: 0.0171\n",
      "Epoch 104/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 112us/sample - loss: 0.0488 - val_loss: 0.0170\n",
      "Epoch 105/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 108us/sample - loss: 0.0505 - val_loss: 0.0170\n",
      "Epoch 106/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 103us/sample - loss: 0.0520 - val_loss: 0.0169\n",
      "Epoch 107/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 100us/sample - loss: 0.0468 - val_loss: 0.0169\n",
      "Epoch 108/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 84us/sample - loss: 0.0441 - val_loss: 0.0168\n",
      "Epoch 109/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.064 - 0s 82us/sample - loss: 0.0482 - val_loss: 0.0168\n",
      "Epoch 110/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0478 - val_loss: 0.0168\n",
      "Epoch 111/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 86us/sample - loss: 0.0494 - val_loss: 0.0167\n",
      "Epoch 112/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 89us/sample - loss: 0.0478 - val_loss: 0.0166\n",
      "Epoch 113/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.044 - 0s 113us/sample - loss: 0.0469 - val_loss: 0.0165\n",
      "Epoch 114/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 85us/sample - loss: 0.0449 - val_loss: 0.0164\n",
      "Epoch 115/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 90us/sample - loss: 0.0424 - val_loss: 0.0163\n",
      "Epoch 116/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.054 - 0s 96us/sample - loss: 0.0467 - val_loss: 0.0163\n",
      "Epoch 117/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.057 - 0s 97us/sample - loss: 0.0452 - val_loss: 0.0162\n",
      "Epoch 118/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0434 - val_loss: 0.0162\n",
      "Epoch 119/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.031 - 0s 100us/sample - loss: 0.0424 - val_loss: 0.0161\n",
      "Epoch 120/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 88us/sample - loss: 0.0452 - val_loss: 0.0161\n",
      "Epoch 121/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0435 - val_loss: 0.0161\n",
      "Epoch 122/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 83us/sample - loss: 0.0432 - val_loss: 0.0160\n",
      "Epoch 123/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 103us/sample - loss: 0.0426 - val_loss: 0.0159\n",
      "Epoch 124/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 83us/sample - loss: 0.0416 - val_loss: 0.0159\n",
      "Epoch 125/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.050 - 0s 89us/sample - loss: 0.0424 - val_loss: 0.0159\n",
      "Epoch 126/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0388 - val_loss: 0.0158\n",
      "Epoch 127/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 83us/sample - loss: 0.0416 - val_loss: 0.0158\n",
      "Epoch 128/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 96us/sample - loss: 0.0404 - val_loss: 0.0157\n",
      "Epoch 129/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0394 - val_loss: 0.0157\n",
      "Epoch 130/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.024 - 0s 115us/sample - loss: 0.0391 - val_loss: 0.0156\n",
      "Epoch 131/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.039 - 0s 91us/sample - loss: 0.0365 - val_loss: 0.0156\n",
      "Epoch 132/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.037 - 0s 103us/sample - loss: 0.0401 - val_loss: 0.0156\n",
      "Epoch 133/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.034 - 0s 117us/sample - loss: 0.0370 - val_loss: 0.0156\n",
      "Epoch 134/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 96us/sample - loss: 0.0389 - val_loss: 0.0156\n",
      "Epoch 135/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0376 - val_loss: 0.0155\n",
      "Epoch 136/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0340 - val_loss: 0.0155\n",
      "Epoch 137/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 97us/sample - loss: 0.0394 - val_loss: 0.0155\n",
      "Epoch 138/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.036 - 0s 101us/sample - loss: 0.0365 - val_loss: 0.0155\n",
      "Epoch 139/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.046 - 0s 90us/sample - loss: 0.0360 - val_loss: 0.0154\n",
      "Epoch 140/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 115us/sample - loss: 0.0351 - val_loss: 0.0153\n",
      "Epoch 141/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.038 - 0s 92us/sample - loss: 0.0346 - val_loss: 0.0153\n",
      "Epoch 142/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.052 - 0s 98us/sample - loss: 0.0364 - val_loss: 0.0153\n",
      "Epoch 143/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0316 - val_loss: 0.0152\n",
      "Epoch 144/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.025 - 0s 89us/sample - loss: 0.0330 - val_loss: 0.0152\n",
      "Epoch 145/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.042 - 0s 100us/sample - loss: 0.0332 - val_loss: 0.0152\n",
      "Epoch 146/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.041 - 0s 123us/sample - loss: 0.0301 - val_loss: 0.0151\n",
      "Epoch 147/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.043 - 0s 109us/sample - loss: 0.0349 - val_loss: 0.0151\n",
      "Epoch 148/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.026 - 0s 105us/sample - loss: 0.0355 - val_loss: 0.0150\n",
      "Epoch 149/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0341 - val_loss: 0.0150\n",
      "Epoch 150/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.032 - 0s 96us/sample - loss: 0.0308 - val_loss: 0.0149\n",
      "Train on 407 samples, validate on 175 samples\n",
      "Epoch 1/150\n",
      "407/407 [==============================] - ETA: 1s - loss: 0.284 - 0s 799us/sample - loss: 0.4697 - val_loss: 0.2851\n",
      "Epoch 2/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.528 - 0s 107us/sample - loss: 0.4426 - val_loss: 0.2581\n",
      "Epoch 3/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.494 - 0s 115us/sample - loss: 0.4516 - val_loss: 0.2330\n",
      "Epoch 4/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.393 - 0s 95us/sample - loss: 0.3927 - val_loss: 0.2121\n",
      "Epoch 5/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.374 - 0s 93us/sample - loss: 0.3511 - val_loss: 0.1928\n",
      "Epoch 6/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.382 - 0s 114us/sample - loss: 0.3918 - val_loss: 0.1736\n",
      "Epoch 7/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.388 - 0s 98us/sample - loss: 0.3448 - val_loss: 0.1572\n",
      "Epoch 8/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.351 - 0s 115us/sample - loss: 0.3317 - val_loss: 0.1444\n",
      "Epoch 9/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.430 - 0s 98us/sample - loss: 0.2993 - val_loss: 0.1337\n",
      "Epoch 10/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.387 - 0s 99us/sample - loss: 0.3041 - val_loss: 0.1231\n",
      "Epoch 11/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.253 - 0s 91us/sample - loss: 0.2981 - val_loss: 0.1138\n",
      "Epoch 12/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.208 - 0s 110us/sample - loss: 0.2599 - val_loss: 0.1053\n",
      "Epoch 13/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.311 - 0s 105us/sample - loss: 0.2873 - val_loss: 0.0972\n",
      "Epoch 14/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.158 - 0s 113us/sample - loss: 0.2510 - val_loss: 0.0912\n",
      "Epoch 15/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.133 - 0s 108us/sample - loss: 0.2417 - val_loss: 0.0867\n",
      "Epoch 16/150\n",
      "407/407 [==============================] - ETA: 0s - loss: 0.250"
     ]
    }
   ],
   "source": [
    "result = model.predict(testFeature).reshape(testTarget.shape[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1878e9c0b88>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2deXxcVd3/39/safatTZs0SZsmXaAF2rR0AVmFgkpRAQEVFH2QzeXnihv44C6PuD2oLCI+iEJlE7ECZZFFbG260DZd0z1JszZN0rTZz++PMzedJpNkljszdybn/XrlNZm7nkzufO653/M5368opTAYDAZD9BIT7gYYDAaDIbgYoTcYDIYoxwi9wWAwRDlG6A0GgyHKMUJvMBgMUU5cuBswlNzcXFVSUhLuZhgMBkNEsX79+malVJ6ndY4T+pKSEiorK8PdDIPBYIgoROTASOtM6MZgMBiiHCP0BoPBEOUYoTcYDIYoxwi9wWAwRDlG6A0GgyHK8UroRWS5iOwUkWoRuXOU7a4SESUiFW7Lvu7ab6eIXGpHow0Gg8HgPWPaK0UkFrgfeC9QA6wTkeeVUtuGbJcGfA5Y67ZsDnAtcBowBXhFRMqVUv32/QkGg8FgGA1vevSLgGql1F6lVA/wBLDCw3bfBX4CdLktWwE8oZTqVkrtA6pdxzMYhrPzRWjdH+5WGAxRhzdCXwAccntf41o2iIicBUxVSr3g676u/W8WkUoRqWxqavKq4YYoo68bnvwo/OsX4W6JwRB1eCP04mHZYLUSEYkBfgZ8ydd9Bxco9aBSqkIpVZGX53EGryHaadoJA33QsifcLTEYog5vUiDUAFPd3hcCdW7v04DTgX+KCEA+8LyIXOHFvgaDpqFKvx7ZF952GAxRiDc9+nVAmYhME5EE9ODq89ZKpVSbUipXKVWilCoB1gBXKKUqXdtdKyKJIjINKAP+Y/tfYYh8Grbq17ZD0Ns1+rYGg8EnxhR6pVQfcAfwErAdWKmUqhKRe1y99tH2rQJWAtuAF4HbjePG4BGrR4+CoyPmZjIYDH7gVfZKpdQqYNWQZXeNsO35Q95/H/i+n+0zjBcaqiBvNjRthyN7IW9muFtkMEQNZmasIfwca4TORpj9Af3eDMgaDLZihN4QfqywTck5kJSpe/QGg8E2jNAbwo8l9JNOg5xSI/QGg80YoTeEn4YqSM2HlFzIng5HTOjGLxp3QLtxLxuGY4TeEH4aturePGihb6vRM2UN3tN7An6/HF7+VrhbYnAgRugN4aW/D5p2nCr0agCOHgxvuyKNqmfhRCu0VIe7JQYHYoTeEF5aqqG/Byadrt9nl7qWm/CNT6z7nX5tNXMQDMMxQm8IL9aMWPcePZgBWV84/C7UVkJWCXQd1T17g8ENI/SG8NJQBTFxkFuu30/IhsQMI/S+UPl7iEuGc7+s35tevWEIRugN4aWhCnJnQlyCfi8COcZ54zVd7bB5JZz+YZh8hl5mcvobhmCE3hBeGqpOhm0ssqebHr23bFkJvZ1QcRNkFetlJleQYQhG6A3h40QrtNd4FvqjB6GvJzztihSUgnWPQP48KJgPSRmQnGV69IZhGKE3hI8GV9lhy3FjkV2qLZZth4bvYzjJof9AYxUs/JQOeYEekDVCbxiCEXpD+HBPfeCO5bwxFsvRqXwEEtLg9KtOLssqMYOxhmEYoTec5PUfQu360J2vYSskZ0Na/qnLjcVybI4f0ZOkzrgWElNPLs8q0WGvAVP2wXASI/QGzYlWeONHsPaB0J3TGoiVIaWFU3J1T9UI/chsehz6u6Hik6cuzyyGgV6T88ZwCkboDRorTHLw36E538AANG4bHp8HY7Eci4EBHbaZunh42CurRL+aOL3BDSP0Bo2VI+XoQWirDf75WvdB7/HhQmVhLJYjs+8N/dks/NTwdZbQG4ulwQ0j9AZN8+6Tvx9aE/zzjTQQa2FZLPt7g9+WSKPyET22MdtDyeaMQpAY06M3nIIReoOmpVrHd+NT4GCIhF5iIG+W5/XZpTDQZ7JYDqX9MOz4O5z1MYhPGr4+Nl6LvRF6gxteFQc3jANaqrXoZneHJk7fsFWLecIEz+sHnTf7dNUpg2bjY6D6YcEnRt7GWCwNQzA9eoMe3GvZA7llULRE97a72oJ7Tk+pD9wxFsvh9PfB+keh9MLRb35m0pRhCEboDdBeC30ntHgULdazUmvWBe983cf0YKwnx41F6kRISDXOG3d2v6z/VxU3jb5dZjF0NkJPZ2jaZXA8RugN0OIaiM0pg4IKkNjgxukbt+vX0Xr0IpA9zfTo3al8BNImQ/llo283aLE04RuDxiuhF5HlIrJTRKpF5E4P628RkS0isklE3haROa7lJSJywrV8k4j81u4/wGADloc+Z4aeZTl5XnCFfmixkZEwFsuTtO6H6ldg/o0QO8bQWtY0/WoslgYXYwq9iMQC9wOXAXOA6ywhd+NPSqm5SqkzgZ8A97mt26OUOtP1c4tdDTfYSPNuHSaxUhEULYGayuBlj2yo0jNfM4tG3y67VAtcf19w2hFJrH9Uu5Tm3zD2tla6YhOnN7jwpke/CKhWSu1VSvUATwAr3DdQSrW7vU0BlH1NNASdlmodn7dSERQt1jH7+s3BOd9IqQ+Gkj1dWyzHexbLvm7Y8BjMvAwyCsbefkKOvnGPN6Hf/gLsezPcrXAk3gh9AeD+TatxLTsFEbldRPage/Sfc1s1TUQ2isgbInKupxOIyM0iUikilU1NTT4032ALLbt1fN5i6mL9GgybpVJjO24sjPNGs/1vcLx5eF6bkRAZfxbLLU/Bkx+DV/473C1xJN4Ivadu17Aeu1LqfqVUKfA14FuuxYeBIqXUWcAXgT+JSLqHfR9USlUopSry8vK8b70hcHq74OghHZ+3SJukRTYYcfq2GuhuM0LvC5W/18I9/ULv98ksHj89+upX4dlb9A2uebfuTBhOwRuhrwGmur0vBEZLjfcEcCWAUqpbKdXi+n09sAco96+phqBwZC+gtIfenaIlukdv95dmMPXBKNZKi7R8iJ8wvoW+cQcceBsWfBJifDDJWV76aBe9mkrdk8+bBed/Q3cijjWGu1WOw5srZx1QJiLTRCQBuBZ43n0DEXFXifcBu13L81yDuYjIdKAMCM63tqsN1vwW6rcG5fBRi5XMbOgEnKLFcLzl5Hq7sBw3E2ePva2Icd6s/z3EJuiUB76QVaLHWaJZ9Bp3wONXQeok+NjTUFihlzfvCm+7HMiYQq+U6gPuAF4CtgMrlVJVInKPiFhZle4QkSoR2YQO0dzoWv4eYLOIvAs8BdyilDpi+18BepLPi1+DPa8F5fBRy6CHfsapy4uW6Fe74/QNVTqskDQsgueZ8eyl7+mETX+GOSt0jn5fiPYslkcPwmMf1DfBjz+rw425rmCBEfpheJXrRim1Clg1ZNldbr9/foT9ngaeDqSBXpOcBRNy7e+BRjsteyA1HxLTTl2eM0O7Nw6u8c7S5y0NVd6FbSyyS2HXS7piUkysfe2IBLY+o0MRY82E9YS7xXLqIlubFXY6m7XI93TCJ1fpzgBA+hTtNjJCP4zomhmbW2aE3leadw+Pz4MOm1hxervo7dJPEN4MxFpkT4f+Hj2IO96ofATyZp98uvIFa45CtA3IdnfocE1bDVz/BOS7dRpE9LVshH4Y0SX0OaVG6H2lpXp42MaiaLEOm3Q02HOuph06xOar0MP4C9/UbYS6Dbo3P9Z8A0/EJ+t0CdFksezrhieuh8Ob4eo/QPHS4dvklp9aW8EARJ3Ql8GxBuhqH3tbgy4wfeLIKELv6knaVYjEF8eNhTVIPN6Sm1U+oh1HZ3zE/2NEk8VyoB+e/rSeELXifpi53PN2uWV6gp1J6HYKUSb0LsEyvXrvsD4nT6EbgPx5EJdsn5++oUofz4qpekNqvt7nyD572hAJdLXpCUBzr4KkDP+PEy3pipWCv38Rtj8Pl3wfzrxu5G2tAVmjAacQXYVHLMFqqYaC+eFtSyTQPILjxiIuQVvW7IrTN2zVtkpfBlVjYsaf8+bdJ3U9XX8GYd3JKoHNT+qQR1yiLU0LC699T+f6OeeLsPSO0be1hL5pF0w+I+hNO4XqV2Dni4EdI7MIln1u7O18JLqEPqtEJ34yd3PvaKmGmDj9iD8SRYvhrft0DvnEVP/PpZQW+pmX+75v9vTxE3dVSodtpsyHKWcFdqysEkDpgctIrdK15jfw1v/orJ0X3TX29tnTtQaEY0B29Xegead2/vjLlDON0I9JXKK+Ixqh946W3Tql7Whpb4sW69J1tZUw/Xz/z3WsUU/A8iU+b5E9XRfdGA8Wy4P/hqbtcMX/Bn6sQYtlhJZjfPdJePFOmP0BeP/PvBuUjkvU13Sohb6/V4v82bfAJd8N7bm9ILpi9KAHZMdL7y9QmqtHjs9bFC7SPaRA4/Te5qD3hGWxbB8t80aUUPkIJGbA6R8K/FiDBUj2B36sULPrJXjuVig5Fz70sG83+HA4b1r26GvUn+s7BESh0M/QH3q05/gIlIF+Hfceq6eXlK4v3kDj9IOOGz+FHqLfedPZDNv+qgcbE1ICP15qPsQmRp7F8uAaWHmj9shf+yeIT/Jtf2s+zUB/cNrniUbX9T1xaKkOZxB9Qp87A3o7oeNwuFvibNoOQX/3qemJR6JoCRxaF1gBkIYqSJsCE7J933fQYhnlA7Ib/6h7hQu8TEc8FjExOpQZST36hir40zU67/5Hn/Y+VYY7ueX62j560P72jUTDNl2CM29m6M7pA9En9MZi6R2DycxGcNy4U7RY3zwbtvh/Pm9z0HsibYrumUa70G/6ExQvg4mz7DtmJFksW/fDYx/S8wc+/iyk+pmyPBw5bxq36e+SQ91NUSj0rh6qidOPTvMYHnp3BguR+Bmn7+/Vs2L9FfpBi2UUe+lPtOrBvBkX23vcSCpA8rfPQ1+XFvmxykyOhnVNh1LoG6pgkjPDNhCNQp82WfcIWqI8nhsoLdWQmA4pXvSaMgr0F8/fOH3zbhjo9c9xY5FdGt3/07pN+jVQS+VQskp0YrQTrfYeNxg07YTZ7/cuhfVoTMjW13WohL67Q2cJnejMgViIRqGPiXGJgunRj0rLbv2o6W0elaIlukfvzyB3IAOxFtnTtE1wYMD/YziZuo36dcqZ9h43UgqF9/dCR70O09lBKJ03jTv0q+nRh5jcGSZGPxYte7yLz1sULdZ5hFr9CJ80bIWYeO/CRCORPV0/1kfrIHvdRv03JmfZe9xIsVgeawCUTjVsB6HMYulwxw1Eq9DnzNBxyb6ecLfEmfQc164bX4R3sBCJH3H6hipd6i023vd9LaI9uVndJvvDNnBy1rPThd6aI5FeYM/xcsv1BL3OFnuONxoN2yA+ZfQZ5mEmSoW+TM/mDOXF3dsFP5+rJ7w4Hcu94stsydyZkJTpX5w+EMeNRTSnK+5shraDwRH6pHRIznb+gOyg0NsYuoHQ9Oobt7lyODlXTp3bskAIh8Wyabv27b58l441OpnB8oE+9OhjYnT4xtce/fEj0FEXuNCnF+iycdEo9IPx+SAIPUSGxTJShV4pxztuIGqF3tVTDeWArDXg2HMMVt8duvP6w0gFwceiaLH+4nQ2e7+PHQOxoKfAZ5VEp/OmbiMgwcu2GBFCX6vTUds1RpExFeKSgi/0xxp0TQcHO24gWoU+OVPbq0LZo6/fqm2dyz4Pm5+AAzYX1baT5mrdQ/Z1mr0/cXp/io2MRHZpdHrp6zbqHujQur12kVWix2RCmRLAV9rrIH2yf9W0PBETE5q8V4PXt+nRh4ecGScnBYWChq161P28r0J6Iaz6cmApA4LJaOUDR2PKWXqGqi9x+oatumh76kTfzzeU7Ok6dBNteYxqNwQvbAPaYjnQp3vNTqW9zr6BWIvcMj0JLZg0btOvpkcfJnJCaLEcjNOdpnvJl35fC5wTB2aVOumh95W4RF3Qxdce/aTT7OmpZU+DvhPRZbFsPwzH6oMs9CX61cnhm/Y6++LzFrnlehC6t8ve47rTsE0nj0vJCd45bCC6hb6zUZdlCzYdh3WczgpPzFkB087TlXGONQX//L7Q2aw/E3897UWL4fAmbdEci4F+aNxuT9gGojO5mTUQG8yKaE4X+oEB/R2yW+jzygEVXEtuo/MHYiGahd69rGCwseJ0+S5BE4HL79WJwF79TvDP7wu+JDPzRNESHQaoXT/2tkf26R64XTm6o9FiWbdRZz2062boifRCfQ6nWiyPN+sUGbaHboLsvBno12kbHDxRysIroReR5SKyU0SqReROD+tvEZEtIrJJRN4WkTlu677u2m+niFxqZ+NHZdBiGQKXRr0rq6P7PzxvJiy+VaeePbQu+G3wlpYx6sSOxdRF+tWb8E0gxUY8kV6oZ9hGk/OmboP2YCdMCN45YuMgo9C5PXpr7MDuHn12KSDBG5A9slfP1nZosRF3xhR6EYkF7gcuA+YA17kLuYs/KaXmKqXOBH4C3Ofadw5wLXAasBz4tet4wSdrmqt2ZAgslg1VkFGk3T7unPc1nWRt1Zed43hoqdZ+dH+zAyZn6RuaNwOyDVX6f5BnU9rd2DgdhoiWHr1Sukdvd34bTzjZYml56NMm23vchAmQOTV4PfoG56c+sPCmR78IqFZK7VVK9QBPACvcN1BKtbu9TQEsW8QK4AmlVLdSah9Q7Tpe8IlL0FOSQxK62er5rp6YBpd8T8e0N/wh+O3whuZqHQIJpPZq0RI49J+xb14NVdri5muFoNHInh49Fsu2Q3qafjAHYi2yinWGRSdid/oDd3LLdXglGDRuc3VknFlsxB1vhL4AOOT2vsa17BRE5HYR2YPu0X/Ox31vFpFKEalsarJx8DJnRvAnTfV26aeG/BFirKd/GIrPgVfv0bNEw42/1kp3ipZAT8fJHs1IjHQDDIRoslgOzogN4kCsRVYJdDZB97Hgn8tX2mshJs67lNm+klvuKisYhKynDVU6PBSfbP+xbcYboffkixv2LVNK3a+UKgW+BnzLx30fVEpVKKUq8vJs/GfnlgW/fmzTDp1XZyRBE4HLfwJd7Vrsw0l/n6tObKBC70Uhkq523YMMhtD3drqyHUY4tRv0mEMoYryW88aJvfr2Op2eOBi5YnLLofd4cOYQNG6LCMcNeCf0NcBUt/eFQN0o2z8BXOnnvvaSU+r6JwfxlIMz4+aOvM2k02DRzbD+Uf3lDhdtB7W7IVChz5yqB0ZHi9M3btevdrtJcqLIeVO3UV8boSg/52SLZTA89BbBct70dOoQosMnSll4I/TrgDIRmSYiCejB1efdNxARd1P2+wArXvI8cK2IJIrINKAM+E/gzfaSnBBYLBu26hwd2dNG3+6Cr+tH01VfCV/xDF/KB45F0WIt9CM9LdntuLGIFoulUsFLTeyJzBL96kSLZUiE3uYQbtMOQEVPj14p1QfcAbwEbAdWKqWqROQeEbnCtdkdIlIlIpuALwI3uvatAlYC24AXgduVUqGzn4Qii2XDVv3PHmtwMykD3nsP1FbCpseD157RCNRD707RYj3J5ehBz+sbqiAxQ9v67CSjSMdzI91ieWSvLvEXzIlS7kzIhoQ05/XolQqu0Kfk6vTadqdCaLBSH0SG0Md5s5FSahWwasiyu9x+//wo+34f+L6/DQyI9Cmu+rFBEnqldDKz2e/3bvt5H4H1v4dX7tb72F1NaCxaduuLfoIN07XdE5xleSi4YGfqA3di47SbKtJ79MFOTTwUEWdaLE+06kl1wRJ6keCUFWyo0tqSNcaTvEOI3pmxoP/JOaXBE/qO+lNTH4xFTAxc/j/64n79B8Fp02hYjhs7xHfibN1j9xSnd8/9Ewws500kU7dRp9G1a46BNzjRYml3HnpP5JXbH6NvdFVNc3CxEXcio5WBkDMjeJOm/EnBO3keVNwE6x6Gw5uD066RaK62Jz4POlQ1dZFn583Rg9p+GWyhj2SLZd1GyJ8bWHlFX7F69E763ILpobfILXfljT9q3zEbIsdxA+NC6Mt0LyYY9WMbXKkPfP2HX/gtHbZZ9ZXQfem6j+lKT3bE5y2KFuvKWkPnB9iZg94TOaW6wEunwxLGectAPxx+NzT+eXeySvSUfSdZU4OV/sAda0DWrif7Y406P0+EOG5gXAj9DFAD0BqE2ZQNVbqSja+x9uQsuPg7cGgNbH7S/nZ5wsrgZ6vQu+L0h4YYqQanhs+271zuRLrzpnm3vlGFKj5v4USLZcdhPbs0dVLwzmG3xTJCio24E/1CnxtE5019ADM/z/wYFCyAl78dmlTKLTZaKy0K5usJP0Pj9A1b9SBVYqp953LHEvpIdd6EeiDWItM1aO4ki2V7rRb5YIawMot1fie7UiFESLERd6Jf6K0erN1x+r5u3UPwNzwRE6NTGXc2wT9/bG/bPNFcDchJkbSD+GQtVkPj9MEciAWdkE1iI7dHX7cR4lPsvel6g5XIzkk9+vY6+5OZDSU2TqcqsEsDGrbpOTGpQUjZECSiX+iTMiBlov09+rFSH3hDwQKYfwOs/e1JX26waNmtw0x25+UoWqxT7VpVfHqO6zBRMPOrx8Zr0YpkoZ9yZmCJ5fwhPkmnGnCa0AczPm+RW2Zf6KaxKmL88xbRL/TgSm5m82P+YLGRUVIfeMNFd+ssl//4anAHZluqT1ZospOiJdDfczIc0bRDj4kEO39L9vTgVg4KFv29UL859GEbC6dZLINRK9YTueV6nK6/N7DjDPRD446IyEHvzjgR+lL7s1jWW6kPAgyFpOTARd+G/W/B1qftadtQlLLXWunO1LP1qxWnHxyoCoXQ73OWVdAbmnZo50vYhL7EOT367g7obg9Rj75cV0YLNMV16349wcv06B1IbpmOhdvqo92qXSV2PH4v+CRMPgNe/pa++O3mWKP2tdvpuLFIyYHcmXBwDX39A6GbMZhTqkXieEtwz2M34RqItcgq0b3oYBbM9pZ2V5H3kPToXZ2cQFMhRKDjBsaL0NtdVlApe3Otx8TqGbMdh2HtA/Yc051AyweORdFi+g+sYckPXuHQjnW6txPsGYORarGs26hnFNs5KO4LWSWA0kVPwk0oPPQWg0IfYJy+cRsgkBck63CQGCdCb3MWy2MNuidp54Dj1EVQtFT76u0OR9iZzMwD9ZlnEdvTRvbxPaQe3cmJ7BBM649Ui2XtBj0Qa3cOIG9xksUyFOkPLBLT9JNDoM6bhiqdqTaYNX6DwPgQ+qwSbcezK05vpeAdqaqUv8y7Rvc4Dm+y97jNuyE2UbtubGZv0zFueVN7oB+Yf4gs6eD1oxNtP88wMov1RJtI6tH3dWuhCFfYBtwmTTmgHGOwasWOhB3Om8ZtERefh/Ei9HEJ2m1gV4++Pki51ues0BOQNv/F3uO27NExbZvDKQdaOrn+obXUqIn0TZhEyYGnAPjjvjQOt52w9VzDiEvQN65IEvqGKl34JZxCnzpJJ1NzwoBse63OpGpnTeHRsLJY+vvE3HtCX28R5riB8SL04EpuZpPQN1TpCkt2pxmekA3ll8LWp8YuvO0LLbttD9vUtB7n+ofW0t3Xz+P/tYS4kiWDOVR2qkLufz0ERdkjzWJpDcSGKge9J2Ji9BwEJ1gsQ+Wht8gt1wP4HfX+7W9Zh02P3sHkzNCiYEd1J9dAbGd3H5X7j/D7f+3jSyvfZcX9/+I3/9yj3Sf+MvdqLZj73gi8naB9w637bRX6w20nuP6htXR09fLYp85mZn7aybw36YUsr5jNk+sOUdN63LZzeiSnFFoiKItl3Qbdg7UphDYwoDjYcpwXt9bzs9W7uO3x9Tzy9j7UWJ+HUyyWofLQWwQ6IGtNaozAHr1XhUeigpwZun5sx2HI8P3i6ujqpaqunW2HmrixcSdPHD2Nb33npUGNyU1NJD8jkR+/uIMXq+r56dXzmDExzfd2li+HxHQdvim90Pf9h9J6QPuHbfLQN7Z38dGH1nKks4fHP302pxdk6BVWwfBJp3HHhTP4y/oafvVqNT++ap4t5/VI9nRdpelEq34acjpW6UA/BmKP9/Sxo76D7YfbXT8d7Kzv4Fh3H6APOSktiVVb6ll/sJV7r5rHhIQRvt5ZJTpthVLhGxQGnU116sLQnS93pn5t3gXTz/N9/8ZtOuwVLsdUAIwvoQdXKoDRhb7tRC9VtW1srWtjS207VbVt7G3uBGCO7OemxH6OZZTz+UVlnD4lg7mFGUxM0wWeX9h8mLv+upXLf/k2X3pvOZ8+dzqxMT58meKTYM4VUPUcvO+ngY/u2+i4aTnWzUcfXkt9exePfWoRZ0zNPLly0ul6UK14KZMzkrl+URGPrTnAreeXUpKbEvC5PeLuvHG60Pcc1wXTZ1426mZKKWqPnmD7YXdRb+fAkeODnYq0xDhmT07nw/MLmDU5ndmT05k5KY2k+BgefHMvP35xB3saj/HQDRVMzfZw/WQW6xBGOG+QvV3auRbK0E1avi6n6K/zpqEK8maGPnWFDYwfoc91s1hOP/+UVQ3tXbyxs4m3qpt599BRDh45GXIoyEzmtCnpfPCsAk4vyGDB0RZ4ET5zzZW6cs0QPnDGFBZPz+Fbz23hh//YwUtV9dx79RmU5vmQyXHuNbDxj7DrH3D6h/34Y92wyUPf2tnDRx9ey6HW4zz6yUUsKB4iELFx8LmNOksgcNsFpTyx7iC/fHU3933kzIDOPSLuXvpQ9gz9oWGrzo00Qg76mtbj/GDVdt7a3UxHV9/g8pKcCcyenM4Hzypk9uQ0Zk9OpzArGRmhJ/6Z80qZNTmdz/5pAx/437e5//r5LJuRe+pG7umKwyX0HZbjJoRCLxKY86ZxG5ReZG+bQsT4Efq0yTpjYHM1PX0DVB44whu7mnhjZxM76vVs1IlpiSwozuIjC6cytyCD06akk5OaeOpxXto55uNbXloiv/3YAp5/t467/lrF5b94i69cOpNPLpvmXe++5Bzd3s0rbRD6ah0XDuAL3Xail48/spa9zZ08cuNCFk8foeasW8K0iWlJ3LCkhIff2sttF8xgxsQgpCzOKgEkMpw3tRv06xDHTf+A4tF39vPTl/WMzRVnFnDaFN1Ln5WfRkqi71/R88rzeGwtmOgAACAASURBVP6Oc7j5sUo+/ru1fOPy2XzqnGknbw7uQh+ugeFQeujdyS2H/W/7vl9nix47i7AZsRbjRugPtZ4gJXkqtZvXc+2/X6azp5/4WKGiOJs7L5vFeeV5zMpPG7GnNEjDVl0rMnb0j05EWHFmAUum5/CNZ7fwvb9v58Wtunc/baxQRkwszL0K1vxGX2ApARTzbq4OqDff0dXLjY/8h531HTz48QrOKcsdeycXn3nPdP645gA/f2UX/3t9EAQlzjU3IBKcN3UbITUf0k96xrfVtfP1Zzbzbk0bF8zM47tXnk5hlj0TcUpyU3jmtmV8eeW7fO/v26mqa+eHH5pLUnzsyWLu4RyQDUUJQU/klsHmJ3TFNV/qJTRaxXSM0DuKrt5+1u47whs7m3hjVyN7mjr5VXwm8+P2ceVZBZxXnsfSGbmk+tJjUkp76Gcu93qXielJPHRDBc9urOU7z1dx2S/e5KuXzuITS0uIGa13P/caeOdXsO1ZWPhp79s4lJZqmHGxX7t2dvdx06Pr2Frbxq8/Op8LZvk2ESonNZFPLC3h1//cwx0XtjMrP92vdoxK9rTI6NHXbRzszXf19vOLV3fz0Jt7yZwQzy+vO4sPzJs8difDR1IT4/j1R+dz/+vV/HT1LnY3dvDAxysoyEzTT3nhtFgOpj8I0WQpi8Gygrt9m88w6LgJYvrtIBI1Qq+UYl9zpw7H7Gpizd4WunoHSIiLYfH0HK4/u5hlRxeTtf4/fP8D5bo36CtWrUgf/9kiwofmF7JsRi5ff2YL97ywjRer6rn3qnkU54zQu8+fq/NpbF7pv9B3tcOxer/SE3f19vPpP1Sy/kArv7puPpeclu9XE25+z3Qe+/cBfrZ6Fw98vMKvY4xKTilUPWv/ce2ku0PHhedexTt7mvnGM1vY33KcqxcU8s33zSZzQkLQTh0TI3z2ojJmT07nC09u4opfvc2vPzqfs220WHb19vPytgb+urEWEeGi2RO5cNZEJqWPMhGq/bDO+ZPohzMtEPIs542PQt9YpW+OqSGY9R0Eokboa1pPcOFPtfd8em4K1y0q4rzyPM6elkNygmuUfPNpUDmgU5VO9CMfi5X6wM+7+qT0JH53YwVPra/hnr9tY/nP3+Lrl8/iY2cXD+/di8C8q+HVe/QX0oqr+oKf5QO7evu5+bH1rNnXws8/cibvm+d/rytzQgI3nTONX7y6m621bSftmHaRPV27R44fca7z5vC7gOJ3ezP47j/WUpwzgcc/ffbwQdIgcvGcSTx3+zJu/r9KPvrwWlYX5VHSugN/nyGUUmw4eJSn1tfwwuY6Orr6KMhMRgRe2a4nzs0tyOCi2RO5aNYkTi9IP/WJpb029PF50FlVJdb3AdkGV+qDcNpRA8AroReR5cAvgFjgYaXUj4as/yLwaaAPaAJuUkodcK3rB7a4Nj2olLrCprafwtTsCfzP1WewqCSbopwR4pxWz7alOkCh93/ChIhwdcVUzinL5c6nt3DXX6tYteUw9151xnAr3FyX0G/5C7znK76frMX3guA9fQPc/vgG3tzVxE+umseKMwOPoX7q3Gk8+s5+7lu9i0c+YbM7ZtB5s8+RQq+UYlvlG5wGPLA7nVvOK+ULF5fpWHmImTExlefuWMYXntjEquoEbok7RF9PN4kJ3j/d1h09wbMba3lqfQ37mjtJjo/lsrn5XLWgkMXTchCBXQ3HeGV7A6/taOQXr+7m56/sZlJ6IhfOmsRFsyaybEYuye11oQ/bgE6dkT3NN6EfGNDW2PkfD167gsyYQi8iscD9wHuBGmCdiDyvlHKvfbcRqFBKHReRW4GfAB9xrTuhlAqSv+5UrlpQOPoGg156P6fnN1TpwSMbBGVyRjKPfnIhKysP8d0XtnPpz9/k65fP5uLZE1EKBpRCqVzyppxN7MYnqJl9KwoYUACKAYXbdvoVID42hqT4GJLjY0mv30EiAlnTvOq59fYP8Lk/b+TVHY1878rTuabCnhmc6Unx3Pye6dz70k42HGxlfpGNqSOyXTfvI3uhcIF9x7WB2qMn+PZzW7lyz1vkxefx+zsu57QpNj/R+Eh6UjwP31DB6j+eTuze57n1gb/z3RsvHzXMcqKnn5eq6nlqfQ3/2tOMUnD2tGxuPb+Uy+dOHjbONTM/jZn5adx+wQxajnXz+s4mXtvRwN/erePP/zlIYlwMaxMP0Dy5mNS2LvIzQpTrxiK3HJp8EPqjB6C3M2IHYsG7Hv0ioFoptRdARJ4AVgCDQq+Uet1t+zXAx+xspG0M1o/1c8JEvY056NG9+48sLOKcsjzufHoz335uK99+7tRtro89nR/E/4477nuUKuVbMY9fxv+LMyWX8+96laT4WJLjY0mKjyXRdSNIio8dvCkkxsfS0NZF5YFW7v7AHD62uNi2vxPgE0tL+N3b+/jZ6l089qmz7Tuwm8Wys7uPAaVIS4q37/h+0D+geOzf+7n3pZ0MKPhZag1pxYuZGGaRt4iJES49ZzHshd6mvbz/V2/z248tYEHxyRuwUorKA608vb6GFzYf5lh3H4VZyXzuwjI+PL9w5KfmIeSkJnLVgkKuWlBIT98Aa/e18Pq2OtI3HuEP+4Wf/fBVTi9I58JZk7h49kTmTE4nLjbImVlyy6D6FejvG9M9B7hy0BORqQ8svBH6AsC9SkENMNo39VPAP9zeJ4lIJTqs8yOl1HNDdxCRm4GbAYqKirxoUgDklvmXw7yvR1enKb/U9iYVZCbzfzct4tXtjTQd6yZGQBBEIKG3mIGX/8Av5uykau4HAYgRvS5GBEHfMERAgN5+RVdvPyd6+1n6r1Y648q4bdaMwWVdvQN09fXT1dOvX3sHaO3spauvn97+Ae7+wBw+ucz+6lApiXHcct50frBqB//Zd4RF02wKs8QnQXoBjfu3ceHrr3Ksu4/peSnMK8hgbmEmZxRmMGdK+sjpAGxmR307dz69hU2HjnJeeR7fX15IxoOHoOCmkJzfa1xjPj+4II2PrIvl2gf/zXdXnM655Xk8s76GpzfUsL/lOBMSYrl87mSuWlDIopLs0Z1iY5AQF8O5ZXmcm9cFGxXXXnQ28TKT17Y38r+v7eaXr+oOWFyMkBgX4+qI6I5JUtzJ16R4t3Wu7ax1OakJTM2eQFH2BAoykz2HyHJn6jrHRw94Z1SwHDd5IaizECS8ufo9/Wc9Zk0SkY8BFYB7IokipVSdiEwHXhORLUqpU5RWKfUg8CBARUVFcDNU5ZTCjlW+79e8U+eMCdJdXUS4eM4kD2umwv5LmVH7MjM++nPvp18rBa8eInf++Xz50pm2ttVfPr64hIfe2sd9q3fyxM1LbDtuU0IBtXurKMxO5vK5k9lS28aavUd4bpP2ascIlE1MY25hBvMKM5hbkMHsyekBxcmP9/RR39ZFfXsXDe1d1Ld1s7+5k6c31JCeHM8vrj2TK86Yguz9p94hnKmJPZFeABLL5IEGnr/jk3z2zxu585ktg6uXTM/hjgvLuOz0fL8mbY2Ky0M/qbCU28pmcNv5MzjS2cM/dzZS03qCLleHpLvvZMek2+qk9PZzrLtPb9N3cll33wA9facmE7Ty/xRlTxgU/6KcZGb35TMLUM27EG+EvrFK3xh98d07DG/+gzWAe7C2EKgbupGIXAx8EzhPKdVtLVdK1ble94rIP4GzgPDNcMmZoS2SJ1p9SzNs1YrMnxucdo3GvKth599h35tQeoF3+3Qc1nHFYJUP9IPkhFhuO7+U//7bNt6pbmapDa6Th9/ay4T6FN6fsIMnP7OEjOSTYZvG9i4217SxubaNLTVH+efORp5aXwPoXmP5pDQt/IUZzCvIZGZ+GnExQnNnNw1t3dS3u4T8FEHXv7unKbBIS4zjyrMK+Mbls8lOcVkmB2vEhmSYynti4yBzKrTuJ3NCAr//xEIefWc/J3r6ufKsAs85cuyiY/is2OyUBD40f4wxtjEYGFA0d3Zz6MhxDh45zsGWExw8cpxDR47zr+pmnm7XdXLTOcbmJLj38b+xOnPCKTeCrJR4YkSIjRFiRYiJEZYd2syJtFKqdjaeslxvx+D2MSIU5UwgPcyhQ094I/TrgDIRmQbUAtcC17tvICJnAQ8Ay5VSjW7Ls4DjSqluEckFlqEHasPHYFnBPVDog6+7fouu0pTtuyc9YAYzWq70XuiDXD7QX65bVMSDb+7lp6t3saQ0x+9JQgMDih+9uIMH39zLfQUzSG95DegETiZam5iexMVzkgaflJRSHG7T4r+l9iiba9p4saqeJ9bpyGR8rKAU9A2c+lAZGyPkpSYyKSOJ6XkpLC3NYVJGEvnp+sf63WPPt26jtvTZXbvADty89HGxMXz63BBlZQxS+oOYGGFiWhIT05KG52JC24Zrj2rxP/F0Du9Nb6c6PYWDR46zZm8LnT3Da0Ak0Mu2xH08cmQu9/1+3ZhtyEiO52vLZ3HtwqkBhbnsZkyhV0r1icgdwEtoe+UjSqkqEbkHqFRKPQ/cC6QCf3F9cS0b5WzgAREZQOe+/9EQt07ocXfe+CL0DVXakunN4I3dxCfD7Ctg21+9z2hpZeizKT2xXSTFx3L7BTP41nNbeWNXE+fP9H0CSk/fAF996l2e21THDUuKWVF2Lqx8UDtvRsndIiJMyUxmSmYyy0/XE8CUUtS0nmBH9V7SNv6GgxkL6So+n0kuEc/PSCI3NdG3DKTu1G3U9YCdSGYx7Hgh9Odtr4O4ZEjKHHtbG0mKj6U0L1UnGJw8m7MGGnnwBq0BSimOdPbQ3tVH/4BiQCn6BxQJTVuJe2aAK977XpaVLGVAKQYGFP1KMTCA61Vv39M3wB/+vZ9vPLuFp9Yf4ntXzmXOlCDMBvcDr1RLKbUKWDVk2V1uv3ucY6+UegcIQ6xjFAbrx/posWzYCmX2D8R6zbxrYJMPGS1b9ugvUyizA3rJNRVT+c0/93Df6l2cV57nU6/+WHcft/5xPW/tbuYrl87ktvNLkUaXS2MMofeE9PcwdduDTH3zf6Cng8WtL8D71uqUtoFyrAnaDsHZnwn8WMEgq0SnCu7uCO0MVWuyVDgnH+WVw9ZnBnPyiwg5qYnDkxg2HgSgZM5CSvLGfipbfno+z26s5ft/384H/vdtblpWwhcuLrd/nMNHxk+FKQurfqwvOamPNUJnU3jtVYMZLb2sJ2uVD7S5TqwdJMTF8LmLZrC5po1XtjeOvYOLpo5urntwDe/saeEnV83j9gtm6JuENWvYl5w3SsG25+H+RfDK3VCyDK5fCX1d8ML/s6dqlVXk3WkDsRaDWSxDnPMm1CUEPZFbDl1H9Y1uNBq2+hSytdKdvPql87imYioPvbWPi+97g5eq6seu/BVEnKcCoSDHR4ulNSM2P4wJjWJidU++erXOaDkWLdV+5bgJFR+aX0hxzgTuW72LgYGxvwAHWjq56rfvsLuxg4duWHDqZK6ECfrJxVuhP/wuPPp+WPlxiJ8AH38Wrn9SW2cv/DbsXKVnIwdK3UZAYPIZgR8rGLinKw4loS4h6Alvywo2bNO9fx9DtpkTEvjhh+by9K1LyUiO5zOPree//q8y+OU1R2CcCv0MLYTe1o+tDyzHjW3M+4i2eG4bI4lXX4/upTksPu9OfGwMn7+ojO2H23mxavRizVtq2vjwb96h/UQvf/6vxVw4y4MNNad0bKHvaIC/3g4PnAdN2+F998Fn3jq1ZOPiW6FwEaz6it4+EGo36J5jqBN3eYsl9KHMYjkwoB1hTujRw9hC37gNJvr/JL+gOIsXPnsO37x8Nu/saeG9973Jb9/YQ28gdaX9YHwKfe4M6Dtx0uY1Fg1VuscY7lwq+XP1pI2xwjet+3U1oxznCj3oIhuleSn8bPUu+kfo1b+1u4lrH/w3iXGxPHXrUs4aKX1C9rSRn9J6u+Ctn8Kv5sO7T8KS2+GzG2Dhp4b31GJi4cpf2xPCcUtN7EiSs7SbK5Q9+s4m3VkJt9CnF+oxrNFSIRw/om9KARYbiYuN4b/eM53VXzyPc8ty+dE/dvC+X77Fuv1HAjquL4xPobecN97G6RvsTX3gNyJ6UPbQmtG/nDaVDww2sTHCFy4uZ3fjMV7YPPym+9zGWj75+3UU5aTwzG1LRy/HmD1dz4/oaju5TCmdwvj+hTo53PTz4fa1cOn3IXkUx0duGVz4LT13YctT/v1x7Yd1imgnC72IHq8KpdAP5qEPs9DHxOgO32g9eiv1QQA9encKMpN58IYKHrqhgs7ufq7+7b/56lPvcqSzx5bjj8b4FnpvnDd9PdC0M7zxeXfmXq1fR4shD3ronRujt3jf3MnMyk/j56/sps/tcfahN/fyhSc3sbAkmyc/s3j03Obgltxsn36t3QC/vwz+8gnda73hebj2ce8/k8W3QeFC+IefIZzBiVIOFnrQFsuQCn2YSgh6Infm6EI/WGzE3mRm750zidVffA+3nFfKMxtquein/2Rl5aGgDtaOT6G36sd6I/TNu2CgN/zxeYvMIihaoidPjXRhNO+GlLzRe60OIcbVq9/X3MmzG2sZGFB874VtfH/Vdt43bzKP3rTQu5mGVrriA/+CZ2+Fhy7Qn8MHfgGfeROmnzf6/sMaFgsrfg09x+HvX/Q9hFO3Qdt4wzGT2heySuDoQe/HqwIlXCUEPZFbrv/23hOe1zdWaa9/mv3plCckxHHnZbP4++fOpTQvla8+tZmPPLCGXQ0dtp8LxqvQi+ienTdCb6U+cIrQgw7fNO9yFbTwQEu14+Pz7lx6mi5M8cvXdvP/Vm7i4bf38YmlJfzq2rNIjPMyH022KxHbS9+ArU/Bss/D5zbAgk94nx9oKHnlOoSz4wXY+rRv+9ZthImzvZvcFk6ySvR4xLEAB569pb0WYuJhQuiKroxIbhmgRh7badimQ7ZB9PvPzE9j5WeW8JMPz2NXYwd3/GmDVy40XxmfQg+uLJbeCP0WiE1wVrx7zpX6yzJS+Mbh1sqhiAhffG85h46c4K+b6vja8lnc/YE5vk0hT0iBmZfrz+b2/8B779FpqQNlye06hLPqy3o+hTco5RqIdVh+G09kuW6QoQrfWAVHnDC/Y9B5s3P4OqV0sZEQ5KCPiRGuWTiV1750Pj//yFlBSZ3ggE87TOTM0I9tfd2jb9dQpZ0u4Uh9MBITsqHsEj1QODAkP8eJo9rZ4GBrpScumDmRz5w3nV9edxa3nl/qXw6c6/4M1/zhZO/eDmJiYcX9OoTjrQun7ZCeiOP0+DzowVgIncWy47Azwjbg6gyJZ1PG0YPQ02F7fH40slMSgpYyYRwLfRmogZODdyNRv9WZcdZ5V2tXx743T13uR/lAJyAifP2y2VxxhgMG6YaSNxMu+Ib3IZzaDfp1im/pGMJCxlRAQtijrw1KzNsv4pNds+Q9DMja7LgJN+NY6K36saNYLI81QmejM6yVQylfDglpw8M3g9bKyOrRO56ln4WCCj2RaqwQTt1GHVpz4nUzlPgk7YAJhdAr5Yz0B+7klnsWemtsbuLs0LYnSIxjoffCYunEgViL+GSYs0Lna3F3DbRUa7eHNevRYA/WRKqezrFdOHUbtcjHeV90O6yEymJ5olUP/DoldAMuofcwS75xG2QUQZIzsk8GyvgV+qR0SJ2k/8kj0eCQ1AcjMe9qHUfc6Va5sXm3fhyNSwhfu6KVvJlwwddh+9+g6hnP2ygFdZsiIz5vkVUSmsRmTpks5U5umZ4l315z6vKGbSGNzweb8Sv0cDLnzUg0VOl4YkpO6NrkCyXn6va5h29a9kRcfD6iWPJZKFgAf/+yTkM8lCN7obvN53TJYSWrRKcD6e0K7nmc5KG3sJw37qkQ+np0CDQEjptQYYR+tBh9vUNSH4yEldFy98s6L8fAQMR56COO2DjXRKpjsOpLw9dHyoxYdwadNweDex5H9ug9JDdr3hXU+tDhwAj98RYtkkPp74WmHc4N21jMu0ZflFXP6l5Z34mI8tBHJBNnwflf1xW/qoZkEq3bCHFJ2pIbKYQqi2X7YZAYHTJ1Cim5kJx9qtAPOm5Mjz46sLzmntLbOi31wUjkz3NltFzp2PKBUcnSz2n75N+/dGoIp26jtuPGOq9A9IiEKi99e50WeSfNSQHXgKzbk31DlXZNRdH3aHwL/WhZLAcdNw5/fBPRic4OrYE9r+llJnQTfGLjtAunu0PPmgU9ea1uU2T4591JnaSfQoIu9LXOCttY5JYN79HnlkfWzXoMxrfQZxaPXD+23pX6IBLu6lZGy3UPQ0KqPfVODWMzcTacfydse06HcJp3Q29nZMXnQXcWQmGxdJqH3iK3XM+XOdGq30eZ4wbGu9DHJejHVk8Dsg1V2k4XCXf1rGKd0bL3uI7Ph7Po8nhj6edh8pnahVO9Wi+LNKGH0FgsnVBC0BODA7K7dQqR9hrnP8n7yPgWenA5bzxkr2vYCpMcmPpgJKxevbFWhpbYOLjyN9DdDq/8t05/HQlPgUPJKnFVJgtSTvSudj3nw4k9+jw3503jdv17lKQ+sDBCn+sqFO4+M+5Yk07bGkl39dM+qEUmf164WzL+mDQHzvuaHryfcqb/aZHDSVaxFmJPDjQ76DisX53Yo88s1mHa5l06Bz1EXejGYcPfYSCn1DUzrhYyp+pl1oxYp1SV8oYJ2fDZ9TDBoZO7op1lX9COmxkXhbsl/jFosdwfnAmClofeKQnN3ImJ1U/Czbuh+xgkZjjzhhQAXvXoRWS5iOwUkWoRudPD+i+KyDYR2Swir4pIsdu6G0Vkt+vnRjsbbwuWQ8V9QNbJOW5GI32ySX0QLmLjdKnCipvC3RL/CLbF0kklBD2RW6ZLhja6BmKjbJxrTKEXkVjgfuAyYA5wnYgMfa7ZCFQopeYBTwE/ce2bDdwNnA0sAu4WkSz7mm8DnpKbNVRBar6eTGEwjAcyXX2zYAu9E3v0oAdkW/fr734UTZSy8KZHvwioVkrtVUr1AE8AK9w3UEq9rpQ67nq7Bih0/X4psFopdUQp1QqsBpbb03SbSMvXlsRThH5LZMXnDYZASUzV5f3Gqs/gL+21+vjxYxR5Dxe55aD69aB6lMXnwTuhLwAOub2vcS0biU8BVjpFr/YVkZtFpFJEKpuaPCSKCiZW/Vhr0lR/r36Ei6T4vMFgBxNnj1yHOFCc6qG3sCyWEHWOG/BO6D0Fqzx6sETkY0AFcK8v+yqlHlRKVSilKvLy8rxoks24Z7Fs3g39PZEXnzcYAqV4mZ4o2NVm/7Gd6qG3cLclR0mxEXe8EfoaYKrb+0KgbuhGInIx8E3gCqVUty/7hp2cMp25r7crclIfGAx2U7wUUHBwrf3HdnqPPjEV0gv1T3JmuFtjO94I/TqgTESmiUgCcC3wvPsGInIW8ABa5N3rrL0EXCIiWa5B2Etcy5xFzgxAQes+HZ+PiT/1Uc5gGA8ULtTX/oF/2Xvc3hNw4oh2hTmZmZfB7PeHuxVBYUwfvVKqT0TuQAt0LPCIUqpKRO4BKpVSz6NDNanAX0Tbkg4qpa5QSh0Rke+ibxYA9yilgjQjIwBy3ZKbNVTpbJCRkPrAYLCThAm6YIrdQu/EgiOeeN//hLsFQcOrCVNKqVXAqiHL7nL7/eJR9n0EeMTfBoaEbKtQeLUuNlJ6QXjbYzCEi+Kl8M6vdG3chBR7jul0D/04wKRAgJP1Yw+thWP1Jj5vGL8UL9OFbGrWjb2tt0RKjz6KMUJvkVN2Mp+7cdwYxitTz9ZVoA68Y98xnZz+YJxghN4ip1TbKsEIvWH8kpSuE+PttzFO33EYkjK0s8UQFozQW1ipZVMnQWoYvPwGg1MoXqZDN33dY2/rDe11kGbi8+HECL2FNWHCxOcN453ipdDfDbUb7DmeU0sIjiOM0FtYWSxN2MYw3ilaol/tslk6fbLUOMAIvUX2NJ1idt414W6JwRBeUnJ0Bkc7hL6vB441GsdNmDGFRyxiYuH9Pwt3KwwGZ1C8FDb9Gfr7dK59fzlWDyjTow8zpkdvMBiGU7wUejuhPsBslsZD7wiM0BsMhuEUL9OvgfrpB4XeeOjDiRF6g8EwnLR8nRrENqE3oZtwYoTeYDB4pnipFvqBAf+P0V4H8RMgKfpS/0YSRugNBoNnipdB11FdMNtfLA99lBXbjjSM0BsMBs8UL9WvgYRvjIfeERihNxgMnskqhoypgfnpnV5CcJxghN5gMIxM8VIt9MpjmejRGejXPnrTow87RugNBsPIFC+FziZdlMdXOpt0bnuTnjjsGKE3GAwjM+in9yN8Y+WhN6GbsGOE3mAwjEzODEiZ6N+ArPHQOwYj9AaDYWREdPhmvx9xepP+wDEYoTcYDKNTvAzaa+DoQd/2a6+F2ASYkBOcdhm8xgi9wWAYHX/99O11eiA2xshMuDH/AYPBMDoT5+gUBr4OyLYfNvF5h2CE3mAwjE5MzMm8N75gSgg6Bq+EXkSWi8hOEakWkTs9rH+PiGwQkT4RuWrIun4R2eT6ed6uhhsMhhBSvBSO7IGOeu+2V8qkP3AQYwq9iMQC9wOXAXOA60RkzpDNDgKfAP7k4RAnlFJnun6uCLC9BoMhHAzG6b0M3xw/oguMG8eNI/CmR78IqFZK7VVK9QBPACvcN1BK7VdKbQYCyGdqMBgcS/4ZkJDqffhmcLKU6dE7AW+EvgA45Pa+xrXMW5JEpFJE1ojIlZ42EJGbXdtUNjU1+XBog8EQEmLjYOrZPgi98dA7CW+E3lMiaV9mThQppSqA64Gfi0jpsIMp9aBSqkIpVZGXl+fDoQ0GQ8goXqpz03e2jL2t1aM3eW4cgTdCXwNMdXtfCNR5ewKlVJ3rdS/wT+AsH9pnMBicgpX35uC/x9624zBIDKROCm6bDF7hjdCvA8pEZJqIJADXAl65Z0QkS0QSXb/nAsuAAMrVGAyGsFEwH+KSvAvftNdBar4O+RjCzphCr5TqA+4AXgK2AyuVUlUico+IU8mjjQAACPVJREFUXAEgIgtFpAa4GnhARKpcu88GKkXkXeB14EdKKSP0BkMkEpcIhQu9c94YD72j8Op2q5RaBawasuwut9/XoUM6Q/d7B5gbYBsNBoNTKF4Kb94LXe2QlD7ydu11kDcrdO0yjIqZGWswGLyneCmoATi0duRtlIK2WuO4cRBG6A0Gg/cULoSYuNHDN93t0NtpQjcOwgi9wWDwnoQUmDJ/9AHZ9sP61Qi9YzBCbzAYfKN4KdRugJ7jntebWbGOwwi9wWDwjeJlMNALNes8rzclBB2HEXqDweAbRWfryVAjhW8soTezYh2DEXqDweAbSRmQP3fkAdn2WkjJ0757gyMwQm8wGHyneJkO3fT1DF9n8tA7DiP0BoPBd4qXQl8X1G0Yvq69DtKM0DsJI/QGg8F3ikYpRNJhevROwwi9wWDwnZQcyJs9fEC25zicaDVC7zCM0BsMBv8oXgoH10J/38llHdZkKZP+wEkYoTcYDP5RvBR6OqBhy8llZrKUIzFCbzAY/MMqRLLfLU5vSgg6EiP0BoPBP9InQ/b0U+P0gz16M1nKSRihNxgM/lO8FA6+AwMD+n37YT2hKiElvO0ynIIReoPB4D/Fy7TLpmmHft9eZ8I2DsQIvcFg8J/iIX56U0LQkRihNxgM/pNZDOmFbkJvJks5ESP0BoPBf0R0r/7AO9DXDZ2NJnTjQIzQGwyGwCheCscaTvbqTY/ecRihNxgMgWH56bc8pV9NQjPHYYTeYDAERm6Zzj+//W/6venROw4j9AaDITCsOH13u35vhN5xeCX0IrJcRHaKSLWI3Olh/XtEZIOI9InIVUPW3Sgiu10/N9rVcIPB4CCs8E18ip4wZXAUYwq9iMQC9wOXAXOA60RkzpDNDgKfAP40ZN9s4G7gbGARcLeIZAXebIPB4CgsP336FN3DNzgKb3r0i4BqpdRepVQP8ASwwn0DpdR+pdRmYGDIvpcCq5VSR5RSrcBqYLkN7TYYDE5i4hzdkzc5bhxJnBfbFACH3N7XoHvo3uBp32EmWxG5GbgZoKioyMtDGwwGxxATC8t/DCm54W6JwQPeCL2n5zDl5fG92lcp9SDwIEBFRYW3xzYYDE7izOvC3QLDCHgTuqkBprq9LwTqvDx+IPsaDAaDwQa8Efp1QJmITBORBOBa4Hkvj/8ScImIZLkGYS9xLTMYDAZDiBhT6JVSfcAdaIHeDqxUSlWJyD0icgWAiCwUkRrgauABEaly7XsE+C76ZrEOuMe1zGAwGAwhQpRyVki8oqJCVVZWhrsZBoPBEFGIyHqlVIWndWZmrMFgMEQ5RugNBoMhyjFCbzAYDFGOEXqDwWCIchw3GCsiTcCBAA6RCzTb1JxgYNoXGKZ9gWHaFxhObl+xUirP0wrHCX2giEjlSCPPTsC0LzBM+wLDtC8wnN6+kTChG4PBYIhyjNAbDAZDlBONQv9guBswBqZ9gWHaFximfYHh9PZ5JOpi9AaDwWA4lWjs0RsMBoPBDSP0BoPBEOVEpNB7Uaw8UUSedK1fKyIlIWzbVBF5XUS2i0iViHzewzbni0ibiGxy/dwVqva5tWG/iGxxnX9YFjnR/NL1GW4WkfkhbNtMt89mk4i0i8gXhmwT0s9QRB4RkUYR2eq2LFtEVrsK368eqR6yiNzo2ma3iNwYwvbdKyI7XP+/Z0Ukc4R9R70Wgti+74hIrdv/8PIR9h31+x7E9j3p1rb9IrJphH2D/vkFjFIqon6AWGAPMB1IAN4F5gzZ5jbgt67frwWeDGH7JgPzXb+nAbs8tO984IUwf477gdxR1l8O/ANdJWwxsDaM/+969GSQsH2GwHuA+cBWt2U/Ae50/X4n8GMP+2UDe12vWa7fs0LUvkuAONfvP/bUPm+uhSC27zvAl734/4/6fQ9W+4as/ylwV7g+v0B/IrFHP2axctf7P7h+fwq4SCQ0pemVUoeVUhtcv3egc/gPq5MbAawA/k9p1gCZIhKOys8XAXuUUoHMlg4YpdSbwNBaCu7X2R+AKz3seimwWil1RCnVCqwGloeifUqpl5WuJwGwBl3hLSyM8Pl5gzff94AZrX0u7bgG+LPd5w0VkSj03hQcH9zGdaG3ATkhaZ0brpDRWcBaD6uXiMi7IvIPETktpA3TKOBlEVnvKs4+FK8Ku4eAaxn5Cxbuz3CSUuow6Bs8MNHDNk75HG9CP6F5YqxrIZjc4QotPTJC6MsJn9+5QINSavcI68P5+XlFJAq9NwXHAylobgsikgo8DXxBKdU+ZPUGdCjiDOBXwHOhbJuLZUqp+cBlwO0i8p4h653wGSYAVwB/8bDaCZ+hNzjhc/wm0Ac8PsImY10LweI3QClwJnAYHR4ZStg/P+A6Ru/Nh+vz85pIFHpvCo4PbiMicUAG/j02+oWIxKNF/nGl1DND1yul2pVSx1y/rwLiRSQ3VO1znbfO9doIPIt+RHbHCYXdLwM2KKUahq5wwmcINFjhLNdro4dtwvo5ugZ/3w98VLkCykPx4loICkqpBqVUv1JqAHhohPOG+/OLAz4EPDnSNuH6/HwhEoXem2LlzwOWu+Eq4LWRLnK7ccXzfgdsV0rdN8I2+daYgYgsQv8fWkLRPtc5U0QkzfodPWi3dchmzwM3uNw3i4E2K0wRQkbsSYX7M3Thfp3dCPzVwzYvAZeISJYrNHGJa1nQEZHlwNeAK5RSx0fYxptrIVjtcx/z+eAI5/Xm+x5MLgZ2KKVqPK0M5+fnE+EeDfbnB+0I2YUejf+ma9k96AsaIAn9uF8N/AeYHsK2nYN+tNwMbHL9XA7cAtzi2uYOoArtIFgDLA3x5zfdde53Xe2wPkP3Ngpwv+sz3gJUhLiNE9DCneG2LGyfIfqGcxjoRfcyP4Ue93kV2O16zXZtWwE87LbvTa5rsRr4ZAjbV42Ob1vXoeVEmwKsGu1aCFH7HnNdW5vR4j15aPtc74d930PRPtfyR61rzm3bkH9+gf6YFAgGg8EQ5URi6MZgMBgMPmCE3mAwGKIcI/QGg8EQ5RihNxgMhijHCL3BYDBEOUboDQaDIcoxQm8wGAxRzv8Hw7n79Tz/oSUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result)\n",
    "plt.plot(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25138924662023787"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27890962902070837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2768579797593501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
