{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:30:20.151038Z",
     "start_time": "2020-09-02T07:29:18.486999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: jdcal in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jmp08\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n",
      "      T_ID   GDAY_DS  HEADER_NO   P_ID  START_CK  BAT_ORDER_NO   PA   AB  RBI  \\\n",
      "0       HH  20160401          0  60404         0             3    1    1    0   \n",
      "1       HH  20160401          0  62700         1             9    2    2    0   \n",
      "2       HH  20160401          0  64086         1             7    6    4    0   \n",
      "3       HH  20160401          0  66740         1             5    6    6    0   \n",
      "4       HH  20160401          0  71347         1             2    6    6    1   \n",
      "...    ...       ...        ...    ...       ...           ...  ...  ...  ...   \n",
      "18679   WO  20161009          0  74215        91           374  402  341   80   \n",
      "18680   WO  20161009          0  78168       139           177  646  560   63   \n",
      "18681   WO  20161009          0  79130        15           251   80   66    7   \n",
      "18682   WO  20161009          0  79300        13           429  106   91    9   \n",
      "18683   WO  20161009          0  79365       122           965  454  411   70   \n",
      "\n",
      "       RUN  ...  BB  IB  HP  KK  GD  ERR  LOB  P_AB_CN  P_HIT_CN  GAME_COUNT  \n",
      "0        0  ...   0   0   0   0   0    0    1        0         0           1  \n",
      "1        1  ...   0   0   0   0   0    1    0        0         0           1  \n",
      "2        0  ...   1   0   0   3   0    0    1        2         0           1  \n",
      "3        0  ...   0   0   0   0   0    0    1        1         1           1  \n",
      "4        1  ...   0   0   0   2   0    0    0        1         0           1  \n",
      "...    ...  ...  ..  ..  ..  ..  ..  ...  ...      ...       ...         ...  \n",
      "18679   72  ...  46   3   9  50  16    6   77      121        35          92  \n",
      "18680  111  ...  69   2  10  58   6   15  113      118        36         140  \n",
      "18681   10  ...  11   0   1  24   1    1   18       20         3          40  \n",
      "18682   16  ...  10   0   0  16   3    0   29       25         4          81  \n",
      "18683   44  ...  27   0   7  93  18    7   71      132        33         127  \n",
      "\n",
      "[18684 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "%run batter_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T13:05:08.382310Z",
     "start_time": "2020-09-02T13:05:08.376351Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:136: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:134: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\jmp08\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from statsmodels import tsa\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from plotly.offline import plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "feature, target = batter_data(\"OB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeature = feature.loc[0:feature.shape[0]-20]\n",
    "trainTarget = target.loc[0:feature.shape[0]-20]\n",
    "\n",
    "testFeature = feature.loc[feature.shape[0]-20:].reset_index(drop = True)\n",
    "testTarget = target[feature.shape[0]-20:].reset_index(drop = True)\n",
    "trainFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "res = scaler.fit(trainFeature)\n",
    "res = scaler.transform(trainFeature)\n",
    "trainFeature = pd.DataFrame(res, columns = trainFeature.columns, index = list(trainFeature.index.values))\n",
    "res = scaler.transform(testFeature)\n",
    "testFeature = pd.DataFrame(res, columns = testFeature.columns, index = list(testFeature.index.values))\n",
    "\n",
    "res = scaler.fit(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "trainTarget = scaler.transform(np.array(trainTarget).reshape(trainTarget.shape[0], 1))\n",
    "testTarget = scaler.transform(np.array(testTarget).reshape(testTarget.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape = trainFeature.shape[1]))\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(8, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(4, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(rate = 0.3))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation = None))\n",
    "model.compile(optimizer = \"Adam\", loss = \"mse\")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(min_delta = 0.0005, patience = 30, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(trainFeature, trainTarget, epochs = 200, validation_split = 0.3, shuffle = True,\n",
    "          use_multiprocessing = True, callbacks = [early_stopping], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.548 - 0s 612us/sample - loss: 0.4830 - val_loss: 0.4061\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.574 - 0s 112us/sample - loss: 0.4305 - val_loss: 0.3750\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.331 - 0s 109us/sample - loss: 0.4409 - val_loss: 0.3460\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.439 - 0s 115us/sample - loss: 0.4113 - val_loss: 0.3183\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.442 - 0s 100us/sample - loss: 0.3716 - val_loss: 0.2930\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.282 - 0s 109us/sample - loss: 0.3588 - val_loss: 0.2712\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.304 - 0s 100us/sample - loss: 0.3507 - val_loss: 0.2508\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.319 - 0s 110us/sample - loss: 0.3309 - val_loss: 0.2321\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.262 - 0s 95us/sample - loss: 0.2901 - val_loss: 0.2149\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.367 - 0s 105us/sample - loss: 0.2955 - val_loss: 0.1983\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.340 - 0s 93us/sample - loss: 0.2830 - val_loss: 0.1828\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.329 - 0s 114us/sample - loss: 0.2634 - val_loss: 0.1676\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.375 - 0s 106us/sample - loss: 0.2843 - val_loss: 0.1539\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.120 - 0s 118us/sample - loss: 0.2334 - val_loss: 0.1423\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 120us/sample - loss: 0.2500 - val_loss: 0.1316\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 115us/sample - loss: 0.2046 - val_loss: 0.1226\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.249 - 0s 99us/sample - loss: 0.2282 - val_loss: 0.1136\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.186 - 0s 117us/sample - loss: 0.1742 - val_loss: 0.1057\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 113us/sample - loss: 0.1856 - val_loss: 0.0988\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.134 - 0s 110us/sample - loss: 0.1781 - val_loss: 0.0923\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 113us/sample - loss: 0.1853 - val_loss: 0.0868\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 108us/sample - loss: 0.1533 - val_loss: 0.0818\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.233 - 0s 112us/sample - loss: 0.1729 - val_loss: 0.0771\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.238 - 0s 105us/sample - loss: 0.1862 - val_loss: 0.0721\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.214 - 0s 122us/sample - loss: 0.1440 - val_loss: 0.0678\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 120us/sample - loss: 0.1514 - val_loss: 0.0639\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.147 - 0s 109us/sample - loss: 0.1574 - val_loss: 0.0605\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.248 - 0s 115us/sample - loss: 0.1500 - val_loss: 0.0565\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.233 - 0s 105us/sample - loss: 0.1470 - val_loss: 0.0528\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 112us/sample - loss: 0.1391 - val_loss: 0.0498\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 108us/sample - loss: 0.1267 - val_loss: 0.0480\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 88us/sample - loss: 0.1213 - val_loss: 0.0457\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 99us/sample - loss: 0.1322 - val_loss: 0.0436\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.169 - 0s 105us/sample - loss: 0.1305 - val_loss: 0.0417\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.155 - 0s 110us/sample - loss: 0.1247 - val_loss: 0.0400\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 110us/sample - loss: 0.1259 - val_loss: 0.0387\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.114 - 0s 97us/sample - loss: 0.1214 - val_loss: 0.0374\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.128 - 0s 111us/sample - loss: 0.1145 - val_loss: 0.0359\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 108us/sample - loss: 0.1103 - val_loss: 0.0343\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 103us/sample - loss: 0.1134 - val_loss: 0.0333\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.153 - 0s 104us/sample - loss: 0.1034 - val_loss: 0.0322\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 107us/sample - loss: 0.0978 - val_loss: 0.0309\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 105us/sample - loss: 0.1081 - val_loss: 0.0301\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 120us/sample - loss: 0.1072 - val_loss: 0.0293\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 117us/sample - loss: 0.1001 - val_loss: 0.0280\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 117us/sample - loss: 0.0959 - val_loss: 0.0268\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 100us/sample - loss: 0.1032 - val_loss: 0.0260\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 104us/sample - loss: 0.0886 - val_loss: 0.0255\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 97us/sample - loss: 0.0942 - val_loss: 0.0250\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 86us/sample - loss: 0.0787 - val_loss: 0.0248\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 91us/sample - loss: 0.0899 - val_loss: 0.0244\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 90us/sample - loss: 0.0831 - val_loss: 0.0239\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 99us/sample - loss: 0.0919 - val_loss: 0.0234\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 102us/sample - loss: 0.0740 - val_loss: 0.0229\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 101us/sample - loss: 0.0753 - val_loss: 0.0228\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 108us/sample - loss: 0.0803 - val_loss: 0.0225\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 108us/sample - loss: 0.0726 - val_loss: 0.0226\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 100us/sample - loss: 0.0802 - val_loss: 0.0221\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 101us/sample - loss: 0.0707 - val_loss: 0.0218\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 96us/sample - loss: 0.0730 - val_loss: 0.0215\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 100us/sample - loss: 0.0658 - val_loss: 0.0210\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 102us/sample - loss: 0.0644 - val_loss: 0.0207\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 98us/sample - loss: 0.0672 - val_loss: 0.0204\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 97us/sample - loss: 0.0746 - val_loss: 0.0202\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 95us/sample - loss: 0.0612 - val_loss: 0.0202\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 89us/sample - loss: 0.0636 - val_loss: 0.0202\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 110us/sample - loss: 0.0602 - val_loss: 0.0202\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 103us/sample - loss: 0.0563 - val_loss: 0.0200\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 86us/sample - loss: 0.0603 - val_loss: 0.0200\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 88us/sample - loss: 0.0575 - val_loss: 0.0197\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 98us/sample - loss: 0.0658 - val_loss: 0.0195\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0553 - val_loss: 0.0194\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 94us/sample - loss: 0.0572 - val_loss: 0.0193\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 95us/sample - loss: 0.0478 - val_loss: 0.0192\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 86us/sample - loss: 0.0586 - val_loss: 0.0192\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 116us/sample - loss: 0.0512 - val_loss: 0.0190\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 91us/sample - loss: 0.0496 - val_loss: 0.0189\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 83us/sample - loss: 0.0546 - val_loss: 0.0188\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 78us/sample - loss: 0.0540 - val_loss: 0.0185\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 87us/sample - loss: 0.0533 - val_loss: 0.0182\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 83us/sample - loss: 0.0504 - val_loss: 0.0180\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0465 - val_loss: 0.0179\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 84us/sample - loss: 0.0518 - val_loss: 0.0176\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 95us/sample - loss: 0.0468 - val_loss: 0.0174\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0502 - val_loss: 0.0171\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 88us/sample - loss: 0.0425 - val_loss: 0.0170\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 85us/sample - loss: 0.0461 - val_loss: 0.0169\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0402 - val_loss: 0.0169\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 110us/sample - loss: 0.0421 - val_loss: 0.0169\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 115us/sample - loss: 0.0378 - val_loss: 0.0169\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 76us/sample - loss: 0.0402 - val_loss: 0.0167\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 85us/sample - loss: 0.0372 - val_loss: 0.0165\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 105us/sample - loss: 0.0402 - val_loss: 0.0164\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 123us/sample - loss: 0.0396 - val_loss: 0.0163\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0395 - val_loss: 0.0162\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0357 - val_loss: 0.0162\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0368 - val_loss: 0.0161\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 83us/sample - loss: 0.0385 - val_loss: 0.0161\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 91us/sample - loss: 0.0376 - val_loss: 0.0160\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 83us/sample - loss: 0.0355 - val_loss: 0.0158\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0362 - val_loss: 0.0158\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 108us/sample - loss: 0.0357 - val_loss: 0.0156\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 85us/sample - loss: 0.0335 - val_loss: 0.0155\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 84us/sample - loss: 0.0341 - val_loss: 0.0154\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 90us/sample - loss: 0.0360 - val_loss: 0.0151\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 93us/sample - loss: 0.0344 - val_loss: 0.0150\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 85us/sample - loss: 0.0298 - val_loss: 0.0149\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0301 - val_loss: 0.0149\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 85us/sample - loss: 0.0289 - val_loss: 0.0149\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 95us/sample - loss: 0.0290 - val_loss: 0.0148\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 103us/sample - loss: 0.0254 - val_loss: 0.0147\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 109us/sample - loss: 0.0287 - val_loss: 0.0147\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 90us/sample - loss: 0.0293 - val_loss: 0.0146\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 92us/sample - loss: 0.0292 - val_loss: 0.0145\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0300 - val_loss: 0.0145\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 90us/sample - loss: 0.0291 - val_loss: 0.0145\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0276 - val_loss: 0.0145\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 82us/sample - loss: 0.0302 - val_loss: 0.0144\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 79us/sample - loss: 0.0268 - val_loss: 0.0142\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 77us/sample - loss: 0.0265 - val_loss: 0.0141\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0258 - val_loss: 0.0141\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 90us/sample - loss: 0.0272 - val_loss: 0.0140\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 85us/sample - loss: 0.0259 - val_loss: 0.0139\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 79us/sample - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0261 - val_loss: 0.0137\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0269 - val_loss: 0.0137\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 112us/sample - loss: 0.0255 - val_loss: 0.0136\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 103us/sample - loss: 0.0249 - val_loss: 0.0135\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 82us/sample - loss: 0.0255 - val_loss: 0.0135\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0242 - val_loss: 0.0134\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0234 - val_loss: 0.0134\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0228 - val_loss: 0.0133\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 83us/sample - loss: 0.0251 - val_loss: 0.0131\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 92us/sample - loss: 0.0225 - val_loss: 0.0130\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 83us/sample - loss: 0.0247 - val_loss: 0.0129\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0215 - val_loss: 0.0128\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0246 - val_loss: 0.0127\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0217 - val_loss: 0.0128\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0206 - val_loss: 0.0127\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0209 - val_loss: 0.0127\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 107us/sample - loss: 0.0195 - val_loss: 0.0126\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 124us/sample - loss: 0.0212 - val_loss: 0.0125\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 127us/sample - loss: 0.0200 - val_loss: 0.0125\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 115us/sample - loss: 0.0223 - val_loss: 0.0125\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 99us/sample - loss: 0.0223 - val_loss: 0.0124\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0211 - val_loss: 0.0123\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 99us/sample - loss: 0.0198 - val_loss: 0.0123\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0192 - val_loss: 0.0123\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0202 - val_loss: 0.0120\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0190 - val_loss: 0.0119\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0191 - val_loss: 0.0113\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 122us/sample - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 80us/sample - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 76us/sample - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0191 - val_loss: 0.0110\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 84us/sample - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 108us/sample - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0107\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 104us/sample - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 107us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0126 - val_loss: 0.0098\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 107us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 120us/sample - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 122us/sample - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 117us/sample - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 85us/sample - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 97us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0120 - val_loss: 0.0094\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 101us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0120 - val_loss: 0.0093\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 74us/sample - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 76us/sample - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 82us/sample - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 79us/sample - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 79us/sample - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 89us/sample - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 84us/sample - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0087\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0086\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 113us/sample - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 120us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 111us/sample - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 152us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 77us/sample - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 78us/sample - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 79us/sample - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 82us/sample - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 122us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 121us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.322 - 1s 2ms/sample - loss: 0.3266 - val_loss: 0.1861\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.363 - 0s 99us/sample - loss: 0.3165 - val_loss: 0.1722\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.217 - 0s 97us/sample - loss: 0.2661 - val_loss: 0.1596\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.292 - 0s 106us/sample - loss: 0.2769 - val_loss: 0.1473\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.303 - 0s 106us/sample - loss: 0.2528 - val_loss: 0.1358\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.275 - 0s 115us/sample - loss: 0.2406 - val_loss: 0.1249\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.237 - 0s 100us/sample - loss: 0.2294 - val_loss: 0.1146\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.216 - 0s 93us/sample - loss: 0.2079 - val_loss: 0.1053\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.177 - 0s 76us/sample - loss: 0.1877 - val_loss: 0.0965\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.152 - 0s 78us/sample - loss: 0.1930 - val_loss: 0.0883\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 83us/sample - loss: 0.1699 - val_loss: 0.0803\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 81us/sample - loss: 0.1711 - val_loss: 0.0730\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.201 - 0s 87us/sample - loss: 0.1530 - val_loss: 0.0665\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.162 - 0s 102us/sample - loss: 0.1480 - val_loss: 0.0603\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 112us/sample - loss: 0.1378 - val_loss: 0.0547\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.192 - 0s 110us/sample - loss: 0.1388 - val_loss: 0.0494\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.114 - 0s 115us/sample - loss: 0.1261 - val_loss: 0.0446\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 85us/sample - loss: 0.1145 - val_loss: 0.0402\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 81us/sample - loss: 0.1135 - val_loss: 0.0362\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 86us/sample - loss: 0.1034 - val_loss: 0.0328\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 90us/sample - loss: 0.1017 - val_loss: 0.0296\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.112 - 0s 88us/sample - loss: 0.0975 - val_loss: 0.0267\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 88us/sample - loss: 0.0839 - val_loss: 0.0241\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.131 - 0s 89us/sample - loss: 0.0827 - val_loss: 0.0219\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 91us/sample - loss: 0.0783 - val_loss: 0.0200\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 92us/sample - loss: 0.0833 - val_loss: 0.0183\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 93us/sample - loss: 0.0838 - val_loss: 0.0168\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 86us/sample - loss: 0.0718 - val_loss: 0.0155\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 88us/sample - loss: 0.0701 - val_loss: 0.0145\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 93us/sample - loss: 0.0683 - val_loss: 0.0136\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.078 - 0s 89us/sample - loss: 0.0659 - val_loss: 0.0128\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 100us/sample - loss: 0.0630 - val_loss: 0.0122\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 97us/sample - loss: 0.0635 - val_loss: 0.0117\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 108us/sample - loss: 0.0603 - val_loss: 0.0113\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 95us/sample - loss: 0.0547 - val_loss: 0.0110\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 88us/sample - loss: 0.0575 - val_loss: 0.0107\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 99us/sample - loss: 0.0543 - val_loss: 0.0105\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 100us/sample - loss: 0.0535 - val_loss: 0.0103\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 98us/sample - loss: 0.0524 - val_loss: 0.0102\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 97us/sample - loss: 0.0525 - val_loss: 0.0101\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 94us/sample - loss: 0.0496 - val_loss: 0.0101\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 98us/sample - loss: 0.0529 - val_loss: 0.0101\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 152us/sample - loss: 0.0479 - val_loss: 0.0101\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 96us/sample - loss: 0.0513 - val_loss: 0.0101\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 96us/sample - loss: 0.0463 - val_loss: 0.0101\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0451 - val_loss: 0.0101\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 108us/sample - loss: 0.0496 - val_loss: 0.0102\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 86us/sample - loss: 0.0443 - val_loss: 0.0102\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 93us/sample - loss: 0.0470 - val_loss: 0.0102\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 101us/sample - loss: 0.0438 - val_loss: 0.0102\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 104us/sample - loss: 0.0424 - val_loss: 0.0103\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 97us/sample - loss: 0.0438 - val_loss: 0.0103\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 95us/sample - loss: 0.0441 - val_loss: 0.0103\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 82us/sample - loss: 0.0444 - val_loss: 0.0103\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 78us/sample - loss: 0.0452 - val_loss: 0.0104\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0401 - val_loss: 0.0105\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 98us/sample - loss: 0.0389 - val_loss: 0.0105\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 94us/sample - loss: 0.0425 - val_loss: 0.0105\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 84us/sample - loss: 0.0392 - val_loss: 0.0105\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 97us/sample - loss: 0.0363 - val_loss: 0.0104\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 111us/sample - loss: 0.0406 - val_loss: 0.0104\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0371 - val_loss: 0.0104\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0385 - val_loss: 0.0103\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 107us/sample - loss: 0.0339 - val_loss: 0.0103\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 108us/sample - loss: 0.0372 - val_loss: 0.0103\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 136us/sample - loss: 0.0367 - val_loss: 0.0103\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 144us/sample - loss: 0.0384 - val_loss: 0.0103\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0331 - val_loss: 0.0103\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 88us/sample - loss: 0.0348 - val_loss: 0.0102\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 105us/sample - loss: 0.0364 - val_loss: 0.0102\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 101us/sample - loss: 0.0313 - val_loss: 0.0102\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 111us/sample - loss: 0.0321 - val_loss: 0.0102\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0321 - val_loss: 0.0102\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.029 - 0s 753us/sample - loss: 0.0377 - val_loss: 0.0352\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 87us/sample - loss: 0.0349 - val_loss: 0.0322\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0360 - val_loss: 0.0293\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0329 - val_loss: 0.0272\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 97us/sample - loss: 0.0296 - val_loss: 0.0254\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0301 - val_loss: 0.0237\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 80us/sample - loss: 0.0320 - val_loss: 0.0222\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 78us/sample - loss: 0.0285 - val_loss: 0.0210\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0200\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0312 - val_loss: 0.0191\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0276 - val_loss: 0.0182\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0284 - val_loss: 0.0176\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0262 - val_loss: 0.0168\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 99us/sample - loss: 0.0249 - val_loss: 0.0163\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0309 - val_loss: 0.0158\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0275 - val_loss: 0.0153\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 110us/sample - loss: 0.0236 - val_loss: 0.0149\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 92us/sample - loss: 0.0247 - val_loss: 0.0144\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 122us/sample - loss: 0.0264 - val_loss: 0.0139\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 115us/sample - loss: 0.0266 - val_loss: 0.0136\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0254 - val_loss: 0.0132\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 92us/sample - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 80us/sample - loss: 0.0244 - val_loss: 0.0125\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0241 - val_loss: 0.0122\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0231 - val_loss: 0.0120\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0222 - val_loss: 0.0118\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 102us/sample - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0218 - val_loss: 0.0114\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0221 - val_loss: 0.0111\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 117us/sample - loss: 0.0202 - val_loss: 0.0109\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 92us/sample - loss: 0.0180 - val_loss: 0.0108\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0215 - val_loss: 0.0106\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0193 - val_loss: 0.0105\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0210 - val_loss: 0.0104\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0210 - val_loss: 0.0103\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0208 - val_loss: 0.0102\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 99us/sample - loss: 0.0188 - val_loss: 0.0101\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0205 - val_loss: 0.0099\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0212 - val_loss: 0.0099\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0191 - val_loss: 0.0098\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 122us/sample - loss: 0.0189 - val_loss: 0.0098\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 132us/sample - loss: 0.0179 - val_loss: 0.0098\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 130us/sample - loss: 0.0199 - val_loss: 0.0097\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 131us/sample - loss: 0.0168 - val_loss: 0.0097\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 102us/sample - loss: 0.0164 - val_loss: 0.0096\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 101us/sample - loss: 0.0186 - val_loss: 0.0096\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 114us/sample - loss: 0.0179 - val_loss: 0.0096\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 115us/sample - loss: 0.0174 - val_loss: 0.0096\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0157 - val_loss: 0.0095\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0165 - val_loss: 0.0095\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0163 - val_loss: 0.0095\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0157 - val_loss: 0.0095\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 99us/sample - loss: 0.0169 - val_loss: 0.0094\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 109us/sample - loss: 0.0151 - val_loss: 0.0094\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0167 - val_loss: 0.0094\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0157 - val_loss: 0.0094\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 106us/sample - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0163 - val_loss: 0.0094\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0165 - val_loss: 0.0094\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 81us/sample - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0151 - val_loss: 0.0094\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0154 - val_loss: 0.0094\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0146 - val_loss: 0.0093\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0133 - val_loss: 0.0094\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 108us/sample - loss: 0.0153 - val_loss: 0.0094\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 122us/sample - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 97us/sample - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 102us/sample - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 137us/sample - loss: 0.0133 - val_loss: 0.0093\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 123us/sample - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 134us/sample - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 130us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0125 - val_loss: 0.0091\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0124 - val_loss: 0.0092\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 109us/sample - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 128us/sample - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 122us/sample - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 104us/sample - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 113us/sample - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 117us/sample - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 76us/sample - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0074 - val_loss: 0.0089\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0080 - val_loss: 0.0088\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0086\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0085\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 82us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 82us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0054 - val_loss: 0.0075\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.228 - 0s 565us/sample - loss: 0.2586 - val_loss: 0.0913\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.248 - 0s 98us/sample - loss: 0.2493 - val_loss: 0.0798\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.227 - 0s 90us/sample - loss: 0.2493 - val_loss: 0.0704\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.200 - 0s 90us/sample - loss: 0.2132 - val_loss: 0.0625\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.203 - 0s 84us/sample - loss: 0.2077 - val_loss: 0.0563\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.214 - 0s 86us/sample - loss: 0.1834 - val_loss: 0.0514\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 93us/sample - loss: 0.1859 - val_loss: 0.0480\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.140 - 0s 93us/sample - loss: 0.1635 - val_loss: 0.0454\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.193 - 0s 94us/sample - loss: 0.1439 - val_loss: 0.0434\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 110us/sample - loss: 0.1483 - val_loss: 0.0420\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 104us/sample - loss: 0.1276 - val_loss: 0.0411\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 98us/sample - loss: 0.1218 - val_loss: 0.0403\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.176 - 0s 108us/sample - loss: 0.1036 - val_loss: 0.0398\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.108 - 0s 110us/sample - loss: 0.1129 - val_loss: 0.0393\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 117us/sample - loss: 0.1076 - val_loss: 0.0387\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 93us/sample - loss: 0.1128 - val_loss: 0.0382\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 107us/sample - loss: 0.0970 - val_loss: 0.0376\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.106 - 0s 110us/sample - loss: 0.0962 - val_loss: 0.0371\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 109us/sample - loss: 0.0899 - val_loss: 0.0368\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 105us/sample - loss: 0.0949 - val_loss: 0.0364\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.147 - 0s 112us/sample - loss: 0.0899 - val_loss: 0.0359\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 105us/sample - loss: 0.0895 - val_loss: 0.0356\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 104us/sample - loss: 0.0834 - val_loss: 0.0352\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 108us/sample - loss: 0.0771 - val_loss: 0.0347\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 110us/sample - loss: 0.0754 - val_loss: 0.0341\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 105us/sample - loss: 0.0732 - val_loss: 0.0335\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 108us/sample - loss: 0.0765 - val_loss: 0.0329\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 108us/sample - loss: 0.0778 - val_loss: 0.0326\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 108us/sample - loss: 0.0708 - val_loss: 0.0318\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 112us/sample - loss: 0.0707 - val_loss: 0.0313\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 110us/sample - loss: 0.0675 - val_loss: 0.0309\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.119 - 0s 111us/sample - loss: 0.0719 - val_loss: 0.0307\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 114us/sample - loss: 0.0677 - val_loss: 0.0303\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 108us/sample - loss: 0.0662 - val_loss: 0.0301\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 105us/sample - loss: 0.0626 - val_loss: 0.0299\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 94us/sample - loss: 0.0670 - val_loss: 0.0296\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 95us/sample - loss: 0.0659 - val_loss: 0.0293\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 98us/sample - loss: 0.0636 - val_loss: 0.0292\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 101us/sample - loss: 0.0593 - val_loss: 0.0288\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 90us/sample - loss: 0.0672 - val_loss: 0.0286\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 83us/sample - loss: 0.0580 - val_loss: 0.0282\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 103us/sample - loss: 0.0530 - val_loss: 0.0280\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 88us/sample - loss: 0.0562 - val_loss: 0.0278\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0621 - val_loss: 0.0276\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 91us/sample - loss: 0.0569 - val_loss: 0.0274\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 91us/sample - loss: 0.0554 - val_loss: 0.0272\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 85us/sample - loss: 0.0572 - val_loss: 0.0270\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 87us/sample - loss: 0.0525 - val_loss: 0.0266\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0556 - val_loss: 0.0264\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 88us/sample - loss: 0.0572 - val_loss: 0.0261\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0521 - val_loss: 0.0260\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 88us/sample - loss: 0.0511 - val_loss: 0.0258\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 88us/sample - loss: 0.0493 - val_loss: 0.0254\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 93us/sample - loss: 0.0493 - val_loss: 0.0250\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 107us/sample - loss: 0.0507 - val_loss: 0.0248\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.0526 - val_loss: 0.0246\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 97us/sample - loss: 0.0480 - val_loss: 0.0243\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 104us/sample - loss: 0.0484 - val_loss: 0.0240\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 123us/sample - loss: 0.0538 - val_loss: 0.0238\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 109us/sample - loss: 0.0478 - val_loss: 0.0236\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 109us/sample - loss: 0.0480 - val_loss: 0.0233\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 88us/sample - loss: 0.0499 - val_loss: 0.0230\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 97us/sample - loss: 0.0472 - val_loss: 0.0227\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 89us/sample - loss: 0.0469 - val_loss: 0.0225\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 93us/sample - loss: 0.0450 - val_loss: 0.0222\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 98us/sample - loss: 0.0479 - val_loss: 0.0219\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.0443 - val_loss: 0.0217\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 97us/sample - loss: 0.0442 - val_loss: 0.0215\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 92us/sample - loss: 0.0428 - val_loss: 0.0212\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0399 - val_loss: 0.0209\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 95us/sample - loss: 0.0436 - val_loss: 0.0208\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0424 - val_loss: 0.0206\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 92us/sample - loss: 0.0400 - val_loss: 0.0202\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0407 - val_loss: 0.0199\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 90us/sample - loss: 0.0423 - val_loss: 0.0196\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0445 - val_loss: 0.0195\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 90us/sample - loss: 0.0389 - val_loss: 0.0193\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 105us/sample - loss: 0.0380 - val_loss: 0.0191\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 78us/sample - loss: 0.0435 - val_loss: 0.0189\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 78us/sample - loss: 0.0406 - val_loss: 0.0187\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0389 - val_loss: 0.0185\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 111us/sample - loss: 0.0390 - val_loss: 0.0182\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 109us/sample - loss: 0.0375 - val_loss: 0.0180\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 88us/sample - loss: 0.0375 - val_loss: 0.0177\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0358 - val_loss: 0.0174\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0353 - val_loss: 0.0172\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0344 - val_loss: 0.0170\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 95us/sample - loss: 0.0335 - val_loss: 0.0168\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 89us/sample - loss: 0.0342 - val_loss: 0.0166\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 95us/sample - loss: 0.0341 - val_loss: 0.0165\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0390 - val_loss: 0.0164\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0348 - val_loss: 0.0163\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 87us/sample - loss: 0.0357 - val_loss: 0.0161\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 86us/sample - loss: 0.0363 - val_loss: 0.0160\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0339 - val_loss: 0.0158\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 92us/sample - loss: 0.0344 - val_loss: 0.0157\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 85us/sample - loss: 0.0347 - val_loss: 0.0155\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0313 - val_loss: 0.0154\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 94us/sample - loss: 0.0337 - val_loss: 0.0153\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 89us/sample - loss: 0.0332 - val_loss: 0.0152\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 90us/sample - loss: 0.0337 - val_loss: 0.0151\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 110us/sample - loss: 0.0316 - val_loss: 0.0150\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 101us/sample - loss: 0.0290 - val_loss: 0.0148\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0307 - val_loss: 0.0147\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 97us/sample - loss: 0.0306 - val_loss: 0.0146\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 92us/sample - loss: 0.0303 - val_loss: 0.0144\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0320 - val_loss: 0.0143\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 102us/sample - loss: 0.0298 - val_loss: 0.0142\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0317 - val_loss: 0.0141\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0313 - val_loss: 0.0140\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0321 - val_loss: 0.0139\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 99us/sample - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 100us/sample - loss: 0.0274 - val_loss: 0.0136\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0271 - val_loss: 0.0135\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0282 - val_loss: 0.0135\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0290 - val_loss: 0.0134\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 99us/sample - loss: 0.0290 - val_loss: 0.0133\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 98us/sample - loss: 0.0288 - val_loss: 0.0132\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0274 - val_loss: 0.0131\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0283 - val_loss: 0.0130\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0295 - val_loss: 0.0130\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 92us/sample - loss: 0.0286 - val_loss: 0.0129\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 81us/sample - loss: 0.0261 - val_loss: 0.0127\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0291 - val_loss: 0.0126\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0270 - val_loss: 0.0126\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 86us/sample - loss: 0.0277 - val_loss: 0.0125\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0268 - val_loss: 0.0124\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0248 - val_loss: 0.0123\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0244 - val_loss: 0.0122\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0259 - val_loss: 0.0121\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 103us/sample - loss: 0.0225 - val_loss: 0.0120\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 102us/sample - loss: 0.0269 - val_loss: 0.0119\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0243 - val_loss: 0.0119\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0255 - val_loss: 0.0118\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 81us/sample - loss: 0.0233 - val_loss: 0.0117\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0249 - val_loss: 0.0116\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 85us/sample - loss: 0.0234 - val_loss: 0.0116\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0243 - val_loss: 0.0115\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 83us/sample - loss: 0.0233 - val_loss: 0.0114\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0113\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0221 - val_loss: 0.0112\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0216 - val_loss: 0.0112\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0228 - val_loss: 0.0111\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0232 - val_loss: 0.0110\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0227 - val_loss: 0.0110\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 76us/sample - loss: 0.0234 - val_loss: 0.0109\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 102us/sample - loss: 0.0192 - val_loss: 0.0108\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0216 - val_loss: 0.0107\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 105us/sample - loss: 0.0206 - val_loss: 0.0107\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0190 - val_loss: 0.0106\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 98us/sample - loss: 0.0197 - val_loss: 0.0106\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 106us/sample - loss: 0.0205 - val_loss: 0.0106\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 110us/sample - loss: 0.0209 - val_loss: 0.0105\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0184 - val_loss: 0.0105\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 112us/sample - loss: 0.0204 - val_loss: 0.0104\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0196 - val_loss: 0.0104\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0196 - val_loss: 0.0103\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0198 - val_loss: 0.0102\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 94us/sample - loss: 0.0190 - val_loss: 0.0102\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0193 - val_loss: 0.0102\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0183 - val_loss: 0.0101\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0190 - val_loss: 0.0101\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 102us/sample - loss: 0.0181 - val_loss: 0.0100\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0175 - val_loss: 0.0100\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0186 - val_loss: 0.0100\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 95us/sample - loss: 0.0191 - val_loss: 0.0099\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0169 - val_loss: 0.0099\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0098\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 92us/sample - loss: 0.0183 - val_loss: 0.0098\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0097\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0097\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0155 - val_loss: 0.0097\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0096\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0178 - val_loss: 0.0096\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0096\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0163 - val_loss: 0.0095\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0170 - val_loss: 0.0095\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0157 - val_loss: 0.0095\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0141 - val_loss: 0.0095\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 109us/sample - loss: 0.0165 - val_loss: 0.0095\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0157 - val_loss: 0.0094\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0168 - val_loss: 0.0094\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0093\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0136 - val_loss: 0.0092\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 109us/sample - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 117us/sample - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 125us/sample - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 125us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 110us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0131 - val_loss: 0.0090\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 103us/sample - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 80us/sample - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 84us/sample - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0109 - val_loss: 0.0087\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 87us/sample - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0077 - val_loss: 0.0086\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0074 - val_loss: 0.0086\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0068 - val_loss: 0.0082\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 107us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0067 - val_loss: 0.0082\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 117us/sample - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0061 - val_loss: 0.0081\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.419 - 0s 575us/sample - loss: 0.3130 - val_loss: 0.1684\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.187 - 0s 89us/sample - loss: 0.2970 - val_loss: 0.1500\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.237 - 0s 90us/sample - loss: 0.2705 - val_loss: 0.1331\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.226 - 0s 85us/sample - loss: 0.2385 - val_loss: 0.1176\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.152 - 0s 85us/sample - loss: 0.2275 - val_loss: 0.1038\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.271 - 0s 105us/sample - loss: 0.2078 - val_loss: 0.0910\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.256 - 0s 93us/sample - loss: 0.1931 - val_loss: 0.0799\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.161 - 0s 98us/sample - loss: 0.1668 - val_loss: 0.0702\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 100us/sample - loss: 0.1526 - val_loss: 0.0615\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 99us/sample - loss: 0.1376 - val_loss: 0.0540\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.150 - 0s 96us/sample - loss: 0.1166 - val_loss: 0.0475\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 90us/sample - loss: 0.1154 - val_loss: 0.0420\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.127 - 0s 95us/sample - loss: 0.1056 - val_loss: 0.0373\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 92us/sample - loss: 0.0986 - val_loss: 0.0331\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 90us/sample - loss: 0.0836 - val_loss: 0.0296\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 100us/sample - loss: 0.0757 - val_loss: 0.0266\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 90us/sample - loss: 0.0707 - val_loss: 0.0242\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 88us/sample - loss: 0.0694 - val_loss: 0.0222\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 95us/sample - loss: 0.0635 - val_loss: 0.0204\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 87us/sample - loss: 0.0649 - val_loss: 0.0189\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0575 - val_loss: 0.0178\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 93us/sample - loss: 0.0551 - val_loss: 0.0169\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 100us/sample - loss: 0.0510 - val_loss: 0.0163\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 105us/sample - loss: 0.0455 - val_loss: 0.0159\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 103us/sample - loss: 0.0510 - val_loss: 0.0155\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0462 - val_loss: 0.0153\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 79us/sample - loss: 0.0407 - val_loss: 0.0152\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 82us/sample - loss: 0.0434 - val_loss: 0.0151\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 83us/sample - loss: 0.0412 - val_loss: 0.0151\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 88us/sample - loss: 0.0432 - val_loss: 0.0151\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0355 - val_loss: 0.0151\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 85us/sample - loss: 0.0395 - val_loss: 0.0151\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 87us/sample - loss: 0.0388 - val_loss: 0.0151\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 89us/sample - loss: 0.0361 - val_loss: 0.0152\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 84us/sample - loss: 0.0333 - val_loss: 0.0152\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 93us/sample - loss: 0.0341 - val_loss: 0.0153\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 88us/sample - loss: 0.0341 - val_loss: 0.0153\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 90us/sample - loss: 0.0323 - val_loss: 0.0154\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 86us/sample - loss: 0.0367 - val_loss: 0.0154\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0310 - val_loss: 0.0154\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 94us/sample - loss: 0.0309 - val_loss: 0.0154\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 83us/sample - loss: 0.0309 - val_loss: 0.0154\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 85us/sample - loss: 0.0331 - val_loss: 0.0154\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0277 - val_loss: 0.0155\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 87us/sample - loss: 0.0302 - val_loss: 0.0153\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 89us/sample - loss: 0.0312 - val_loss: 0.0153\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0289 - val_loss: 0.0152\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 80us/sample - loss: 0.0299 - val_loss: 0.0151\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 81us/sample - loss: 0.0320 - val_loss: 0.0150\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 79us/sample - loss: 0.0265 - val_loss: 0.0149\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 113us/sample - loss: 0.0315 - val_loss: 0.0148\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 117us/sample - loss: 0.0286 - val_loss: 0.0146\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 99us/sample - loss: 0.0270 - val_loss: 0.0145\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 104us/sample - loss: 0.0266 - val_loss: 0.0144\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 115us/sample - loss: 0.0264 - val_loss: 0.0144\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 108us/sample - loss: 0.0265 - val_loss: 0.0144\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0272 - val_loss: 0.0143\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0287 - val_loss: 0.0142\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 106us/sample - loss: 0.0236 - val_loss: 0.0142\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 110us/sample - loss: 0.0262 - val_loss: 0.0141\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 117us/sample - loss: 0.0281 - val_loss: 0.0140\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0245 - val_loss: 0.0140\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 107us/sample - loss: 0.0223 - val_loss: 0.0139\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 107us/sample - loss: 0.0237 - val_loss: 0.0138\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0246 - val_loss: 0.0137\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 104us/sample - loss: 0.0217 - val_loss: 0.0136\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 109us/sample - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 112us/sample - loss: 0.0213 - val_loss: 0.0134\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 110us/sample - loss: 0.0244 - val_loss: 0.0134\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0243 - val_loss: 0.0133\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0242 - val_loss: 0.0132\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0211 - val_loss: 0.0131\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 89us/sample - loss: 0.0223 - val_loss: 0.0131\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0218 - val_loss: 0.0131\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 92us/sample - loss: 0.0208 - val_loss: 0.0130\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0220 - val_loss: 0.0129\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0202 - val_loss: 0.0127\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0214 - val_loss: 0.0126\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0218 - val_loss: 0.0126\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 103us/sample - loss: 0.0204 - val_loss: 0.0126\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0204 - val_loss: 0.0125\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0196 - val_loss: 0.0125\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 79us/sample - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 111us/sample - loss: 0.0183 - val_loss: 0.0121\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0193 - val_loss: 0.0121\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 81us/sample - loss: 0.0171 - val_loss: 0.0119\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0183 - val_loss: 0.0118\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0162 - val_loss: 0.0118\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 96us/sample - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 102us/sample - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0174 - val_loss: 0.0114\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 89us/sample - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 89us/sample - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 102us/sample - loss: 0.0153 - val_loss: 0.0111\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0168 - val_loss: 0.0106\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 78us/sample - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 80us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 104us/sample - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0120 - val_loss: 0.0094\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 78us/sample - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 78us/sample - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 82us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 77us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 78us/sample - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0079\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 1.251 - 0s 695us/sample - loss: 1.2575 - val_loss: 1.1817\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.218 - 0s 99us/sample - loss: 1.1945 - val_loss: 1.1212\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.175 - 0s 98us/sample - loss: 1.1880 - val_loss: 1.0607\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.417 - 0s 95us/sample - loss: 1.0123 - val_loss: 1.0058\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.461 - 0s 98us/sample - loss: 1.0514 - val_loss: 0.9521\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.127 - 0s 90us/sample - loss: 0.9418 - val_loss: 0.8996\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.089 - 0s 104us/sample - loss: 0.9093 - val_loss: 0.8513\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.924 - 0s 98us/sample - loss: 0.8551 - val_loss: 0.8030\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.878 - 0s 99us/sample - loss: 0.8099 - val_loss: 0.7565\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.674 - 0s 93us/sample - loss: 0.8189 - val_loss: 0.7130\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.718 - 0s 93us/sample - loss: 0.7077 - val_loss: 0.6718\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.548 - 0s 95us/sample - loss: 0.6906 - val_loss: 0.6310\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.707 - 0s 93us/sample - loss: 0.6477 - val_loss: 0.5930\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.683 - 0s 93us/sample - loss: 0.6436 - val_loss: 0.5569\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.535 - 0s 93us/sample - loss: 0.6061 - val_loss: 0.5207\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.287 - 0s 93us/sample - loss: 0.5455 - val_loss: 0.4877\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.553 - 0s 93us/sample - loss: 0.5420 - val_loss: 0.4558\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.453 - 0s 94us/sample - loss: 0.4849 - val_loss: 0.4260\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.392 - 0s 97us/sample - loss: 0.4471 - val_loss: 0.3981\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.357 - 0s 99us/sample - loss: 0.4202 - val_loss: 0.3722\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.425 - 0s 90us/sample - loss: 0.4160 - val_loss: 0.3476\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.321 - 0s 91us/sample - loss: 0.3794 - val_loss: 0.3243\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.412 - 0s 88us/sample - loss: 0.3714 - val_loss: 0.3034\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.335 - 0s 85us/sample - loss: 0.3393 - val_loss: 0.2834\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.351 - 0s 85us/sample - loss: 0.3458 - val_loss: 0.2647\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.401 - 0s 84us/sample - loss: 0.3014 - val_loss: 0.2462\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.275 - 0s 96us/sample - loss: 0.2951 - val_loss: 0.2289\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.319 - 0s 90us/sample - loss: 0.2649 - val_loss: 0.2130\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.292 - 0s 95us/sample - loss: 0.2566 - val_loss: 0.1982\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.240 - 0s 98us/sample - loss: 0.2307 - val_loss: 0.1850\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.292 - 0s 91us/sample - loss: 0.2342 - val_loss: 0.1720\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.232 - 0s 98us/sample - loss: 0.2142 - val_loss: 0.1601\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 91us/sample - loss: 0.2048 - val_loss: 0.1489\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.128 - 0s 92us/sample - loss: 0.1855 - val_loss: 0.1392\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.235 - 0s 95us/sample - loss: 0.1871 - val_loss: 0.1300\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.117 - 0s 82us/sample - loss: 0.1762 - val_loss: 0.1211\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.140 - 0s 86us/sample - loss: 0.1630 - val_loss: 0.1129\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.251 - 0s 90us/sample - loss: 0.1711 - val_loss: 0.1050\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.237 - 0s 78us/sample - loss: 0.1664 - val_loss: 0.0980\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.189 - 0s 87us/sample - loss: 0.1577 - val_loss: 0.0913\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 81us/sample - loss: 0.1402 - val_loss: 0.0854\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.132 - 0s 97us/sample - loss: 0.1477 - val_loss: 0.0804\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.165 - 0s 108us/sample - loss: 0.1346 - val_loss: 0.0753\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.182 - 0s 103us/sample - loss: 0.1368 - val_loss: 0.0706\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.164 - 0s 105us/sample - loss: 0.1196 - val_loss: 0.0665\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 97us/sample - loss: 0.1048 - val_loss: 0.0630\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.123 - 0s 103us/sample - loss: 0.1129 - val_loss: 0.0598\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 90us/sample - loss: 0.1059 - val_loss: 0.0570\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 89us/sample - loss: 0.1285 - val_loss: 0.0540\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 130us/sample - loss: 0.1003 - val_loss: 0.0509\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 88us/sample - loss: 0.1004 - val_loss: 0.0484\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 120us/sample - loss: 0.1109 - val_loss: 0.0462\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 90us/sample - loss: 0.1113 - val_loss: 0.0438\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.119 - 0s 93us/sample - loss: 0.1033 - val_loss: 0.0417\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 95us/sample - loss: 0.0921 - val_loss: 0.0399\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 88us/sample - loss: 0.0889 - val_loss: 0.0383\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.128 - 0s 98us/sample - loss: 0.0888 - val_loss: 0.0371\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 90us/sample - loss: 0.0988 - val_loss: 0.0359\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.134 - 0s 90us/sample - loss: 0.1017 - val_loss: 0.0349\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 90us/sample - loss: 0.0903 - val_loss: 0.0338\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 93us/sample - loss: 0.0904 - val_loss: 0.0327\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 97us/sample - loss: 0.0838 - val_loss: 0.0317\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 76us/sample - loss: 0.0824 - val_loss: 0.0307\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 83us/sample - loss: 0.0805 - val_loss: 0.0301\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 101us/sample - loss: 0.0745 - val_loss: 0.0293\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.137 - 0s 95us/sample - loss: 0.0896 - val_loss: 0.0284\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 87us/sample - loss: 0.0877 - val_loss: 0.0278\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 86us/sample - loss: 0.0889 - val_loss: 0.0272\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 86us/sample - loss: 0.0756 - val_loss: 0.0265\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0684 - val_loss: 0.0261\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 86us/sample - loss: 0.0807 - val_loss: 0.0256\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 93us/sample - loss: 0.0764 - val_loss: 0.0251\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 90us/sample - loss: 0.0815 - val_loss: 0.0245\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 92us/sample - loss: 0.0743 - val_loss: 0.0242\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0686 - val_loss: 0.0239\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 96us/sample - loss: 0.0737 - val_loss: 0.0236\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 88us/sample - loss: 0.0671 - val_loss: 0.0234\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 88us/sample - loss: 0.0637 - val_loss: 0.0233\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 91us/sample - loss: 0.0701 - val_loss: 0.0231\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 86us/sample - loss: 0.0706 - val_loss: 0.0230\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 85us/sample - loss: 0.0654 - val_loss: 0.0228\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 81us/sample - loss: 0.0656 - val_loss: 0.0226\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 85us/sample - loss: 0.0680 - val_loss: 0.0223\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 88us/sample - loss: 0.0647 - val_loss: 0.0223\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 87us/sample - loss: 0.0637 - val_loss: 0.0222\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 91us/sample - loss: 0.0698 - val_loss: 0.0220\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0609 - val_loss: 0.0220\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 109us/sample - loss: 0.0618 - val_loss: 0.0219\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 109us/sample - loss: 0.0538 - val_loss: 0.0218\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 122us/sample - loss: 0.0624 - val_loss: 0.0215\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 109us/sample - loss: 0.0571 - val_loss: 0.0213\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 125us/sample - loss: 0.0573 - val_loss: 0.0212\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0564 - val_loss: 0.0210\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 96us/sample - loss: 0.0552 - val_loss: 0.0207\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 97us/sample - loss: 0.0502 - val_loss: 0.0206\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 89us/sample - loss: 0.0537 - val_loss: 0.0205\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 95us/sample - loss: 0.0541 - val_loss: 0.0203\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0567 - val_loss: 0.0201\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 95us/sample - loss: 0.0543 - val_loss: 0.0200\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 96us/sample - loss: 0.0488 - val_loss: 0.0198\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 96us/sample - loss: 0.0503 - val_loss: 0.0197\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 95us/sample - loss: 0.0541 - val_loss: 0.0195\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 98us/sample - loss: 0.0490 - val_loss: 0.0194\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0491 - val_loss: 0.0192\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 108us/sample - loss: 0.0472 - val_loss: 0.0192\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 115us/sample - loss: 0.0494 - val_loss: 0.0191\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 92us/sample - loss: 0.0497 - val_loss: 0.0190\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 90us/sample - loss: 0.0457 - val_loss: 0.0189\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 99us/sample - loss: 0.0423 - val_loss: 0.0189\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 98us/sample - loss: 0.0441 - val_loss: 0.0188\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 99us/sample - loss: 0.0404 - val_loss: 0.0186\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 89us/sample - loss: 0.0437 - val_loss: 0.0184\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0395 - val_loss: 0.0183\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 103us/sample - loss: 0.0423 - val_loss: 0.0182\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0408 - val_loss: 0.0181\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 94us/sample - loss: 0.0408 - val_loss: 0.0180\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 94us/sample - loss: 0.0372 - val_loss: 0.0178\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.0392 - val_loss: 0.0177\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 103us/sample - loss: 0.0384 - val_loss: 0.0176\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 90us/sample - loss: 0.0354 - val_loss: 0.0175\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0350 - val_loss: 0.0174\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 98us/sample - loss: 0.0336 - val_loss: 0.0173\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0337 - val_loss: 0.0171\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0361 - val_loss: 0.0170\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 98us/sample - loss: 0.0362 - val_loss: 0.0169\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0315 - val_loss: 0.0169\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0387 - val_loss: 0.0168\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 98us/sample - loss: 0.0321 - val_loss: 0.0167\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 117us/sample - loss: 0.0336 - val_loss: 0.0166\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 117us/sample - loss: 0.0352 - val_loss: 0.0165\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 127us/sample - loss: 0.0339 - val_loss: 0.0164\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 108us/sample - loss: 0.0297 - val_loss: 0.0163\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 105us/sample - loss: 0.0325 - val_loss: 0.0162\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0277 - val_loss: 0.0161\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 110us/sample - loss: 0.0308 - val_loss: 0.0160\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 103us/sample - loss: 0.0298 - val_loss: 0.0160\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 94us/sample - loss: 0.0260 - val_loss: 0.0159\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0285 - val_loss: 0.0158\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 110us/sample - loss: 0.0280 - val_loss: 0.0157\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 89us/sample - loss: 0.0276 - val_loss: 0.0157\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 99us/sample - loss: 0.0283 - val_loss: 0.0156\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0296 - val_loss: 0.0154\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0272 - val_loss: 0.0153\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 127us/sample - loss: 0.0258 - val_loss: 0.0152\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 90us/sample - loss: 0.0240 - val_loss: 0.0152\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0258 - val_loss: 0.0152\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 117us/sample - loss: 0.0243 - val_loss: 0.0151\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0251 - val_loss: 0.0150\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0224 - val_loss: 0.0149\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0219 - val_loss: 0.0148\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0252 - val_loss: 0.0146\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0245 - val_loss: 0.0145\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0249 - val_loss: 0.0144\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 90us/sample - loss: 0.0239 - val_loss: 0.0143\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0245 - val_loss: 0.0142\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0235 - val_loss: 0.0140\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0245 - val_loss: 0.0139\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0230 - val_loss: 0.0137\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0224 - val_loss: 0.0136\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 105us/sample - loss: 0.0226 - val_loss: 0.0135\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 95us/sample - loss: 0.0218 - val_loss: 0.0133\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0232 - val_loss: 0.0132\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0243 - val_loss: 0.0129\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0128\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0209 - val_loss: 0.0127\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0205 - val_loss: 0.0124\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0121\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0121\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 110us/sample - loss: 0.0185 - val_loss: 0.0120\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 94us/sample - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0182 - val_loss: 0.0109\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0169 - val_loss: 0.0108\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0180 - val_loss: 0.0107\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0163 - val_loss: 0.0106\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0167 - val_loss: 0.0104\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 102us/sample - loss: 0.0170 - val_loss: 0.0103\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 85us/sample - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 127us/sample - loss: 0.0146 - val_loss: 0.0099\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 80us/sample - loss: 0.0160 - val_loss: 0.0099\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0152 - val_loss: 0.0098\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0159 - val_loss: 0.0096\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0155 - val_loss: 0.0096\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0141 - val_loss: 0.0095\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0149 - val_loss: 0.0095\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0140 - val_loss: 0.0094\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0093\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0137 - val_loss: 0.0092\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0134 - val_loss: 0.0090\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 99us/sample - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 107us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0108 - val_loss: 0.0083\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 76us/sample - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 79us/sample - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 80us/sample - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 80us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 130us/sample - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 116us/sample - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 1.129 - 0s 816us/sample - loss: 1.1592 - val_loss: 0.9902\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.054 - 0s 102us/sample - loss: 1.1173 - val_loss: 0.9590\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.214 - 0s 99us/sample - loss: 1.0581 - val_loss: 0.9298\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.078 - 0s 102us/sample - loss: 1.0548 - val_loss: 0.9011\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.840 - 0s 92us/sample - loss: 0.9965 - val_loss: 0.8733\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.796 - 0s 102us/sample - loss: 0.9979 - val_loss: 0.8470\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.728 - 0s 88us/sample - loss: 0.8723 - val_loss: 0.8219\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.180 - 0s 87us/sample - loss: 0.8863 - val_loss: 0.7971\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.025 - 0s 78us/sample - loss: 0.8754 - val_loss: 0.7731\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.827 - 0s 78us/sample - loss: 0.8677 - val_loss: 0.7490\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.659 - 0s 87us/sample - loss: 0.8282 - val_loss: 0.7262\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.806 - 0s 90us/sample - loss: 0.7891 - val_loss: 0.7039\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.744 - 0s 81us/sample - loss: 0.8024 - val_loss: 0.6820\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.930 - 0s 88us/sample - loss: 0.7729 - val_loss: 0.6607\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.853 - 0s 81us/sample - loss: 0.7185 - val_loss: 0.6402\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.818 - 0s 98us/sample - loss: 0.6805 - val_loss: 0.6217\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.947 - 0s 83us/sample - loss: 0.7072 - val_loss: 0.6026\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.463 - 0s 76us/sample - loss: 0.6371 - val_loss: 0.5850\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.555 - 0s 85us/sample - loss: 0.6454 - val_loss: 0.5676\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.602 - 0s 82us/sample - loss: 0.5527 - val_loss: 0.5518\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.693 - 0s 81us/sample - loss: 0.6333 - val_loss: 0.5349\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.436 - 0s 79us/sample - loss: 0.5748 - val_loss: 0.5189\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.533 - 0s 81us/sample - loss: 0.5529 - val_loss: 0.5036\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.613 - 0s 80us/sample - loss: 0.5527 - val_loss: 0.4887\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.414 - 0s 86us/sample - loss: 0.5292 - val_loss: 0.4741\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.419 - 0s 78us/sample - loss: 0.4881 - val_loss: 0.4605\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.650 - 0s 78us/sample - loss: 0.5296 - val_loss: 0.4466\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.522 - 0s 88us/sample - loss: 0.4869 - val_loss: 0.4328\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.393 - 0s 89us/sample - loss: 0.5009 - val_loss: 0.4195\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.634 - 0s 83us/sample - loss: 0.4765 - val_loss: 0.4064\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.431 - 0s 103us/sample - loss: 0.4448 - val_loss: 0.3946\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.405 - 0s 108us/sample - loss: 0.4228 - val_loss: 0.3828\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.492 - 0s 108us/sample - loss: 0.4400 - val_loss: 0.3710\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.506 - 0s 95us/sample - loss: 0.4049 - val_loss: 0.3603\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.583 - 0s 88us/sample - loss: 0.3980 - val_loss: 0.3492\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.442 - 0s 96us/sample - loss: 0.3955 - val_loss: 0.3387\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.320 - 0s 108us/sample - loss: 0.3590 - val_loss: 0.3289\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.379 - 0s 116us/sample - loss: 0.3628 - val_loss: 0.3192\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.470 - 0s 104us/sample - loss: 0.3593 - val_loss: 0.3097\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.280 - 0s 90us/sample - loss: 0.3362 - val_loss: 0.3005\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.334 - 0s 91us/sample - loss: 0.3391 - val_loss: 0.2913\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.348 - 0s 95us/sample - loss: 0.3228 - val_loss: 0.2827\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.239 - 0s 98us/sample - loss: 0.3080 - val_loss: 0.2743\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.396 - 0s 110us/sample - loss: 0.3094 - val_loss: 0.2664\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.244 - 0s 115us/sample - loss: 0.3099 - val_loss: 0.2581\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.282 - 0s 99us/sample - loss: 0.2774 - val_loss: 0.2507\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.214 - 0s 94us/sample - loss: 0.2743 - val_loss: 0.2433\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.224 - 0s 86us/sample - loss: 0.2525 - val_loss: 0.2364\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.196 - 0s 86us/sample - loss: 0.2723 - val_loss: 0.2296\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.156 - 0s 90us/sample - loss: 0.2502 - val_loss: 0.2229\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.277 - 0s 92us/sample - loss: 0.2542 - val_loss: 0.2164\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.247 - 0s 89us/sample - loss: 0.2438 - val_loss: 0.2102\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.237 - 0s 90us/sample - loss: 0.2144 - val_loss: 0.2044\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.143 - 0s 93us/sample - loss: 0.2304 - val_loss: 0.1986\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.211 - 0s 111us/sample - loss: 0.2203 - val_loss: 0.1928\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.192 - 0s 113us/sample - loss: 0.2082 - val_loss: 0.1875\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.258 - 0s 84us/sample - loss: 0.2058 - val_loss: 0.1820\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.268 - 0s 74us/sample - loss: 0.2039 - val_loss: 0.1767\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.129 - 0s 90us/sample - loss: 0.1841 - val_loss: 0.1719\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.173 - 0s 78us/sample - loss: 0.1948 - val_loss: 0.1670\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.158 - 0s 83us/sample - loss: 0.1825 - val_loss: 0.1623\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.223 - 0s 86us/sample - loss: 0.1827 - val_loss: 0.1576\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.202 - 0s 83us/sample - loss: 0.1782 - val_loss: 0.1530\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.169 - 0s 100us/sample - loss: 0.1659 - val_loss: 0.1486\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.162 - 0s 103us/sample - loss: 0.1665 - val_loss: 0.1445\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 97us/sample - loss: 0.1458 - val_loss: 0.1407\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.174 - 0s 105us/sample - loss: 0.1583 - val_loss: 0.1369\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.172 - 0s 79us/sample - loss: 0.1438 - val_loss: 0.1332\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.151 - 0s 84us/sample - loss: 0.1406 - val_loss: 0.1296\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.149 - 0s 90us/sample - loss: 0.1477 - val_loss: 0.1260\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 87us/sample - loss: 0.1342 - val_loss: 0.1227\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 82us/sample - loss: 0.1359 - val_loss: 0.1193\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 83us/sample - loss: 0.1287 - val_loss: 0.1159\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 78us/sample - loss: 0.1296 - val_loss: 0.1128\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 79us/sample - loss: 0.1261 - val_loss: 0.1097\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.148 - 0s 103us/sample - loss: 0.1216 - val_loss: 0.1067\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 101us/sample - loss: 0.1183 - val_loss: 0.1038\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 121us/sample - loss: 0.1136 - val_loss: 0.1011\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 115us/sample - loss: 0.1100 - val_loss: 0.0984\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 122us/sample - loss: 0.1015 - val_loss: 0.0958\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 106us/sample - loss: 0.1017 - val_loss: 0.0934\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 94us/sample - loss: 0.1014 - val_loss: 0.0909\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 95us/sample - loss: 0.0958 - val_loss: 0.0886\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.118 - 0s 93us/sample - loss: 0.0937 - val_loss: 0.0863\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 97us/sample - loss: 0.0945 - val_loss: 0.0841\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.125 - 0s 94us/sample - loss: 0.0933 - val_loss: 0.0819\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 95us/sample - loss: 0.0872 - val_loss: 0.0797\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 93us/sample - loss: 0.0869 - val_loss: 0.0777\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.112 - 0s 92us/sample - loss: 0.0785 - val_loss: 0.0758\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 95us/sample - loss: 0.0817 - val_loss: 0.0740\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0785 - val_loss: 0.0721\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 103us/sample - loss: 0.0745 - val_loss: 0.0703\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 119us/sample - loss: 0.0743 - val_loss: 0.0686\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 122us/sample - loss: 0.0729 - val_loss: 0.0670\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 110us/sample - loss: 0.0746 - val_loss: 0.0652\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 86us/sample - loss: 0.0691 - val_loss: 0.0636\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 82us/sample - loss: 0.0672 - val_loss: 0.0621\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 76us/sample - loss: 0.0701 - val_loss: 0.0605\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 93us/sample - loss: 0.0662 - val_loss: 0.0590\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 83us/sample - loss: 0.0656 - val_loss: 0.0575\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 86us/sample - loss: 0.0637 - val_loss: 0.0561\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 87us/sample - loss: 0.0638 - val_loss: 0.0547\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 93us/sample - loss: 0.0591 - val_loss: 0.0533\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 88us/sample - loss: 0.0571 - val_loss: 0.0521\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 93us/sample - loss: 0.0549 - val_loss: 0.0508\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 93us/sample - loss: 0.0555 - val_loss: 0.0497\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 83us/sample - loss: 0.0539 - val_loss: 0.0485\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 108us/sample - loss: 0.0500 - val_loss: 0.0474\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0539 - val_loss: 0.0463\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 105us/sample - loss: 0.0489 - val_loss: 0.0453\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 110us/sample - loss: 0.0526 - val_loss: 0.0442\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 100us/sample - loss: 0.0484 - val_loss: 0.0432\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0466 - val_loss: 0.0422\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 92us/sample - loss: 0.0431 - val_loss: 0.0413\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 111us/sample - loss: 0.0455 - val_loss: 0.0404\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 115us/sample - loss: 0.0437 - val_loss: 0.0395\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0445 - val_loss: 0.0387\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 82us/sample - loss: 0.0400 - val_loss: 0.0379\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 90us/sample - loss: 0.0409 - val_loss: 0.0370\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0424 - val_loss: 0.0362\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 95us/sample - loss: 0.0399 - val_loss: 0.0354\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 115us/sample - loss: 0.0380 - val_loss: 0.0346\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 100us/sample - loss: 0.0378 - val_loss: 0.0339\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 96us/sample - loss: 0.0388 - val_loss: 0.0332\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0347 - val_loss: 0.0325\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 103us/sample - loss: 0.0338 - val_loss: 0.0318\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 110us/sample - loss: 0.0366 - val_loss: 0.0312\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0337 - val_loss: 0.0305\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 89us/sample - loss: 0.0333 - val_loss: 0.0299\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 96us/sample - loss: 0.0329 - val_loss: 0.0293\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0318 - val_loss: 0.0287\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 85us/sample - loss: 0.0315 - val_loss: 0.0282\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 94us/sample - loss: 0.0314 - val_loss: 0.0276\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 92us/sample - loss: 0.0296 - val_loss: 0.0271\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0302 - val_loss: 0.0266\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 90us/sample - loss: 0.0287 - val_loss: 0.0260\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 91us/sample - loss: 0.0280 - val_loss: 0.0256\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 92us/sample - loss: 0.0274 - val_loss: 0.0251\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0284 - val_loss: 0.0246\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 76us/sample - loss: 0.0270 - val_loss: 0.0241\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0256 - val_loss: 0.0237\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0260 - val_loss: 0.0228\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 82us/sample - loss: 0.0249 - val_loss: 0.0224\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0252 - val_loss: 0.0220\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 81us/sample - loss: 0.0230 - val_loss: 0.0216\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0248 - val_loss: 0.0212\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0221 - val_loss: 0.0200\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 84us/sample - loss: 0.0225 - val_loss: 0.0197\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0209 - val_loss: 0.0194\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 116us/sample - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0187\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0211 - val_loss: 0.0184\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0202 - val_loss: 0.0180\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0205 - val_loss: 0.0177\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0200 - val_loss: 0.0174\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0196 - val_loss: 0.0171\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0192 - val_loss: 0.0168\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0187 - val_loss: 0.0165\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0188 - val_loss: 0.0163\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0176 - val_loss: 0.0160\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0176 - val_loss: 0.0157\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0178 - val_loss: 0.0155\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 107us/sample - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 114us/sample - loss: 0.0161 - val_loss: 0.0147\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 102us/sample - loss: 0.0164 - val_loss: 0.0145\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 110us/sample - loss: 0.0157 - val_loss: 0.0143\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 110us/sample - loss: 0.0149 - val_loss: 0.0141\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 113us/sample - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 104us/sample - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 109us/sample - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 103us/sample - loss: 0.0147 - val_loss: 0.0131\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 111us/sample - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 106us/sample - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 105us/sample - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 80us/sample - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0109\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 113us/sample - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 110us/sample - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 125us/sample - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 117us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 80us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.096 - 0s 709us/sample - loss: 0.0941 - val_loss: 0.0633\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0732 - val_loss: 0.0600\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 88us/sample - loss: 0.0819 - val_loss: 0.0568\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 93us/sample - loss: 0.0707 - val_loss: 0.0537\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 95us/sample - loss: 0.0720 - val_loss: 0.0509\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 88us/sample - loss: 0.0644 - val_loss: 0.0483\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 83us/sample - loss: 0.0612 - val_loss: 0.0459\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 85us/sample - loss: 0.0585 - val_loss: 0.0437\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0511 - val_loss: 0.0417\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 87us/sample - loss: 0.0556 - val_loss: 0.0398\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 88us/sample - loss: 0.0491 - val_loss: 0.0382\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 88us/sample - loss: 0.0486 - val_loss: 0.0367\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0483 - val_loss: 0.0352\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 82us/sample - loss: 0.0418 - val_loss: 0.0340\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 87us/sample - loss: 0.0442 - val_loss: 0.0327\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0455 - val_loss: 0.0313\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0431 - val_loss: 0.0302\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 95us/sample - loss: 0.0368 - val_loss: 0.0295\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 90us/sample - loss: 0.0441 - val_loss: 0.0286\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 90us/sample - loss: 0.0399 - val_loss: 0.0277\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 86us/sample - loss: 0.0374 - val_loss: 0.0270\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 92us/sample - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 109us/sample - loss: 0.0396 - val_loss: 0.0253\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 103us/sample - loss: 0.0378 - val_loss: 0.0246\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 105us/sample - loss: 0.0342 - val_loss: 0.0239\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 90us/sample - loss: 0.0354 - val_loss: 0.0231\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 100us/sample - loss: 0.0315 - val_loss: 0.0224\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0368 - val_loss: 0.0218\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0308 - val_loss: 0.0212\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0306 - val_loss: 0.0208\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0336 - val_loss: 0.0202\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 90us/sample - loss: 0.0347 - val_loss: 0.0197\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0329 - val_loss: 0.0193\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 97us/sample - loss: 0.0325 - val_loss: 0.0189\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0315 - val_loss: 0.0185\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 90us/sample - loss: 0.0307 - val_loss: 0.0181\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0323 - val_loss: 0.0177\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 85us/sample - loss: 0.0305 - val_loss: 0.0172\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0287 - val_loss: 0.0169\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 100us/sample - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 102us/sample - loss: 0.0269 - val_loss: 0.0163\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0271 - val_loss: 0.0161\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 80us/sample - loss: 0.0306 - val_loss: 0.0158\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 85us/sample - loss: 0.0280 - val_loss: 0.0156\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0154\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 90us/sample - loss: 0.0287 - val_loss: 0.0151\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0253 - val_loss: 0.0149\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0279 - val_loss: 0.0147\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 80us/sample - loss: 0.0261 - val_loss: 0.0145\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 83us/sample - loss: 0.0254 - val_loss: 0.0143\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 81us/sample - loss: 0.0256 - val_loss: 0.0141\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 85us/sample - loss: 0.0226 - val_loss: 0.0139\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0250 - val_loss: 0.0137\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0260 - val_loss: 0.0136\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0228 - val_loss: 0.0134\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0242 - val_loss: 0.0133\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 77us/sample - loss: 0.0218 - val_loss: 0.0132\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 81us/sample - loss: 0.0243 - val_loss: 0.0130\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 92us/sample - loss: 0.0240 - val_loss: 0.0129\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 83us/sample - loss: 0.0218 - val_loss: 0.0127\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 102us/sample - loss: 0.0217 - val_loss: 0.0126\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0227 - val_loss: 0.0125\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0237 - val_loss: 0.0123\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0122\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 79us/sample - loss: 0.0222 - val_loss: 0.0121\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0222 - val_loss: 0.0121\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0229 - val_loss: 0.0119\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 130us/sample - loss: 0.0219 - val_loss: 0.0118\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 94us/sample - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0205 - val_loss: 0.0116\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0204 - val_loss: 0.0113\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 97us/sample - loss: 0.0192 - val_loss: 0.0113\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0111\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 96us/sample - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0178 - val_loss: 0.0110\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 89us/sample - loss: 0.0185 - val_loss: 0.0108\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0192 - val_loss: 0.0107\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0186 - val_loss: 0.0105\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0165 - val_loss: 0.0105\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0197 - val_loss: 0.0105\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 107us/sample - loss: 0.0172 - val_loss: 0.0103\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0169 - val_loss: 0.0103\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0101\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0101\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0186 - val_loss: 0.0099\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0164 - val_loss: 0.0099\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0170 - val_loss: 0.0098\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0097\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0161 - val_loss: 0.0096\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0096\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 85us/sample - loss: 0.0165 - val_loss: 0.0095\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0146 - val_loss: 0.0095\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0095\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0091\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0154 - val_loss: 0.0091\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0121 - val_loss: 0.0089\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 104us/sample - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0137 - val_loss: 0.0089\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 107us/sample - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0126 - val_loss: 0.0086\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 76us/sample - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 78us/sample - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 80us/sample - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0085\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0109 - val_loss: 0.0083\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 101us/sample - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 82us/sample - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 130us/sample - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 115us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 107us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 102us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 91us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.278 - 0s 637us/sample - loss: 0.3063 - val_loss: 0.3722\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.316 - 0s 88us/sample - loss: 0.2943 - val_loss: 0.3505\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.408 - 0s 90us/sample - loss: 0.2843 - val_loss: 0.3293\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.247 - 0s 89us/sample - loss: 0.2680 - val_loss: 0.3094\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.221 - 0s 100us/sample - loss: 0.2382 - val_loss: 0.2905\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.264 - 0s 95us/sample - loss: 0.2241 - val_loss: 0.2727\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.216 - 0s 90us/sample - loss: 0.2009 - val_loss: 0.2559\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.161 - 0s 83us/sample - loss: 0.1941 - val_loss: 0.2401\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.198 - 0s 86us/sample - loss: 0.1837 - val_loss: 0.2241\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.185 - 0s 88us/sample - loss: 0.1747 - val_loss: 0.2083\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.211 - 0s 81us/sample - loss: 0.1637 - val_loss: 0.1932\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 82us/sample - loss: 0.1505 - val_loss: 0.1796\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.178 - 0s 83us/sample - loss: 0.1453 - val_loss: 0.1669\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 85us/sample - loss: 0.1243 - val_loss: 0.1557\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 98us/sample - loss: 0.1146 - val_loss: 0.1454\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 101us/sample - loss: 0.1145 - val_loss: 0.1358\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 102us/sample - loss: 0.1067 - val_loss: 0.1269\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.164 - 0s 100us/sample - loss: 0.1062 - val_loss: 0.1184\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.147 - 0s 99us/sample - loss: 0.0939 - val_loss: 0.1114\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 99us/sample - loss: 0.0953 - val_loss: 0.1048\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.115 - 0s 90us/sample - loss: 0.0921 - val_loss: 0.0985\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 87us/sample - loss: 0.0871 - val_loss: 0.0936\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 90us/sample - loss: 0.0809 - val_loss: 0.0891\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 98us/sample - loss: 0.0813 - val_loss: 0.0850\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.121 - 0s 93us/sample - loss: 0.0827 - val_loss: 0.0812\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 108us/sample - loss: 0.0779 - val_loss: 0.0781\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 103us/sample - loss: 0.0760 - val_loss: 0.0751\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 105us/sample - loss: 0.0730 - val_loss: 0.0726\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 103us/sample - loss: 0.0697 - val_loss: 0.0706\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 97us/sample - loss: 0.0705 - val_loss: 0.0683\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 93us/sample - loss: 0.0698 - val_loss: 0.0660\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 90us/sample - loss: 0.0602 - val_loss: 0.0645\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 106us/sample - loss: 0.0686 - val_loss: 0.0627\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 106us/sample - loss: 0.0638 - val_loss: 0.0610\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 93us/sample - loss: 0.0658 - val_loss: 0.0597\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 87us/sample - loss: 0.0647 - val_loss: 0.0579\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 84us/sample - loss: 0.0609 - val_loss: 0.0566\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 88us/sample - loss: 0.0618 - val_loss: 0.0556\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0579 - val_loss: 0.0550\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 83us/sample - loss: 0.0540 - val_loss: 0.0541\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 91us/sample - loss: 0.0571 - val_loss: 0.0529\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 83us/sample - loss: 0.0591 - val_loss: 0.0516\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 109us/sample - loss: 0.0568 - val_loss: 0.0506\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 78us/sample - loss: 0.0560 - val_loss: 0.0498\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 83us/sample - loss: 0.0564 - val_loss: 0.0489\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 86us/sample - loss: 0.0501 - val_loss: 0.0482\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 442us/sample - loss: 0.0580 - val_loss: 0.0472\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0514 - val_loss: 0.0466\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0511 - val_loss: 0.0459\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 90us/sample - loss: 0.0498 - val_loss: 0.0449\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0512 - val_loss: 0.0444\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0487 - val_loss: 0.0438\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 78us/sample - loss: 0.0476 - val_loss: 0.0435\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 81us/sample - loss: 0.0497 - val_loss: 0.0429\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 85us/sample - loss: 0.0475 - val_loss: 0.0424\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 90us/sample - loss: 0.0464 - val_loss: 0.0418\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 89us/sample - loss: 0.0494 - val_loss: 0.0414\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 90us/sample - loss: 0.0462 - val_loss: 0.0408\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 90us/sample - loss: 0.0445 - val_loss: 0.0403\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0427 - val_loss: 0.0397\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 104us/sample - loss: 0.0442 - val_loss: 0.0392\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 103us/sample - loss: 0.0466 - val_loss: 0.0388\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 92us/sample - loss: 0.0424 - val_loss: 0.0382\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 97us/sample - loss: 0.0450 - val_loss: 0.0375\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0452 - val_loss: 0.0371\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 93us/sample - loss: 0.0419 - val_loss: 0.0367\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 92us/sample - loss: 0.0403 - val_loss: 0.0361\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 89us/sample - loss: 0.0398 - val_loss: 0.0354\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 90us/sample - loss: 0.0397 - val_loss: 0.0350\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 85us/sample - loss: 0.0379 - val_loss: 0.0345\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 91us/sample - loss: 0.0396 - val_loss: 0.0338\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0403 - val_loss: 0.0335\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 109us/sample - loss: 0.0384 - val_loss: 0.0331\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 89us/sample - loss: 0.0364 - val_loss: 0.0327\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0396 - val_loss: 0.0324\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0363 - val_loss: 0.0320\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 86us/sample - loss: 0.0377 - val_loss: 0.0317\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0378 - val_loss: 0.0312\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 83us/sample - loss: 0.0377 - val_loss: 0.0310\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 82us/sample - loss: 0.0328 - val_loss: 0.0305\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 82us/sample - loss: 0.0365 - val_loss: 0.0303\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0364 - val_loss: 0.0300\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 83us/sample - loss: 0.0333 - val_loss: 0.0296\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0325 - val_loss: 0.0293\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0323 - val_loss: 0.0287\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 120us/sample - loss: 0.0329 - val_loss: 0.0283\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 81us/sample - loss: 0.0335 - val_loss: 0.0281\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 95us/sample - loss: 0.0315 - val_loss: 0.0279\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 85us/sample - loss: 0.0341 - val_loss: 0.0277\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 98us/sample - loss: 0.0308 - val_loss: 0.0275\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 86us/sample - loss: 0.0335 - val_loss: 0.0272\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0343 - val_loss: 0.0270\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0300 - val_loss: 0.0266\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0320 - val_loss: 0.0265\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 103us/sample - loss: 0.0301 - val_loss: 0.0263\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0307 - val_loss: 0.0259\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 90us/sample - loss: 0.0329 - val_loss: 0.0257\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 86us/sample - loss: 0.0286 - val_loss: 0.0254\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 86us/sample - loss: 0.0286 - val_loss: 0.0252\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 87us/sample - loss: 0.0274 - val_loss: 0.0250\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0297 - val_loss: 0.0248\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0278 - val_loss: 0.0245\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0301 - val_loss: 0.0243\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 89us/sample - loss: 0.0290 - val_loss: 0.0241\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0279 - val_loss: 0.0238\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0268 - val_loss: 0.0234\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0262 - val_loss: 0.0232\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0277 - val_loss: 0.0230\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 94us/sample - loss: 0.0264 - val_loss: 0.0226\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0258 - val_loss: 0.0223\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 94us/sample - loss: 0.0264 - val_loss: 0.0221\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0266 - val_loss: 0.0218\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0243 - val_loss: 0.0215\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0258 - val_loss: 0.0213\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 87us/sample - loss: 0.0245 - val_loss: 0.0211\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0255 - val_loss: 0.0210\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0240 - val_loss: 0.0208\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0241 - val_loss: 0.0202\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0244 - val_loss: 0.0200\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0251 - val_loss: 0.0198\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 75us/sample - loss: 0.0233 - val_loss: 0.0197\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 77us/sample - loss: 0.0229 - val_loss: 0.0194\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0206 - val_loss: 0.0192\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 80us/sample - loss: 0.0233 - val_loss: 0.0190\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 91us/sample - loss: 0.0222 - val_loss: 0.0188\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 89us/sample - loss: 0.0210 - val_loss: 0.0186\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 87us/sample - loss: 0.0209 - val_loss: 0.0184\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0214 - val_loss: 0.0182\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0217 - val_loss: 0.0181\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0218 - val_loss: 0.0179\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0216 - val_loss: 0.0177\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 92us/sample - loss: 0.0217 - val_loss: 0.0175\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0195 - val_loss: 0.0173\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0199 - val_loss: 0.0172\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 110us/sample - loss: 0.0202 - val_loss: 0.0170\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 85us/sample - loss: 0.0191 - val_loss: 0.0167\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0209 - val_loss: 0.0166\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0200 - val_loss: 0.0165\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0181 - val_loss: 0.0164\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 84us/sample - loss: 0.0190 - val_loss: 0.0162\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0177 - val_loss: 0.0160\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0184 - val_loss: 0.0158\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0194 - val_loss: 0.0157\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0169 - val_loss: 0.0155\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0188 - val_loss: 0.0150\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0180 - val_loss: 0.0148\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 119us/sample - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0162 - val_loss: 0.0143\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0170 - val_loss: 0.0142\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0162 - val_loss: 0.0141\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0140\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 107us/sample - loss: 0.0163 - val_loss: 0.0138\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0160 - val_loss: 0.0137\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0165 - val_loss: 0.0136\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0155 - val_loss: 0.0135\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0149 - val_loss: 0.0133\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 106us/sample - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 108us/sample - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 94us/sample - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0134 - val_loss: 0.0116\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 94us/sample - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0119 - val_loss: 0.0103\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 99us/sample - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 99us/sample - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 82us/sample - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 82us/sample - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 121us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 121us/sample - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 116us/sample - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0053 - val_loss: 0.0072\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.444 - 0s 631us/sample - loss: 0.6271 - val_loss: 0.6628\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.656 - 0s 104us/sample - loss: 0.5562 - val_loss: 0.6375\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.724 - 0s 108us/sample - loss: 0.5545 - val_loss: 0.6125\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.565 - 0s 95us/sample - loss: 0.5587 - val_loss: 0.5877\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.503 - 0s 85us/sample - loss: 0.4988 - val_loss: 0.5646\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.515 - 0s 78us/sample - loss: 0.4628 - val_loss: 0.5426\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.567 - 0s 81us/sample - loss: 0.4763 - val_loss: 0.5202\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.312 - 0s 97us/sample - loss: 0.4626 - val_loss: 0.4982\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.376 - 0s 94us/sample - loss: 0.4054 - val_loss: 0.4772\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.466 - 0s 84us/sample - loss: 0.3997 - val_loss: 0.4572\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.437 - 0s 84us/sample - loss: 0.3828 - val_loss: 0.4373\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.433 - 0s 86us/sample - loss: 0.3431 - val_loss: 0.4185\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.354 - 0s 92us/sample - loss: 0.3530 - val_loss: 0.4002\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.324 - 0s 86us/sample - loss: 0.3075 - val_loss: 0.3828\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.384 - 0s 88us/sample - loss: 0.3194 - val_loss: 0.3652\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.240 - 0s 83us/sample - loss: 0.3095 - val_loss: 0.3483\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.243 - 0s 136us/sample - loss: 0.2876 - val_loss: 0.3312\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.316 - 0s 88us/sample - loss: 0.2638 - val_loss: 0.3153\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.206 - 0s 90us/sample - loss: 0.2406 - val_loss: 0.3002\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.297 - 0s 95us/sample - loss: 0.2350 - val_loss: 0.2860\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.143 - 0s 86us/sample - loss: 0.2193 - val_loss: 0.2723\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.191 - 0s 91us/sample - loss: 0.2139 - val_loss: 0.2591\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.248 - 0s 102us/sample - loss: 0.2056 - val_loss: 0.2465\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.239 - 0s 92us/sample - loss: 0.2015 - val_loss: 0.2343\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.165 - 0s 98us/sample - loss: 0.1975 - val_loss: 0.2220\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 98us/sample - loss: 0.1792 - val_loss: 0.2104\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.154 - 0s 100us/sample - loss: 0.1800 - val_loss: 0.2007\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.151 - 0s 92us/sample - loss: 0.1680 - val_loss: 0.1909\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 96us/sample - loss: 0.1552 - val_loss: 0.1817\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 99us/sample - loss: 0.1602 - val_loss: 0.1733\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.165 - 0s 95us/sample - loss: 0.1516 - val_loss: 0.1648\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.1249 - val_loss: 0.1571\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 95us/sample - loss: 0.1309 - val_loss: 0.1501\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 93us/sample - loss: 0.1368 - val_loss: 0.1433\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.144 - 0s 98us/sample - loss: 0.1381 - val_loss: 0.1366\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 95us/sample - loss: 0.1225 - val_loss: 0.1313\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.189 - 0s 95us/sample - loss: 0.1203 - val_loss: 0.1263\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 86us/sample - loss: 0.1255 - val_loss: 0.1210\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.184 - 0s 82us/sample - loss: 0.1233 - val_loss: 0.1167\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 83us/sample - loss: 0.1072 - val_loss: 0.1130\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.134 - 0s 81us/sample - loss: 0.1152 - val_loss: 0.1094\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 82us/sample - loss: 0.1080 - val_loss: 0.1062\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.1000 - val_loss: 0.1028\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 94us/sample - loss: 0.1110 - val_loss: 0.0994\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.106 - 0s 90us/sample - loss: 0.0988 - val_loss: 0.0964\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.148 - 0s 81us/sample - loss: 0.1048 - val_loss: 0.0939\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 88us/sample - loss: 0.1017 - val_loss: 0.0911\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 82us/sample - loss: 0.1051 - val_loss: 0.0890\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.112 - 0s 91us/sample - loss: 0.1030 - val_loss: 0.0866\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 88us/sample - loss: 0.1034 - val_loss: 0.0849\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 82us/sample - loss: 0.0924 - val_loss: 0.0827\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.118 - 0s 86us/sample - loss: 0.0911 - val_loss: 0.0803\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 83us/sample - loss: 0.0938 - val_loss: 0.0779\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 83us/sample - loss: 0.0928 - val_loss: 0.0762\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 87us/sample - loss: 0.0776 - val_loss: 0.0748\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.137 - 0s 95us/sample - loss: 0.0868 - val_loss: 0.0738\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 85us/sample - loss: 0.0818 - val_loss: 0.0728\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 83us/sample - loss: 0.0890 - val_loss: 0.0716\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 89us/sample - loss: 0.0791 - val_loss: 0.0704\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 87us/sample - loss: 0.0766 - val_loss: 0.0693\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 83us/sample - loss: 0.0785 - val_loss: 0.0683\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.150 - 0s 94us/sample - loss: 0.0846 - val_loss: 0.0670\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 102us/sample - loss: 0.0770 - val_loss: 0.0659\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 100us/sample - loss: 0.0746 - val_loss: 0.0648\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 94us/sample - loss: 0.0779 - val_loss: 0.0637\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 85us/sample - loss: 0.0807 - val_loss: 0.0630\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 100us/sample - loss: 0.0797 - val_loss: 0.0619\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 122us/sample - loss: 0.0753 - val_loss: 0.0607\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 98us/sample - loss: 0.0746 - val_loss: 0.0597\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 93us/sample - loss: 0.0743 - val_loss: 0.0586\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 102us/sample - loss: 0.0697 - val_loss: 0.0578\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 92us/sample - loss: 0.0626 - val_loss: 0.0568\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 95us/sample - loss: 0.0707 - val_loss: 0.0562\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 95us/sample - loss: 0.0716 - val_loss: 0.0555\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 103us/sample - loss: 0.0662 - val_loss: 0.0544\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 98us/sample - loss: 0.0649 - val_loss: 0.0536\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 98us/sample - loss: 0.0669 - val_loss: 0.0523\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 98us/sample - loss: 0.0663 - val_loss: 0.0515\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 90us/sample - loss: 0.0668 - val_loss: 0.0512\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.0655 - val_loss: 0.0508\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 95us/sample - loss: 0.0630 - val_loss: 0.0499\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 90us/sample - loss: 0.0604 - val_loss: 0.0492\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 80us/sample - loss: 0.0644 - val_loss: 0.0490\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 79us/sample - loss: 0.0535 - val_loss: 0.0486\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 79us/sample - loss: 0.0591 - val_loss: 0.0482\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 81us/sample - loss: 0.0599 - val_loss: 0.0473\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 85us/sample - loss: 0.0558 - val_loss: 0.0466\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 86us/sample - loss: 0.0576 - val_loss: 0.0460\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 83us/sample - loss: 0.0572 - val_loss: 0.0458\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 84us/sample - loss: 0.0500 - val_loss: 0.0452\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 85us/sample - loss: 0.0595 - val_loss: 0.0445\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0504 - val_loss: 0.0438\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 86us/sample - loss: 0.0512 - val_loss: 0.0431\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 81us/sample - loss: 0.0538 - val_loss: 0.0423\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 84us/sample - loss: 0.0471 - val_loss: 0.0420\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 93us/sample - loss: 0.0554 - val_loss: 0.0414\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 87us/sample - loss: 0.0487 - val_loss: 0.0412\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 88us/sample - loss: 0.0527 - val_loss: 0.0412\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 83us/sample - loss: 0.0514 - val_loss: 0.0406\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 84us/sample - loss: 0.0498 - val_loss: 0.0404\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 86us/sample - loss: 0.0455 - val_loss: 0.0396\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0442 - val_loss: 0.0388\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 91us/sample - loss: 0.0486 - val_loss: 0.0382\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 93us/sample - loss: 0.0488 - val_loss: 0.0384\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 87us/sample - loss: 0.0473 - val_loss: 0.0381\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0443 - val_loss: 0.0379\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 93us/sample - loss: 0.0428 - val_loss: 0.0374\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 103us/sample - loss: 0.0410 - val_loss: 0.0370\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 103us/sample - loss: 0.0453 - val_loss: 0.0366\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 111us/sample - loss: 0.0399 - val_loss: 0.0359\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 102us/sample - loss: 0.0413 - val_loss: 0.0353\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 102us/sample - loss: 0.0427 - val_loss: 0.0351\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 100us/sample - loss: 0.0362 - val_loss: 0.0346\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 99us/sample - loss: 0.0389 - val_loss: 0.0343\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 122us/sample - loss: 0.0376 - val_loss: 0.0341\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 105us/sample - loss: 0.0395 - val_loss: 0.0338\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 110us/sample - loss: 0.0410 - val_loss: 0.0335\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0378 - val_loss: 0.0329\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0419 - val_loss: 0.0324\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0373 - val_loss: 0.0319\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0383 - val_loss: 0.0315\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 90us/sample - loss: 0.0382 - val_loss: 0.0310\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 102us/sample - loss: 0.0344 - val_loss: 0.0305\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 95us/sample - loss: 0.0362 - val_loss: 0.0302\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0348 - val_loss: 0.0299\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 96us/sample - loss: 0.0351 - val_loss: 0.0294\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0336 - val_loss: 0.0290\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 91us/sample - loss: 0.0331 - val_loss: 0.0286\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 83us/sample - loss: 0.0342 - val_loss: 0.0283\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 83us/sample - loss: 0.0308 - val_loss: 0.0279\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 81us/sample - loss: 0.0306 - val_loss: 0.0274\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0321 - val_loss: 0.0272\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0285 - val_loss: 0.0270\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 83us/sample - loss: 0.0363 - val_loss: 0.0267\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 85us/sample - loss: 0.0287 - val_loss: 0.0264\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 92us/sample - loss: 0.0324 - val_loss: 0.0262\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 83us/sample - loss: 0.0302 - val_loss: 0.0258\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 89us/sample - loss: 0.0275 - val_loss: 0.0254\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0295 - val_loss: 0.0251\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0277 - val_loss: 0.0247\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0299 - val_loss: 0.0239\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0290 - val_loss: 0.0237\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0285 - val_loss: 0.0235\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 92us/sample - loss: 0.0260 - val_loss: 0.0234\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0263 - val_loss: 0.0226\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0241 - val_loss: 0.0223\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 85us/sample - loss: 0.0244 - val_loss: 0.0219\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 97us/sample - loss: 0.0261 - val_loss: 0.0217\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0229 - val_loss: 0.0214\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 114us/sample - loss: 0.0246 - val_loss: 0.0210\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 97us/sample - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 106us/sample - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 106us/sample - loss: 0.0246 - val_loss: 0.0199\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0237 - val_loss: 0.0197\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0217 - val_loss: 0.0195\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0222 - val_loss: 0.0191\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0215 - val_loss: 0.0188\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0194 - val_loss: 0.0185\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0206 - val_loss: 0.0183\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0227 - val_loss: 0.0181\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0205 - val_loss: 0.0179\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0207 - val_loss: 0.0177\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0214 - val_loss: 0.0176\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0212 - val_loss: 0.0173\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0213 - val_loss: 0.0171\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 119us/sample - loss: 0.0219 - val_loss: 0.0169\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0186 - val_loss: 0.0167\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 92us/sample - loss: 0.0198 - val_loss: 0.0164\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 78us/sample - loss: 0.0188 - val_loss: 0.0161\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0180 - val_loss: 0.0159\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0181 - val_loss: 0.0156\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 77us/sample - loss: 0.0192 - val_loss: 0.0154\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0191 - val_loss: 0.0153\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0177 - val_loss: 0.0151\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 84us/sample - loss: 0.0172 - val_loss: 0.0149\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0174 - val_loss: 0.0145\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 86us/sample - loss: 0.0176 - val_loss: 0.0144\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0143\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0141\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0177 - val_loss: 0.0140\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0173 - val_loss: 0.0139\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0172 - val_loss: 0.0135\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 102us/sample - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 116us/sample - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0159 - val_loss: 0.0130\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0128\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 112us/sample - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 92us/sample - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 89us/sample - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 77us/sample - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 78us/sample - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 76us/sample - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 92us/sample - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 118us/sample - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 79us/sample - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 135us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 147us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.058 - 0s 701us/sample - loss: 0.0554 - val_loss: 0.0337\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.0523 - val_loss: 0.0316\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 93us/sample - loss: 0.0520 - val_loss: 0.0295\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 100us/sample - loss: 0.0490 - val_loss: 0.0275\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 92us/sample - loss: 0.0472 - val_loss: 0.0257\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 86us/sample - loss: 0.0459 - val_loss: 0.0242\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 96us/sample - loss: 0.0420 - val_loss: 0.0227\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 92us/sample - loss: 0.0413 - val_loss: 0.0213\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 103us/sample - loss: 0.0400 - val_loss: 0.0201\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 109us/sample - loss: 0.0384 - val_loss: 0.0190\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 114us/sample - loss: 0.0354 - val_loss: 0.0179\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 125us/sample - loss: 0.0406 - val_loss: 0.0171\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 117us/sample - loss: 0.0373 - val_loss: 0.0163\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 111us/sample - loss: 0.0369 - val_loss: 0.0156\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 107us/sample - loss: 0.0362 - val_loss: 0.0150\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 133us/sample - loss: 0.0359 - val_loss: 0.0144\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 119us/sample - loss: 0.0354 - val_loss: 0.0140\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 104us/sample - loss: 0.0345 - val_loss: 0.0135\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 112us/sample - loss: 0.0326 - val_loss: 0.0132\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 115us/sample - loss: 0.0315 - val_loss: 0.0129\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 110us/sample - loss: 0.0321 - val_loss: 0.0126\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 112us/sample - loss: 0.0318 - val_loss: 0.0124\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 104us/sample - loss: 0.0281 - val_loss: 0.0121\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0300 - val_loss: 0.0120\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 101us/sample - loss: 0.0300 - val_loss: 0.0118\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0277 - val_loss: 0.0117\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 112us/sample - loss: 0.0292 - val_loss: 0.0115\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0299 - val_loss: 0.0114\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0341 - val_loss: 0.0113\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 101us/sample - loss: 0.0277 - val_loss: 0.0112\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 87us/sample - loss: 0.0302 - val_loss: 0.0112\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0273 - val_loss: 0.0111\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0267 - val_loss: 0.0110\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0289 - val_loss: 0.0110\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0271 - val_loss: 0.0109\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0263 - val_loss: 0.0109\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0282 - val_loss: 0.0108\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0271 - val_loss: 0.0107\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 80us/sample - loss: 0.0275 - val_loss: 0.0107\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 81us/sample - loss: 0.0253 - val_loss: 0.0106\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 79us/sample - loss: 0.0253 - val_loss: 0.0106\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 80us/sample - loss: 0.0250 - val_loss: 0.0105\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 89us/sample - loss: 0.0259 - val_loss: 0.0105\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0244 - val_loss: 0.0105\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0256 - val_loss: 0.0104\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0254 - val_loss: 0.0104\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 90us/sample - loss: 0.0236 - val_loss: 0.0103\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 88us/sample - loss: 0.0248 - val_loss: 0.0103\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 86us/sample - loss: 0.0231 - val_loss: 0.0102\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0237 - val_loss: 0.0102\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0201 - val_loss: 0.0102\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0224 - val_loss: 0.0102\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 99us/sample - loss: 0.0203 - val_loss: 0.0101\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0216 - val_loss: 0.0101\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 95us/sample - loss: 0.0221 - val_loss: 0.0101\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 104us/sample - loss: 0.0214 - val_loss: 0.0100\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0209 - val_loss: 0.0100\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0100\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0200 - val_loss: 0.0099\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0220 - val_loss: 0.0099\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 99us/sample - loss: 0.0186 - val_loss: 0.0098\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0214 - val_loss: 0.0098\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0098\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0170 - val_loss: 0.0097\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0170 - val_loss: 0.0097\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0206 - val_loss: 0.0097\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0195 - val_loss: 0.0097\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0183 - val_loss: 0.0097\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0169 - val_loss: 0.0096\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 87us/sample - loss: 0.0187 - val_loss: 0.0096\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0185 - val_loss: 0.0096\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0174 - val_loss: 0.0095\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0095\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0163 - val_loss: 0.0095\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0156 - val_loss: 0.0094\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0167 - val_loss: 0.0094\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 84us/sample - loss: 0.0172 - val_loss: 0.0094\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 84us/sample - loss: 0.0162 - val_loss: 0.0093\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0160 - val_loss: 0.0093\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0167 - val_loss: 0.0093\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 84us/sample - loss: 0.0163 - val_loss: 0.0092\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0158 - val_loss: 0.0092\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0092\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0092\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 85us/sample - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 82us/sample - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0091\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0149 - val_loss: 0.0091\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0090\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0090\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0147 - val_loss: 0.0089\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 107us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0148 - val_loss: 0.0088\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0129 - val_loss: 0.0088\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 97us/sample - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0127 - val_loss: 0.0087\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 107us/sample - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0141 - val_loss: 0.0086\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0126 - val_loss: 0.0086\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0109 - val_loss: 0.0083\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0082\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0080\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 104us/sample - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 102us/sample - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 80us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 115us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 80us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 104us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 79us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 91us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 89us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 113us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 127us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 130us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.889 - 0s 706us/sample - loss: 0.6143 - val_loss: 0.6731\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.852 - 0s 98us/sample - loss: 0.6272 - val_loss: 0.6380\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.623 - 0s 101us/sample - loss: 0.5865 - val_loss: 0.6039\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.359 - 0s 119us/sample - loss: 0.5603 - val_loss: 0.5728\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.464 - 0s 105us/sample - loss: 0.5481 - val_loss: 0.5423\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.347 - 0s 112us/sample - loss: 0.5108 - val_loss: 0.5137\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.387 - 0s 86us/sample - loss: 0.4639 - val_loss: 0.4874\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.495 - 0s 93us/sample - loss: 0.4339 - val_loss: 0.4628\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.411 - 0s 93us/sample - loss: 0.4532 - val_loss: 0.4384\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.274 - 0s 94us/sample - loss: 0.3870 - val_loss: 0.4163\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.327 - 0s 105us/sample - loss: 0.3995 - val_loss: 0.3960\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.546 - 0s 117us/sample - loss: 0.3892 - val_loss: 0.3734\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.250 - 0s 112us/sample - loss: 0.3665 - val_loss: 0.3541\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.400 - 0s 117us/sample - loss: 0.3584 - val_loss: 0.3353\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.432 - 0s 106us/sample - loss: 0.3249 - val_loss: 0.3184\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.345 - 0s 86us/sample - loss: 0.3046 - val_loss: 0.3038\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.432 - 0s 95us/sample - loss: 0.3373 - val_loss: 0.2875\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.218 - 0s 97us/sample - loss: 0.3022 - val_loss: 0.2736\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.223 - 0s 94us/sample - loss: 0.2987 - val_loss: 0.2619\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.246 - 0s 81us/sample - loss: 0.2920 - val_loss: 0.2498\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.372 - 0s 81us/sample - loss: 0.2722 - val_loss: 0.2381\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.419 - 0s 76us/sample - loss: 0.2697 - val_loss: 0.2267\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.404 - 0s 93us/sample - loss: 0.2502 - val_loss: 0.2162\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.205 - 0s 117us/sample - loss: 0.2898 - val_loss: 0.2069\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.185 - 0s 92us/sample - loss: 0.2732 - val_loss: 0.1987\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 96us/sample - loss: 0.2637 - val_loss: 0.1925\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.343 - 0s 76us/sample - loss: 0.2716 - val_loss: 0.1842\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.252 - 0s 74us/sample - loss: 0.2212 - val_loss: 0.1770\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 82us/sample - loss: 0.2325 - val_loss: 0.1702\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.219 - 0s 97us/sample - loss: 0.2351 - val_loss: 0.1631\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.264 - 0s 91us/sample - loss: 0.2318 - val_loss: 0.1592\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.285 - 0s 93us/sample - loss: 0.2228 - val_loss: 0.1556\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.195 - 0s 94us/sample - loss: 0.2068 - val_loss: 0.1513\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.117 - 0s 78us/sample - loss: 0.2084 - val_loss: 0.1469\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.176 - 0s 81us/sample - loss: 0.2165 - val_loss: 0.1435\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 88us/sample - loss: 0.2009 - val_loss: 0.1403\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.183 - 0s 84us/sample - loss: 0.1988 - val_loss: 0.1368\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.237 - 0s 104us/sample - loss: 0.2014 - val_loss: 0.1335\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 98us/sample - loss: 0.1855 - val_loss: 0.1296\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.154 - 0s 99us/sample - loss: 0.1729 - val_loss: 0.1258\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 83us/sample - loss: 0.1904 - val_loss: 0.1236\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 81us/sample - loss: 0.2015 - val_loss: 0.1205\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.193 - 0s 108us/sample - loss: 0.1763 - val_loss: 0.1167\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.226 - 0s 107us/sample - loss: 0.1809 - val_loss: 0.1148\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 107us/sample - loss: 0.1680 - val_loss: 0.1120\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.159 - 0s 127us/sample - loss: 0.1692 - val_loss: 0.1095\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.150 - 0s 134us/sample - loss: 0.1695 - val_loss: 0.1072\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.168 - 0s 143us/sample - loss: 0.1608 - val_loss: 0.1045\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 108us/sample - loss: 0.1540 - val_loss: 0.1015\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.140 - 0s 105us/sample - loss: 0.1481 - val_loss: 0.0981\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.211 - 0s 105us/sample - loss: 0.1603 - val_loss: 0.0957\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.161 - 0s 100us/sample - loss: 0.1573 - val_loss: 0.0940\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.224 - 0s 111us/sample - loss: 0.1552 - val_loss: 0.0931\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 105us/sample - loss: 0.1477 - val_loss: 0.0921\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 112us/sample - loss: 0.1474 - val_loss: 0.0905\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.156 - 0s 111us/sample - loss: 0.1360 - val_loss: 0.0874\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.129 - 0s 108us/sample - loss: 0.1403 - val_loss: 0.0861\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.142 - 0s 109us/sample - loss: 0.1430 - val_loss: 0.0846\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.120 - 0s 108us/sample - loss: 0.1247 - val_loss: 0.0828\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 108us/sample - loss: 0.1203 - val_loss: 0.0800\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 113us/sample - loss: 0.1346 - val_loss: 0.0783\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 108us/sample - loss: 0.1230 - val_loss: 0.0766\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.144 - 0s 91us/sample - loss: 0.1179 - val_loss: 0.0742\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.112 - 0s 98us/sample - loss: 0.1144 - val_loss: 0.0729\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 100us/sample - loss: 0.1151 - val_loss: 0.0713\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 98us/sample - loss: 0.1072 - val_loss: 0.0697\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 105us/sample - loss: 0.1147 - val_loss: 0.0683\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 112us/sample - loss: 0.1144 - val_loss: 0.0667\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 134us/sample - loss: 0.1003 - val_loss: 0.0647\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 95us/sample - loss: 0.1115 - val_loss: 0.0631\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 88us/sample - loss: 0.1001 - val_loss: 0.0620\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.136 - 0s 104us/sample - loss: 0.1026 - val_loss: 0.0606\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 88us/sample - loss: 0.0927 - val_loss: 0.0591\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 100us/sample - loss: 0.1039 - val_loss: 0.0575\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.123 - 0s 88us/sample - loss: 0.1026 - val_loss: 0.0563\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 95us/sample - loss: 0.0972 - val_loss: 0.0555\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.119 - 0s 93us/sample - loss: 0.0927 - val_loss: 0.0550\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.115 - 0s 108us/sample - loss: 0.0886 - val_loss: 0.0540\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 90us/sample - loss: 0.0902 - val_loss: 0.0529\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 100us/sample - loss: 0.0789 - val_loss: 0.0515\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 84us/sample - loss: 0.0852 - val_loss: 0.0506\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 87us/sample - loss: 0.0821 - val_loss: 0.0496\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 84us/sample - loss: 0.0841 - val_loss: 0.0485\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 90us/sample - loss: 0.0817 - val_loss: 0.0474\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 95us/sample - loss: 0.0794 - val_loss: 0.0460\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 94us/sample - loss: 0.0787 - val_loss: 0.0452\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 100us/sample - loss: 0.0748 - val_loss: 0.0445\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 93us/sample - loss: 0.0789 - val_loss: 0.0433\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 100us/sample - loss: 0.0780 - val_loss: 0.0419\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 98us/sample - loss: 0.0661 - val_loss: 0.0409\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 95us/sample - loss: 0.0702 - val_loss: 0.0400\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 103us/sample - loss: 0.0646 - val_loss: 0.0389\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 93us/sample - loss: 0.0637 - val_loss: 0.0380\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 91us/sample - loss: 0.0670 - val_loss: 0.0374\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 95us/sample - loss: 0.0671 - val_loss: 0.0367\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 91us/sample - loss: 0.0627 - val_loss: 0.0357\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 95us/sample - loss: 0.0576 - val_loss: 0.0350\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0589 - val_loss: 0.0341\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 88us/sample - loss: 0.0598 - val_loss: 0.0334\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0555 - val_loss: 0.0323\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 89us/sample - loss: 0.0537 - val_loss: 0.0313\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 96us/sample - loss: 0.0572 - val_loss: 0.0308\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 90us/sample - loss: 0.0527 - val_loss: 0.0302\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 94us/sample - loss: 0.0573 - val_loss: 0.0292\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 88us/sample - loss: 0.0456 - val_loss: 0.0285\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 78us/sample - loss: 0.0474 - val_loss: 0.0279\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 80us/sample - loss: 0.0499 - val_loss: 0.0271\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 78us/sample - loss: 0.0489 - val_loss: 0.0267\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 85us/sample - loss: 0.0462 - val_loss: 0.0261\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 81us/sample - loss: 0.0437 - val_loss: 0.0255\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 83us/sample - loss: 0.0457 - val_loss: 0.0250\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 94us/sample - loss: 0.0433 - val_loss: 0.0244\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 85us/sample - loss: 0.0445 - val_loss: 0.0238\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 95us/sample - loss: 0.0426 - val_loss: 0.0233\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0428 - val_loss: 0.0228\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 95us/sample - loss: 0.0399 - val_loss: 0.0222\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 94us/sample - loss: 0.0399 - val_loss: 0.0218\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 76us/sample - loss: 0.0410 - val_loss: 0.0213\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 77us/sample - loss: 0.0392 - val_loss: 0.0209\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 83us/sample - loss: 0.0406 - val_loss: 0.0203\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0330 - val_loss: 0.0199\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 84us/sample - loss: 0.0360 - val_loss: 0.0193\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0341 - val_loss: 0.0190\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 81us/sample - loss: 0.0338 - val_loss: 0.0186\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 88us/sample - loss: 0.0339 - val_loss: 0.0182\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 123us/sample - loss: 0.0322 - val_loss: 0.0179\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 94us/sample - loss: 0.0331 - val_loss: 0.0174\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0312 - val_loss: 0.0172\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 81us/sample - loss: 0.0307 - val_loss: 0.0169\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 97us/sample - loss: 0.0316 - val_loss: 0.0165\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0322 - val_loss: 0.0163\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 108us/sample - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0299 - val_loss: 0.0158\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0285 - val_loss: 0.0156\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0250 - val_loss: 0.0154\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0310 - val_loss: 0.0152\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0287 - val_loss: 0.0151\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 97us/sample - loss: 0.0266 - val_loss: 0.0149\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0264 - val_loss: 0.0148\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 96us/sample - loss: 0.0239 - val_loss: 0.0146\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0299 - val_loss: 0.0144\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 88us/sample - loss: 0.0282 - val_loss: 0.0142\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0244 - val_loss: 0.0141\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 89us/sample - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0265 - val_loss: 0.0140\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0250 - val_loss: 0.0139\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 93us/sample - loss: 0.0284 - val_loss: 0.0138\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0242 - val_loss: 0.0135\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0242 - val_loss: 0.0134\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 78us/sample - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 82us/sample - loss: 0.0223 - val_loss: 0.0131\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 80us/sample - loss: 0.0260 - val_loss: 0.0130\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0222 - val_loss: 0.0129\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 91us/sample - loss: 0.0214 - val_loss: 0.0127\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0238 - val_loss: 0.0126\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 82us/sample - loss: 0.0224 - val_loss: 0.0125\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 77us/sample - loss: 0.0195 - val_loss: 0.0124\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0186 - val_loss: 0.0121\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 85us/sample - loss: 0.0203 - val_loss: 0.0119\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0204 - val_loss: 0.0116\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 85us/sample - loss: 0.0196 - val_loss: 0.0116\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0114\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0114\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0207 - val_loss: 0.0113\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 82us/sample - loss: 0.0189 - val_loss: 0.0112\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0187 - val_loss: 0.0111\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0110\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0109\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0189 - val_loss: 0.0108\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0178 - val_loss: 0.0107\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0106\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 100us/sample - loss: 0.0180 - val_loss: 0.0106\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0174 - val_loss: 0.0105\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0166 - val_loss: 0.0104\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0165 - val_loss: 0.0103\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0168 - val_loss: 0.0103\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 109us/sample - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 117us/sample - loss: 0.0163 - val_loss: 0.0101\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0098\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0098\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 92us/sample - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0128 - val_loss: 0.0096\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 82us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 80us/sample - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0136 - val_loss: 0.0095\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0145 - val_loss: 0.0094\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0138 - val_loss: 0.0093\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0093\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 85us/sample - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0092\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0118 - val_loss: 0.0090\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0111 - val_loss: 0.0089\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0112 - val_loss: 0.0087\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 78us/sample - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 76us/sample - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 79us/sample - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.149 - 0s 746us/sample - loss: 0.1444 - val_loss: 0.1499\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.221 - 0s 95us/sample - loss: 0.1415 - val_loss: 0.1424\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 99us/sample - loss: 0.1251 - val_loss: 0.1355\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.120 - 0s 102us/sample - loss: 0.1242 - val_loss: 0.1291\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 102us/sample - loss: 0.1192 - val_loss: 0.1231\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 110us/sample - loss: 0.1071 - val_loss: 0.1176\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.119 - 0s 98us/sample - loss: 0.1115 - val_loss: 0.1122\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 100us/sample - loss: 0.1078 - val_loss: 0.1070\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 108us/sample - loss: 0.0999 - val_loss: 0.1022\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 104us/sample - loss: 0.0949 - val_loss: 0.0978\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 98us/sample - loss: 0.0910 - val_loss: 0.0936\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 95us/sample - loss: 0.0885 - val_loss: 0.0894\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 86us/sample - loss: 0.0859 - val_loss: 0.0855\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 95us/sample - loss: 0.0849 - val_loss: 0.0815\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 98us/sample - loss: 0.0799 - val_loss: 0.0777\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0767 - val_loss: 0.0740\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 81us/sample - loss: 0.0687 - val_loss: 0.0706\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 78us/sample - loss: 0.0684 - val_loss: 0.0674\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 89us/sample - loss: 0.0643 - val_loss: 0.0642\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 85us/sample - loss: 0.0607 - val_loss: 0.0611\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 86us/sample - loss: 0.0616 - val_loss: 0.0581\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 83us/sample - loss: 0.0566 - val_loss: 0.0552\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 93us/sample - loss: 0.0537 - val_loss: 0.0523\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 84us/sample - loss: 0.0536 - val_loss: 0.0497\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 90us/sample - loss: 0.0488 - val_loss: 0.0471\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 92us/sample - loss: 0.0467 - val_loss: 0.0447\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 90us/sample - loss: 0.0456 - val_loss: 0.0424\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0422 - val_loss: 0.0401\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0420 - val_loss: 0.0380\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 84us/sample - loss: 0.0397 - val_loss: 0.0361\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 85us/sample - loss: 0.0365 - val_loss: 0.0343\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 92us/sample - loss: 0.0359 - val_loss: 0.0325\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 85us/sample - loss: 0.0332 - val_loss: 0.0309\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0315 - val_loss: 0.0295\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0314 - val_loss: 0.0281\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0315 - val_loss: 0.0268\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 102us/sample - loss: 0.0294 - val_loss: 0.0257\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 93us/sample - loss: 0.0309 - val_loss: 0.0246\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 95us/sample - loss: 0.0275 - val_loss: 0.0236\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0252 - val_loss: 0.0227\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0253 - val_loss: 0.0220\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0264 - val_loss: 0.0213\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0255 - val_loss: 0.0206\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0245 - val_loss: 0.0200\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0247 - val_loss: 0.0195\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0267 - val_loss: 0.0189\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0231 - val_loss: 0.0185\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0210 - val_loss: 0.0181\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 92us/sample - loss: 0.0217 - val_loss: 0.0177\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 89us/sample - loss: 0.0208 - val_loss: 0.0174\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0223 - val_loss: 0.0171\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 92us/sample - loss: 0.0226 - val_loss: 0.0168\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0224 - val_loss: 0.0166\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0238 - val_loss: 0.0164\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0219 - val_loss: 0.0161\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0188 - val_loss: 0.0159\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 97us/sample - loss: 0.0183 - val_loss: 0.0157\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0155\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 76us/sample - loss: 0.0201 - val_loss: 0.0153\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0151\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 78us/sample - loss: 0.0204 - val_loss: 0.0150\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0148\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0182 - val_loss: 0.0147\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0203 - val_loss: 0.0145\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0191 - val_loss: 0.0145\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0188 - val_loss: 0.0143\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0178 - val_loss: 0.0142\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 85us/sample - loss: 0.0186 - val_loss: 0.0141\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 81us/sample - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0197 - val_loss: 0.0139\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0171 - val_loss: 0.0137\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0180 - val_loss: 0.0136\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 82us/sample - loss: 0.0187 - val_loss: 0.0135\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0180 - val_loss: 0.0134\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0185 - val_loss: 0.0133\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0184 - val_loss: 0.0132\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0176 - val_loss: 0.0131\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0187 - val_loss: 0.0130\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0183 - val_loss: 0.0129\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0172 - val_loss: 0.0129\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 82us/sample - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 105us/sample - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 107us/sample - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0150 - val_loss: 0.0120\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 92us/sample - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 115us/sample - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0150 - val_loss: 0.0117\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 111us/sample - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 108us/sample - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 113us/sample - loss: 0.0153 - val_loss: 0.0114\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 106us/sample - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 130us/sample - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0142 - val_loss: 0.0111\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0146 - val_loss: 0.0111\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 99us/sample - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0108\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0128 - val_loss: 0.0107\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 127us/sample - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0124 - val_loss: 0.0097\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0127 - val_loss: 0.0096\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0125 - val_loss: 0.0096\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0121 - val_loss: 0.0095\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 76us/sample - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 78us/sample - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 82us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 76us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.275 - 0s 748us/sample - loss: 0.3891 - val_loss: 0.3063\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.500 - 0s 93us/sample - loss: 0.3661 - val_loss: 0.2839\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.354 - 0s 89us/sample - loss: 0.3772 - val_loss: 0.2628\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.338 - 0s 93us/sample - loss: 0.3270 - val_loss: 0.2437\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.340 - 0s 96us/sample - loss: 0.3112 - val_loss: 0.2260\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.367 - 0s 93us/sample - loss: 0.2971 - val_loss: 0.2090\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.274 - 0s 89us/sample - loss: 0.2638 - val_loss: 0.1939\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.266 - 0s 87us/sample - loss: 0.2620 - val_loss: 0.1795\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.145 - 0s 110us/sample - loss: 0.2485 - val_loss: 0.1650\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.267 - 0s 86us/sample - loss: 0.2428 - val_loss: 0.1522\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.370 - 0s 78us/sample - loss: 0.2221 - val_loss: 0.1400\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.196 - 0s 89us/sample - loss: 0.2274 - val_loss: 0.1280\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.256 - 0s 85us/sample - loss: 0.2030 - val_loss: 0.1170\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.144 - 0s 82us/sample - loss: 0.2071 - val_loss: 0.1065\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.142 - 0s 83us/sample - loss: 0.1768 - val_loss: 0.0976\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.179 - 0s 88us/sample - loss: 0.1857 - val_loss: 0.0883\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.205 - 0s 84us/sample - loss: 0.1681 - val_loss: 0.0804\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.160 - 0s 84us/sample - loss: 0.1640 - val_loss: 0.0733\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.160 - 0s 87us/sample - loss: 0.1685 - val_loss: 0.0669\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.145 - 0s 100us/sample - loss: 0.1482 - val_loss: 0.0615\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.1279 - val_loss: 0.0568\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.228 - 0s 90us/sample - loss: 0.1467 - val_loss: 0.0526\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.117 - 0s 95us/sample - loss: 0.1274 - val_loss: 0.0489\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.215 - 0s 103us/sample - loss: 0.1348 - val_loss: 0.0457\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 108us/sample - loss: 0.1259 - val_loss: 0.0427\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 110us/sample - loss: 0.1147 - val_loss: 0.0402\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 103us/sample - loss: 0.1103 - val_loss: 0.0382\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 103us/sample - loss: 0.1087 - val_loss: 0.0363\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 98us/sample - loss: 0.1189 - val_loss: 0.0348\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 100us/sample - loss: 0.1161 - val_loss: 0.0333\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 88us/sample - loss: 0.1064 - val_loss: 0.0322\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.078 - 0s 100us/sample - loss: 0.1023 - val_loss: 0.0313\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 92us/sample - loss: 0.1050 - val_loss: 0.0304\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 103us/sample - loss: 0.1015 - val_loss: 0.0297\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 90us/sample - loss: 0.0934 - val_loss: 0.0292\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.106 - 0s 93us/sample - loss: 0.0977 - val_loss: 0.0288\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.160 - 0s 100us/sample - loss: 0.0931 - val_loss: 0.0284\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 100us/sample - loss: 0.0947 - val_loss: 0.0281\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 89us/sample - loss: 0.0930 - val_loss: 0.0278\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 98us/sample - loss: 0.0908 - val_loss: 0.0276\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 93us/sample - loss: 0.0844 - val_loss: 0.0273\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 98us/sample - loss: 0.0888 - val_loss: 0.0271\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 105us/sample - loss: 0.0889 - val_loss: 0.0269\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 88us/sample - loss: 0.0868 - val_loss: 0.0267\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 78us/sample - loss: 0.0792 - val_loss: 0.0265\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 94us/sample - loss: 0.0852 - val_loss: 0.0263\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 95us/sample - loss: 0.0864 - val_loss: 0.0260\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 106us/sample - loss: 0.0829 - val_loss: 0.0259\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 115us/sample - loss: 0.0794 - val_loss: 0.0257\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 100us/sample - loss: 0.0770 - val_loss: 0.0255\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 97us/sample - loss: 0.0776 - val_loss: 0.0253\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 81us/sample - loss: 0.0800 - val_loss: 0.0251\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 83us/sample - loss: 0.0799 - val_loss: 0.0249\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 80us/sample - loss: 0.0744 - val_loss: 0.0248\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 81us/sample - loss: 0.0708 - val_loss: 0.0246\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 84us/sample - loss: 0.0775 - val_loss: 0.0244\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 88us/sample - loss: 0.0723 - val_loss: 0.0243\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 88us/sample - loss: 0.0742 - val_loss: 0.0241\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 84us/sample - loss: 0.0705 - val_loss: 0.0240\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.0772 - val_loss: 0.0238\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 88us/sample - loss: 0.0592 - val_loss: 0.0237\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 105us/sample - loss: 0.0683 - val_loss: 0.0235\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 88us/sample - loss: 0.0650 - val_loss: 0.0234\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 88us/sample - loss: 0.0762 - val_loss: 0.0232\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 98us/sample - loss: 0.0622 - val_loss: 0.0231\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 85us/sample - loss: 0.0664 - val_loss: 0.0229\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 87us/sample - loss: 0.0625 - val_loss: 0.0227\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 108us/sample - loss: 0.0682 - val_loss: 0.0226\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 103us/sample - loss: 0.0570 - val_loss: 0.0224\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 105us/sample - loss: 0.0614 - val_loss: 0.0223\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0609 - val_loss: 0.0221\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 99us/sample - loss: 0.0541 - val_loss: 0.0220\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 93us/sample - loss: 0.0565 - val_loss: 0.0218\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 86us/sample - loss: 0.0607 - val_loss: 0.0216\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0551 - val_loss: 0.0214\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 99us/sample - loss: 0.0579 - val_loss: 0.0213\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 95us/sample - loss: 0.0544 - val_loss: 0.0211\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 90us/sample - loss: 0.0540 - val_loss: 0.0209\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 87us/sample - loss: 0.0538 - val_loss: 0.0207\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 92us/sample - loss: 0.0522 - val_loss: 0.0205\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 89us/sample - loss: 0.0489 - val_loss: 0.0203\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 94us/sample - loss: 0.0463 - val_loss: 0.0201\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 87us/sample - loss: 0.0443 - val_loss: 0.0198\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 89us/sample - loss: 0.0495 - val_loss: 0.0196\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 106us/sample - loss: 0.0490 - val_loss: 0.0193\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 91us/sample - loss: 0.0446 - val_loss: 0.0190\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 94us/sample - loss: 0.0423 - val_loss: 0.0187\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 81us/sample - loss: 0.0433 - val_loss: 0.0183\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 76us/sample - loss: 0.0433 - val_loss: 0.0179\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 85us/sample - loss: 0.0435 - val_loss: 0.0176\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 83us/sample - loss: 0.0383 - val_loss: 0.0173\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 80us/sample - loss: 0.0431 - val_loss: 0.0172\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 83us/sample - loss: 0.0355 - val_loss: 0.0170\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 83us/sample - loss: 0.0408 - val_loss: 0.0167\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0374 - val_loss: 0.0165\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0351 - val_loss: 0.0164\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 112us/sample - loss: 0.0429 - val_loss: 0.0163\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 83us/sample - loss: 0.0372 - val_loss: 0.0161\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 78us/sample - loss: 0.0355 - val_loss: 0.0159\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 98us/sample - loss: 0.0361 - val_loss: 0.0158\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 83us/sample - loss: 0.0364 - val_loss: 0.0157\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 86us/sample - loss: 0.0346 - val_loss: 0.0156\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 86us/sample - loss: 0.0354 - val_loss: 0.0154\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 78us/sample - loss: 0.0320 - val_loss: 0.0153\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 84us/sample - loss: 0.0334 - val_loss: 0.0152\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0345 - val_loss: 0.0152\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 95us/sample - loss: 0.0364 - val_loss: 0.0151\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 96us/sample - loss: 0.0339 - val_loss: 0.0151\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 87us/sample - loss: 0.0329 - val_loss: 0.0149\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 93us/sample - loss: 0.0331 - val_loss: 0.0148\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 90us/sample - loss: 0.0289 - val_loss: 0.0147\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0304 - val_loss: 0.0147\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 110us/sample - loss: 0.0282 - val_loss: 0.0146\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0314 - val_loss: 0.0145\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0299 - val_loss: 0.0144\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 94us/sample - loss: 0.0292 - val_loss: 0.0143\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0319 - val_loss: 0.0143\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0292 - val_loss: 0.0142\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 98us/sample - loss: 0.0322 - val_loss: 0.0142\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0297 - val_loss: 0.0142\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 106us/sample - loss: 0.0278 - val_loss: 0.0142\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 113us/sample - loss: 0.0296 - val_loss: 0.0141\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 92us/sample - loss: 0.0282 - val_loss: 0.0141\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0283 - val_loss: 0.0140\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 87us/sample - loss: 0.0257 - val_loss: 0.0139\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0247 - val_loss: 0.0138\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 88us/sample - loss: 0.0249 - val_loss: 0.0137\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 91us/sample - loss: 0.0272 - val_loss: 0.0137\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0261 - val_loss: 0.0137\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 87us/sample - loss: 0.0261 - val_loss: 0.0136\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0236 - val_loss: 0.0136\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 86us/sample - loss: 0.0254 - val_loss: 0.0135\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0243 - val_loss: 0.0135\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0221 - val_loss: 0.0134\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 97us/sample - loss: 0.0224 - val_loss: 0.0133\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 120us/sample - loss: 0.0219 - val_loss: 0.0133\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 99us/sample - loss: 0.0224 - val_loss: 0.0132\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 99us/sample - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0231 - val_loss: 0.0131\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0244 - val_loss: 0.0130\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 97us/sample - loss: 0.0220 - val_loss: 0.0130\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 93us/sample - loss: 0.0220 - val_loss: 0.0129\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 134us/sample - loss: 0.0205 - val_loss: 0.0128\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0213 - val_loss: 0.0128\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 113us/sample - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 100us/sample - loss: 0.0208 - val_loss: 0.0126\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 99us/sample - loss: 0.0191 - val_loss: 0.0126\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 103us/sample - loss: 0.0203 - val_loss: 0.0125\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 112us/sample - loss: 0.0206 - val_loss: 0.0125\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 114us/sample - loss: 0.0191 - val_loss: 0.0124\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0186 - val_loss: 0.0124\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0179 - val_loss: 0.0124\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 108us/sample - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 117us/sample - loss: 0.0192 - val_loss: 0.0122\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 124us/sample - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 116us/sample - loss: 0.0179 - val_loss: 0.0121\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 115us/sample - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 120us/sample - loss: 0.0193 - val_loss: 0.0121\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 122us/sample - loss: 0.0174 - val_loss: 0.0120\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 127us/sample - loss: 0.0165 - val_loss: 0.0120\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 115us/sample - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 134us/sample - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0187 - val_loss: 0.0119\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0179 - val_loss: 0.0118\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0180 - val_loss: 0.0118\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 89us/sample - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 79us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 81us/sample - loss: 0.0159 - val_loss: 0.0115\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0148 - val_loss: 0.0113\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0156 - val_loss: 0.0112\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 110us/sample - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 115us/sample - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 89us/sample - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 87us/sample - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 117us/sample - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 97us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 104us/sample - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 107us/sample - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 106us/sample - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 122us/sample - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 125us/sample - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 76us/sample - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 109us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 122us/sample - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0079\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.320 - 0s 663us/sample - loss: 0.3062 - val_loss: 0.2148\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.409 - 0s 92us/sample - loss: 0.2573 - val_loss: 0.1938\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.235 - 0s 88us/sample - loss: 0.2484 - val_loss: 0.1748\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.261 - 0s 90us/sample - loss: 0.2436 - val_loss: 0.1569\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.191 - 0s 88us/sample - loss: 0.2208 - val_loss: 0.1417\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 90us/sample - loss: 0.2057 - val_loss: 0.1272\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.165 - 0s 91us/sample - loss: 0.1794 - val_loss: 0.1153\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.151 - 0s 80us/sample - loss: 0.1770 - val_loss: 0.1049\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.148 - 0s 83us/sample - loss: 0.1686 - val_loss: 0.0969\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.115 - 0s 88us/sample - loss: 0.1595 - val_loss: 0.0882\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.166 - 0s 90us/sample - loss: 0.1569 - val_loss: 0.0818\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.188 - 0s 107us/sample - loss: 0.1350 - val_loss: 0.0763\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.192 - 0s 115us/sample - loss: 0.1283 - val_loss: 0.0718\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 110us/sample - loss: 0.1157 - val_loss: 0.0681\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.140 - 0s 89us/sample - loss: 0.1199 - val_loss: 0.0645\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 92us/sample - loss: 0.1163 - val_loss: 0.0617\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 96us/sample - loss: 0.1038 - val_loss: 0.0591\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 88us/sample - loss: 0.1115 - val_loss: 0.0566\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 95us/sample - loss: 0.1091 - val_loss: 0.0546\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 95us/sample - loss: 0.1060 - val_loss: 0.0529\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 95us/sample - loss: 0.0995 - val_loss: 0.0513\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 95us/sample - loss: 0.0941 - val_loss: 0.0496\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 93us/sample - loss: 0.0965 - val_loss: 0.0483\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 95us/sample - loss: 0.0988 - val_loss: 0.0468\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 98us/sample - loss: 0.0974 - val_loss: 0.0454\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 98us/sample - loss: 0.0805 - val_loss: 0.0446\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 100us/sample - loss: 0.0860 - val_loss: 0.0436\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 86us/sample - loss: 0.0903 - val_loss: 0.0422\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 92us/sample - loss: 0.0805 - val_loss: 0.0412\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.113 - 0s 93us/sample - loss: 0.0838 - val_loss: 0.0405\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 90us/sample - loss: 0.0906 - val_loss: 0.0395\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 117us/sample - loss: 0.0769 - val_loss: 0.0388\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 89us/sample - loss: 0.0738 - val_loss: 0.0381\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 100us/sample - loss: 0.0777 - val_loss: 0.0374\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.125 - 0s 93us/sample - loss: 0.0826 - val_loss: 0.0367\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.209 - 0s 85us/sample - loss: 0.0778 - val_loss: 0.0359\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 91us/sample - loss: 0.0749 - val_loss: 0.0352\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 88us/sample - loss: 0.0680 - val_loss: 0.0346\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 93us/sample - loss: 0.0766 - val_loss: 0.0339\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0718 - val_loss: 0.0332\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 81us/sample - loss: 0.0653 - val_loss: 0.0326\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 81us/sample - loss: 0.0666 - val_loss: 0.0321\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 81us/sample - loss: 0.0661 - val_loss: 0.0316\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 90us/sample - loss: 0.0682 - val_loss: 0.0311\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 83us/sample - loss: 0.0658 - val_loss: 0.0306\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 76us/sample - loss: 0.0617 - val_loss: 0.0302\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 77us/sample - loss: 0.0570 - val_loss: 0.0298\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 78us/sample - loss: 0.0587 - val_loss: 0.0294\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 82us/sample - loss: 0.0618 - val_loss: 0.0291\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0569 - val_loss: 0.0287\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 87us/sample - loss: 0.0632 - val_loss: 0.0284\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 88us/sample - loss: 0.0547 - val_loss: 0.0281\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 81us/sample - loss: 0.0518 - val_loss: 0.0278\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0520 - val_loss: 0.0276\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 86us/sample - loss: 0.0579 - val_loss: 0.0274\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0549 - val_loss: 0.0271\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 97us/sample - loss: 0.0535 - val_loss: 0.0268\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 95us/sample - loss: 0.0512 - val_loss: 0.0265\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 101us/sample - loss: 0.0513 - val_loss: 0.0263\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 110us/sample - loss: 0.0495 - val_loss: 0.0261\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 105us/sample - loss: 0.0488 - val_loss: 0.0258\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 101us/sample - loss: 0.0509 - val_loss: 0.0256\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 104us/sample - loss: 0.0461 - val_loss: 0.0254\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 108us/sample - loss: 0.0467 - val_loss: 0.0252\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 103us/sample - loss: 0.0444 - val_loss: 0.0249\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 105us/sample - loss: 0.0468 - val_loss: 0.0247\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 105us/sample - loss: 0.0459 - val_loss: 0.0244\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 93us/sample - loss: 0.0435 - val_loss: 0.0242\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 90us/sample - loss: 0.0449 - val_loss: 0.0240\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 93us/sample - loss: 0.0440 - val_loss: 0.0237\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.0458 - val_loss: 0.0235\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/sample - loss: 0.0408 - val_loss: 0.0232\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 130us/sample - loss: 0.0399 - val_loss: 0.0230\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.040 - 0s 205us/sample - loss: 0.0402 - val_loss: 0.0228\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 135us/sample - loss: 0.0427 - val_loss: 0.0226\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 113us/sample - loss: 0.0449 - val_loss: 0.0223\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0394 - val_loss: 0.0221\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0434 - val_loss: 0.0218\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 98us/sample - loss: 0.0435 - val_loss: 0.0215\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 100us/sample - loss: 0.0418 - val_loss: 0.0213\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0410 - val_loss: 0.0211\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 105us/sample - loss: 0.0409 - val_loss: 0.0209\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 108us/sample - loss: 0.0373 - val_loss: 0.0206\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0387 - val_loss: 0.0203\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 98us/sample - loss: 0.0375 - val_loss: 0.0201\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0359 - val_loss: 0.0199\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0325 - val_loss: 0.0198\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0331 - val_loss: 0.0196\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 103us/sample - loss: 0.0342 - val_loss: 0.0195\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 102us/sample - loss: 0.0364 - val_loss: 0.0192\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 103us/sample - loss: 0.0335 - val_loss: 0.0190\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 120us/sample - loss: 0.0305 - val_loss: 0.0188\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 98us/sample - loss: 0.0334 - val_loss: 0.0186\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 98us/sample - loss: 0.0349 - val_loss: 0.0184\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 99us/sample - loss: 0.0293 - val_loss: 0.0182\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 113us/sample - loss: 0.0309 - val_loss: 0.0180\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 115us/sample - loss: 0.0309 - val_loss: 0.0178\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 112us/sample - loss: 0.0325 - val_loss: 0.0176\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 115us/sample - loss: 0.0324 - val_loss: 0.0174\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 115us/sample - loss: 0.0312 - val_loss: 0.0172\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 120us/sample - loss: 0.0277 - val_loss: 0.0170\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 115us/sample - loss: 0.0308 - val_loss: 0.0169\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 112us/sample - loss: 0.0279 - val_loss: 0.0167\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 110us/sample - loss: 0.0280 - val_loss: 0.0166\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 120us/sample - loss: 0.0291 - val_loss: 0.0164\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 120us/sample - loss: 0.0306 - val_loss: 0.0162\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0276 - val_loss: 0.0161\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0272 - val_loss: 0.0159\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 105us/sample - loss: 0.0273 - val_loss: 0.0158\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 108us/sample - loss: 0.0270 - val_loss: 0.0157\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 105us/sample - loss: 0.0254 - val_loss: 0.0155\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 125us/sample - loss: 0.0252 - val_loss: 0.0154\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0248 - val_loss: 0.0153\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0238 - val_loss: 0.0152\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 111us/sample - loss: 0.0230 - val_loss: 0.0151\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0238 - val_loss: 0.0150\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 93us/sample - loss: 0.0264 - val_loss: 0.0149\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0230 - val_loss: 0.0148\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0228 - val_loss: 0.0147\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0223 - val_loss: 0.0146\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 107us/sample - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0222 - val_loss: 0.0144\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 85us/sample - loss: 0.0229 - val_loss: 0.0143\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0141\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0205 - val_loss: 0.0140\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 85us/sample - loss: 0.0207 - val_loss: 0.0140\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0239 - val_loss: 0.0138\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 102us/sample - loss: 0.0217 - val_loss: 0.0137\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0219 - val_loss: 0.0136\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 104us/sample - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0133\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0206 - val_loss: 0.0132\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 99us/sample - loss: 0.0183 - val_loss: 0.0131\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0208 - val_loss: 0.0130\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0208 - val_loss: 0.0129\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0206 - val_loss: 0.0129\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 113us/sample - loss: 0.0197 - val_loss: 0.0127\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 132us/sample - loss: 0.0180 - val_loss: 0.0126\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 169us/sample - loss: 0.0191 - val_loss: 0.0125\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 136us/sample - loss: 0.0201 - val_loss: 0.0124\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 117us/sample - loss: 0.0183 - val_loss: 0.0124\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 107us/sample - loss: 0.0186 - val_loss: 0.0123\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 144us/sample - loss: 0.0188 - val_loss: 0.0122\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 132us/sample - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 132us/sample - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 125us/sample - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0177 - val_loss: 0.0119\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0164 - val_loss: 0.0116\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0167 - val_loss: 0.0115\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 104us/sample - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 102us/sample - loss: 0.0158 - val_loss: 0.0114\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0157 - val_loss: 0.0110\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0108\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 106us/sample - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 114us/sample - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 97us/sample - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 103us/sample - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 117us/sample - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 130us/sample - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 114us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 126us/sample - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 120us/sample - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 119us/sample - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 119us/sample - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 125us/sample - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 129us/sample - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 111us/sample - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 116us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 78us/sample - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 78us/sample - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 121us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 74us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 80us/sample - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 78us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 76us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0057 - val_loss: 0.0074\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.517 - 0s 829us/sample - loss: 0.4774 - val_loss: 0.5090\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.324 - 0s 112us/sample - loss: 0.4329 - val_loss: 0.4809\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.570 - 0s 94us/sample - loss: 0.4338 - val_loss: 0.4531\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.421 - 0s 98us/sample - loss: 0.4006 - val_loss: 0.4272\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.407 - 0s 90us/sample - loss: 0.3743 - val_loss: 0.4027\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.543 - 0s 95us/sample - loss: 0.3612 - val_loss: 0.3791\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.340 - 0s 91us/sample - loss: 0.3189 - val_loss: 0.3583\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.390 - 0s 92us/sample - loss: 0.3085 - val_loss: 0.3384\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.344 - 0s 98us/sample - loss: 0.2963 - val_loss: 0.3196\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.297 - 0s 115us/sample - loss: 0.2747 - val_loss: 0.3012\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.243 - 0s 108us/sample - loss: 0.2613 - val_loss: 0.2842\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.194 - 0s 95us/sample - loss: 0.2460 - val_loss: 0.2685\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.236 - 0s 88us/sample - loss: 0.2204 - val_loss: 0.2536\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.199 - 0s 93us/sample - loss: 0.2176 - val_loss: 0.2396\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.209 - 0s 90us/sample - loss: 0.2116 - val_loss: 0.2260\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.202 - 0s 88us/sample - loss: 0.1988 - val_loss: 0.2127\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.106 - 0s 83us/sample - loss: 0.1769 - val_loss: 0.2009\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.182 - 0s 127us/sample - loss: 0.1729 - val_loss: 0.1896\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 90us/sample - loss: 0.1624 - val_loss: 0.1793\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.201 - 0s 78us/sample - loss: 0.1588 - val_loss: 0.1693\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.211 - 0s 84us/sample - loss: 0.1485 - val_loss: 0.1597\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.115 - 0s 78us/sample - loss: 0.1455 - val_loss: 0.1510\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.152 - 0s 78us/sample - loss: 0.1353 - val_loss: 0.1417\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.108 - 0s 81us/sample - loss: 0.1187 - val_loss: 0.1334\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 95us/sample - loss: 0.1150 - val_loss: 0.1250\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.202 - 0s 90us/sample - loss: 0.1191 - val_loss: 0.1167\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 92us/sample - loss: 0.1087 - val_loss: 0.1088\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.131 - 0s 92us/sample - loss: 0.1026 - val_loss: 0.1009\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 93us/sample - loss: 0.0954 - val_loss: 0.0934\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.118 - 0s 90us/sample - loss: 0.0896 - val_loss: 0.0857\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 98us/sample - loss: 0.0870 - val_loss: 0.0784\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 81us/sample - loss: 0.0757 - val_loss: 0.0716\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 95us/sample - loss: 0.0714 - val_loss: 0.0651\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 108us/sample - loss: 0.0695 - val_loss: 0.0590\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 122us/sample - loss: 0.0595 - val_loss: 0.0531\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 103us/sample - loss: 0.0599 - val_loss: 0.0475\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 93us/sample - loss: 0.0596 - val_loss: 0.0422\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 96us/sample - loss: 0.0544 - val_loss: 0.0372\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 89us/sample - loss: 0.0517 - val_loss: 0.0335\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 90us/sample - loss: 0.0474 - val_loss: 0.0305\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 100us/sample - loss: 0.0418 - val_loss: 0.0278\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 88us/sample - loss: 0.0455 - val_loss: 0.0255\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 97us/sample - loss: 0.0395 - val_loss: 0.0239\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 115us/sample - loss: 0.0397 - val_loss: 0.0227\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 120us/sample - loss: 0.0372 - val_loss: 0.0216\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 110us/sample - loss: 0.0392 - val_loss: 0.0208\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 100us/sample - loss: 0.0407 - val_loss: 0.0203\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 110us/sample - loss: 0.0402 - val_loss: 0.0197\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 95us/sample - loss: 0.0336 - val_loss: 0.0194\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/sample - loss: 0.0384 - val_loss: 0.0194\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 108us/sample - loss: 0.0353 - val_loss: 0.0190\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 101us/sample - loss: 0.0345 - val_loss: 0.0187\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 105us/sample - loss: 0.0344 - val_loss: 0.0184\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 116us/sample - loss: 0.0310 - val_loss: 0.0182\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 85us/sample - loss: 0.0360 - val_loss: 0.0182\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 77us/sample - loss: 0.0373 - val_loss: 0.0181\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 86us/sample - loss: 0.0329 - val_loss: 0.0180\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 83us/sample - loss: 0.0346 - val_loss: 0.0179\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 81us/sample - loss: 0.0328 - val_loss: 0.0177\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 80us/sample - loss: 0.0335 - val_loss: 0.0176\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0312 - val_loss: 0.0176\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 80us/sample - loss: 0.0301 - val_loss: 0.0174\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 88us/sample - loss: 0.0298 - val_loss: 0.0172\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0302 - val_loss: 0.0170\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 81us/sample - loss: 0.0310 - val_loss: 0.0169\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 150us/sample - loss: 0.0308 - val_loss: 0.0168\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 99us/sample - loss: 0.0313 - val_loss: 0.0167\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0307 - val_loss: 0.0166\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 115us/sample - loss: 0.0288 - val_loss: 0.0166\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 107us/sample - loss: 0.0321 - val_loss: 0.0164\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0286 - val_loss: 0.0163\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0298 - val_loss: 0.0162\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0267 - val_loss: 0.0162\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 114us/sample - loss: 0.0286 - val_loss: 0.0161\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 101us/sample - loss: 0.0303 - val_loss: 0.0160\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0258 - val_loss: 0.0160\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 107us/sample - loss: 0.0270 - val_loss: 0.0158\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 134us/sample - loss: 0.0290 - val_loss: 0.0157\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 144us/sample - loss: 0.0259 - val_loss: 0.0156\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 124us/sample - loss: 0.0259 - val_loss: 0.0155\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 139us/sample - loss: 0.0258 - val_loss: 0.0154\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 127us/sample - loss: 0.0265 - val_loss: 0.0152\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 137us/sample - loss: 0.0254 - val_loss: 0.0151\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 132us/sample - loss: 0.0233 - val_loss: 0.0150\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 112us/sample - loss: 0.0254 - val_loss: 0.0149\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 107us/sample - loss: 0.0243 - val_loss: 0.0148\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0243 - val_loss: 0.0147\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 105us/sample - loss: 0.0246 - val_loss: 0.0146\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 99us/sample - loss: 0.0247 - val_loss: 0.0145\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0239 - val_loss: 0.0144\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0236 - val_loss: 0.0144\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0216 - val_loss: 0.0143\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0234 - val_loss: 0.0142\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 100us/sample - loss: 0.0251 - val_loss: 0.0141\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0205 - val_loss: 0.0141\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0225 - val_loss: 0.0141\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 87us/sample - loss: 0.0222 - val_loss: 0.0140\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0217 - val_loss: 0.0140\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 102us/sample - loss: 0.0227 - val_loss: 0.0139\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0215 - val_loss: 0.0137\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0206 - val_loss: 0.0137\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0220 - val_loss: 0.0136\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0228 - val_loss: 0.0136\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0194 - val_loss: 0.0135\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0217 - val_loss: 0.0134\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0216 - val_loss: 0.0134\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0187 - val_loss: 0.0134\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 85us/sample - loss: 0.0222 - val_loss: 0.0133\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0230 - val_loss: 0.0132\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0182 - val_loss: 0.0131\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0206 - val_loss: 0.0130\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 147us/sample - loss: 0.0206 - val_loss: 0.0130\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0207 - val_loss: 0.0129\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 120us/sample - loss: 0.0211 - val_loss: 0.0129\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 142us/sample - loss: 0.0187 - val_loss: 0.0128\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 129us/sample - loss: 0.0184 - val_loss: 0.0128\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0194 - val_loss: 0.0127\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 112us/sample - loss: 0.0190 - val_loss: 0.0126\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0186 - val_loss: 0.0125\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 108us/sample - loss: 0.0186 - val_loss: 0.0125\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 104us/sample - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 87us/sample - loss: 0.0192 - val_loss: 0.0123\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0182 - val_loss: 0.0123\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 92us/sample - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 96us/sample - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0172 - val_loss: 0.0118\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 81us/sample - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 87us/sample - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0150 - val_loss: 0.0109\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0148 - val_loss: 0.0108\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 110us/sample - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 118us/sample - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 124us/sample - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 122us/sample - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 121us/sample - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 140us/sample - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 112us/sample - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 125us/sample - loss: 0.0119 - val_loss: 0.0098\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 102us/sample - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0118 - val_loss: 0.0093\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 127us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 99us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0054 - val_loss: 0.0069\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.417 - 0s 682us/sample - loss: 0.4288 - val_loss: 0.2385\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.258 - 0s 93us/sample - loss: 0.3575 - val_loss: 0.2163\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.568 - 0s 102us/sample - loss: 0.3814 - val_loss: 0.1963\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.298 - 0s 96us/sample - loss: 0.3090 - val_loss: 0.1782\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.396 - 0s 93us/sample - loss: 0.2928 - val_loss: 0.1622\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.214 - 0s 99us/sample - loss: 0.3077 - val_loss: 0.1466\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.324 - 0s 105us/sample - loss: 0.2921 - val_loss: 0.1327\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 94us/sample - loss: 0.2475 - val_loss: 0.1217\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.292 - 0s 98us/sample - loss: 0.2442 - val_loss: 0.1112\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.291 - 0s 103us/sample - loss: 0.2306 - val_loss: 0.1021\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.452 - 0s 108us/sample - loss: 0.2308 - val_loss: 0.0935\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.205 - 0s 109us/sample - loss: 0.2143 - val_loss: 0.0852\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.214 - 0s 120us/sample - loss: 0.1965 - val_loss: 0.0789\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.269 - 0s 113us/sample - loss: 0.1908 - val_loss: 0.0730\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 125us/sample - loss: 0.1914 - val_loss: 0.0680\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.216 - 0s 112us/sample - loss: 0.1868 - val_loss: 0.0634\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.185 - 0s 110us/sample - loss: 0.1638 - val_loss: 0.0597\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.159 - 0s 125us/sample - loss: 0.1731 - val_loss: 0.0564\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 102us/sample - loss: 0.1646 - val_loss: 0.0535\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 120us/sample - loss: 0.1722 - val_loss: 0.0509\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.161 - 0s 104us/sample - loss: 0.1528 - val_loss: 0.0486\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.164 - 0s 107us/sample - loss: 0.1539 - val_loss: 0.0467\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.187 - 0s 107us/sample - loss: 0.1527 - val_loss: 0.0449\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 105us/sample - loss: 0.1292 - val_loss: 0.0434\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.204 - 0s 108us/sample - loss: 0.1447 - val_loss: 0.0420\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 110us/sample - loss: 0.1383 - val_loss: 0.0408\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.151 - 0s 104us/sample - loss: 0.1406 - val_loss: 0.0398\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.167 - 0s 109us/sample - loss: 0.1229 - val_loss: 0.0389\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 97us/sample - loss: 0.1235 - val_loss: 0.0383\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 95us/sample - loss: 0.1271 - val_loss: 0.0377\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 90us/sample - loss: 0.1183 - val_loss: 0.0371\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.127 - 0s 101us/sample - loss: 0.1245 - val_loss: 0.0364\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.173 - 0s 100us/sample - loss: 0.1230 - val_loss: 0.0358\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.117 - 0s 100us/sample - loss: 0.1162 - val_loss: 0.0352\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.143 - 0s 91us/sample - loss: 0.1168 - val_loss: 0.0347\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 103us/sample - loss: 0.1202 - val_loss: 0.0341\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 110us/sample - loss: 0.1127 - val_loss: 0.0336\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 100us/sample - loss: 0.1158 - val_loss: 0.0332\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 94us/sample - loss: 0.1098 - val_loss: 0.0328\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.145 - 0s 93us/sample - loss: 0.1035 - val_loss: 0.0324\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 91us/sample - loss: 0.0978 - val_loss: 0.0320\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 93us/sample - loss: 0.1065 - val_loss: 0.0317\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 95us/sample - loss: 0.1053 - val_loss: 0.0313\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.108 - 0s 91us/sample - loss: 0.0849 - val_loss: 0.0310\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 93us/sample - loss: 0.1017 - val_loss: 0.0307\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 95us/sample - loss: 0.0944 - val_loss: 0.0303\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 90us/sample - loss: 0.0942 - val_loss: 0.0300\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 100us/sample - loss: 0.0905 - val_loss: 0.0297\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.157 - 0s 97us/sample - loss: 0.0879 - val_loss: 0.0293\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 100us/sample - loss: 0.0990 - val_loss: 0.0290\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 109us/sample - loss: 0.0792 - val_loss: 0.0288\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 113us/sample - loss: 0.0922 - val_loss: 0.0286\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 105us/sample - loss: 0.0825 - val_loss: 0.0283\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 117us/sample - loss: 0.0791 - val_loss: 0.0281\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 102us/sample - loss: 0.0811 - val_loss: 0.0279\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 108us/sample - loss: 0.0840 - val_loss: 0.0276\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.145 - 0s 100us/sample - loss: 0.0828 - val_loss: 0.0274\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 108us/sample - loss: 0.0816 - val_loss: 0.0272\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.106 - 0s 108us/sample - loss: 0.0796 - val_loss: 0.0269\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 109us/sample - loss: 0.0767 - val_loss: 0.0267\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 110us/sample - loss: 0.0737 - val_loss: 0.0264\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 129us/sample - loss: 0.0779 - val_loss: 0.0262\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 103us/sample - loss: 0.0754 - val_loss: 0.0260\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 100us/sample - loss: 0.0764 - val_loss: 0.0259\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 109us/sample - loss: 0.0722 - val_loss: 0.0256\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 115us/sample - loss: 0.0757 - val_loss: 0.0254\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 117us/sample - loss: 0.0724 - val_loss: 0.0252\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 100us/sample - loss: 0.0662 - val_loss: 0.0250\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 107us/sample - loss: 0.0631 - val_loss: 0.0249\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 103us/sample - loss: 0.0724 - val_loss: 0.0247\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 90us/sample - loss: 0.0674 - val_loss: 0.0245\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 88us/sample - loss: 0.0596 - val_loss: 0.0243\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 90us/sample - loss: 0.0691 - val_loss: 0.0241\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 94us/sample - loss: 0.0665 - val_loss: 0.0239\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 92us/sample - loss: 0.0658 - val_loss: 0.0237\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 83us/sample - loss: 0.0667 - val_loss: 0.0235\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 98us/sample - loss: 0.0596 - val_loss: 0.0233\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 92us/sample - loss: 0.0581 - val_loss: 0.0231\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 95us/sample - loss: 0.0625 - val_loss: 0.0229\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0596 - val_loss: 0.0227\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 93us/sample - loss: 0.0549 - val_loss: 0.0225\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 93us/sample - loss: 0.0575 - val_loss: 0.0224\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 90us/sample - loss: 0.0543 - val_loss: 0.0223\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 95us/sample - loss: 0.0542 - val_loss: 0.0222\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 93us/sample - loss: 0.0509 - val_loss: 0.0220\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 102us/sample - loss: 0.0551 - val_loss: 0.0219\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 103us/sample - loss: 0.0548 - val_loss: 0.0217\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 103us/sample - loss: 0.0544 - val_loss: 0.0215\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 91us/sample - loss: 0.0539 - val_loss: 0.0214\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0581 - val_loss: 0.0211\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 94us/sample - loss: 0.0533 - val_loss: 0.0209\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 94us/sample - loss: 0.0533 - val_loss: 0.0207\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 100us/sample - loss: 0.0485 - val_loss: 0.0206\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 99us/sample - loss: 0.0516 - val_loss: 0.0204\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 104us/sample - loss: 0.0502 - val_loss: 0.0203\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 105us/sample - loss: 0.0487 - val_loss: 0.0202\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 104us/sample - loss: 0.0457 - val_loss: 0.0201\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 109us/sample - loss: 0.0427 - val_loss: 0.0200\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 104us/sample - loss: 0.0473 - val_loss: 0.0198\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 108us/sample - loss: 0.0474 - val_loss: 0.0196\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 103us/sample - loss: 0.0466 - val_loss: 0.0194\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 117us/sample - loss: 0.0405 - val_loss: 0.0192\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 126us/sample - loss: 0.0436 - val_loss: 0.0191\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 121us/sample - loss: 0.0414 - val_loss: 0.0190\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 105us/sample - loss: 0.0455 - val_loss: 0.0189\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 103us/sample - loss: 0.0446 - val_loss: 0.0188\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 103us/sample - loss: 0.0439 - val_loss: 0.0186\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0378 - val_loss: 0.0185\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 105us/sample - loss: 0.0418 - val_loss: 0.0184\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 120us/sample - loss: 0.0450 - val_loss: 0.0182\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 110us/sample - loss: 0.0393 - val_loss: 0.0181\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 94us/sample - loss: 0.0397 - val_loss: 0.0180\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 88us/sample - loss: 0.0381 - val_loss: 0.0179\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 94us/sample - loss: 0.0407 - val_loss: 0.0178\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 106us/sample - loss: 0.0406 - val_loss: 0.0176\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 112us/sample - loss: 0.0386 - val_loss: 0.0174\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 101us/sample - loss: 0.0401 - val_loss: 0.0173\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 88us/sample - loss: 0.0367 - val_loss: 0.0172\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 87us/sample - loss: 0.0398 - val_loss: 0.0170\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0365 - val_loss: 0.0169\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 86us/sample - loss: 0.0363 - val_loss: 0.0168\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 90us/sample - loss: 0.0381 - val_loss: 0.0167\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0369 - val_loss: 0.0166\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0371 - val_loss: 0.0164\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 100us/sample - loss: 0.0335 - val_loss: 0.0163\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 108us/sample - loss: 0.0344 - val_loss: 0.0162\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0328 - val_loss: 0.0161\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 110us/sample - loss: 0.0382 - val_loss: 0.0160\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 104us/sample - loss: 0.0351 - val_loss: 0.0160\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 104us/sample - loss: 0.0348 - val_loss: 0.0159\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 95us/sample - loss: 0.0331 - val_loss: 0.0158\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0331 - val_loss: 0.0157\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0312 - val_loss: 0.0156\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 130us/sample - loss: 0.0305 - val_loss: 0.0155\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 107us/sample - loss: 0.0315 - val_loss: 0.0154\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 110us/sample - loss: 0.0283 - val_loss: 0.0153\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0321 - val_loss: 0.0152\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 115us/sample - loss: 0.0324 - val_loss: 0.0151\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 108us/sample - loss: 0.0292 - val_loss: 0.0151\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 102us/sample - loss: 0.0313 - val_loss: 0.0150\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 97us/sample - loss: 0.0297 - val_loss: 0.0149\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 99us/sample - loss: 0.0303 - val_loss: 0.0147\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0257 - val_loss: 0.0147\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 105us/sample - loss: 0.0303 - val_loss: 0.0146\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 109us/sample - loss: 0.0275 - val_loss: 0.0146\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 105us/sample - loss: 0.0276 - val_loss: 0.0145\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 101us/sample - loss: 0.0279 - val_loss: 0.0144\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 109us/sample - loss: 0.0264 - val_loss: 0.0143\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 103us/sample - loss: 0.0266 - val_loss: 0.0142\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0269 - val_loss: 0.0142\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 101us/sample - loss: 0.0262 - val_loss: 0.0141\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 103us/sample - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0274 - val_loss: 0.0139\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0259 - val_loss: 0.0138\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0272 - val_loss: 0.0138\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0262 - val_loss: 0.0137\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0251 - val_loss: 0.0136\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0240 - val_loss: 0.0136\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0242 - val_loss: 0.0135\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 98us/sample - loss: 0.0241 - val_loss: 0.0134\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0234 - val_loss: 0.0134\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 105us/sample - loss: 0.0232 - val_loss: 0.0133\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0256 - val_loss: 0.0132\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0252 - val_loss: 0.0132\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0231 - val_loss: 0.0131\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 99us/sample - loss: 0.0251 - val_loss: 0.0130\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 139us/sample - loss: 0.0239 - val_loss: 0.0128\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 112us/sample - loss: 0.0238 - val_loss: 0.0128\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 115us/sample - loss: 0.0215 - val_loss: 0.0127\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 92us/sample - loss: 0.0228 - val_loss: 0.0127\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 94us/sample - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0232 - val_loss: 0.0125\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 90us/sample - loss: 0.0216 - val_loss: 0.0124\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 97us/sample - loss: 0.0212 - val_loss: 0.0124\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 101us/sample - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 112us/sample - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0221 - val_loss: 0.0122\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0218 - val_loss: 0.0121\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 104us/sample - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 106us/sample - loss: 0.0223 - val_loss: 0.0120\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 107us/sample - loss: 0.0209 - val_loss: 0.0119\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 122us/sample - loss: 0.0200 - val_loss: 0.0119\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 102us/sample - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 115us/sample - loss: 0.0194 - val_loss: 0.0116\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 107us/sample - loss: 0.0186 - val_loss: 0.0115\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 113us/sample - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0113\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0185 - val_loss: 0.0113\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 94us/sample - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0160 - val_loss: 0.0111\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0170 - val_loss: 0.0110\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 125us/sample - loss: 0.0164 - val_loss: 0.0109\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 94us/sample - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 107us/sample - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 107us/sample - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 106us/sample - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 104us/sample - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 130us/sample - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 120us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 117us/sample - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 134us/sample - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 144us/sample - loss: 0.0121 - val_loss: 0.0097\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 147us/sample - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 123us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 104us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 109us/sample - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 104us/sample - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 117us/sample - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 117us/sample - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 122us/sample - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 121us/sample - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 125us/sample - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 147us/sample - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 117us/sample - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 117us/sample - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 122us/sample - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 136us/sample - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 122us/sample - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 152us/sample - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 94us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 295/300\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0287 - val_loss: 0.0134\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0285 - val_loss: 0.0133\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 83us/sample - loss: 0.0293 - val_loss: 0.0133\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 82us/sample - loss: 0.0291 - val_loss: 0.0132\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0303 - val_loss: 0.0131\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0283 - val_loss: 0.0130\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 81us/sample - loss: 0.0292 - val_loss: 0.0130\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0289 - val_loss: 0.0129\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0279 - val_loss: 0.0128\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0277 - val_loss: 0.0128\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 80us/sample - loss: 0.0219 - val_loss: 0.0126\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 78us/sample - loss: 0.0253 - val_loss: 0.0126\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 80us/sample - loss: 0.0242 - val_loss: 0.0125\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 82us/sample - loss: 0.0241 - val_loss: 0.0124\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 80us/sample - loss: 0.0235 - val_loss: 0.0124\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0215 - val_loss: 0.0124\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0214 - val_loss: 0.0123\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 134us/sample - loss: 0.0228 - val_loss: 0.0123\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 83us/sample - loss: 0.0210 - val_loss: 0.0122\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 85us/sample - loss: 0.0226 - val_loss: 0.0121\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0233 - val_loss: 0.0120\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0201 - val_loss: 0.0120\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 102us/sample - loss: 0.0223 - val_loss: 0.0119\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0212 - val_loss: 0.0119\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 112us/sample - loss: 0.0205 - val_loss: 0.0118\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0198 - val_loss: 0.0117\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0199 - val_loss: 0.0116\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0199 - val_loss: 0.0116\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 87us/sample - loss: 0.0179 - val_loss: 0.0113\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0189 - val_loss: 0.0112\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0186 - val_loss: 0.0112\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0111\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0110\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 102us/sample - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0157 - val_loss: 0.0109\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 85us/sample - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 109us/sample - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 84us/sample - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0123 - val_loss: 0.0097\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0126 - val_loss: 0.0096\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 112us/sample - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0090\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 122us/sample - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 76us/sample - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 130us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 104us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 125us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 114us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 115us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 129us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 82us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 81us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 82us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 2s - loss: 0.238 - 0s 850us/sample - loss: 0.2542 - val_loss: 0.2166\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.178 - 0s 94us/sample - loss: 0.2387 - val_loss: 0.1923\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.251 - 0s 100us/sample - loss: 0.2104 - val_loss: 0.1699\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.358 - 0s 100us/sample - loss: 0.2182 - val_loss: 0.1498\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.147 - 0s 98us/sample - loss: 0.1867 - val_loss: 0.1336\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.164 - 0s 108us/sample - loss: 0.1815 - val_loss: 0.1182\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 88us/sample - loss: 0.1454 - val_loss: 0.1057\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.182 - 0s 90us/sample - loss: 0.1481 - val_loss: 0.0952\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.125 - 0s 83us/sample - loss: 0.1332 - val_loss: 0.0856\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.215 - 0s 89us/sample - loss: 0.1353 - val_loss: 0.0781\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 88us/sample - loss: 0.1211 - val_loss: 0.0724\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.116 - 0s 89us/sample - loss: 0.1161 - val_loss: 0.0667\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.223 - 0s 90us/sample - loss: 0.1287 - val_loss: 0.0616\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 90us/sample - loss: 0.1079 - val_loss: 0.0572\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 88us/sample - loss: 0.1006 - val_loss: 0.0532\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.134 - 0s 93us/sample - loss: 0.1053 - val_loss: 0.0505\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.122 - 0s 83us/sample - loss: 0.0955 - val_loss: 0.0479\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 79us/sample - loss: 0.0954 - val_loss: 0.0460\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 114us/sample - loss: 0.0885 - val_loss: 0.0443\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 86us/sample - loss: 0.0832 - val_loss: 0.0432\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 83us/sample - loss: 0.0758 - val_loss: 0.0420\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 92us/sample - loss: 0.0839 - val_loss: 0.0408\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 83us/sample - loss: 0.0795 - val_loss: 0.0399\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 98us/sample - loss: 0.0791 - val_loss: 0.0391\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 86us/sample - loss: 0.0650 - val_loss: 0.0384\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 81us/sample - loss: 0.0774 - val_loss: 0.0374\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 88us/sample - loss: 0.0754 - val_loss: 0.0367\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 83us/sample - loss: 0.0760 - val_loss: 0.0358\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 83us/sample - loss: 0.0736 - val_loss: 0.0350\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 88us/sample - loss: 0.0676 - val_loss: 0.0342\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 103us/sample - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0695 - val_loss: 0.0332\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0673 - val_loss: 0.0328\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0629 - val_loss: 0.0322\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 90us/sample - loss: 0.0627 - val_loss: 0.0318\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 93us/sample - loss: 0.0632 - val_loss: 0.0313\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 93us/sample - loss: 0.0623 - val_loss: 0.0309\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 97us/sample - loss: 0.0563 - val_loss: 0.0304\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 102us/sample - loss: 0.0638 - val_loss: 0.0299\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 115us/sample - loss: 0.0570 - val_loss: 0.0294\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 103us/sample - loss: 0.0479 - val_loss: 0.0288\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 104us/sample - loss: 0.0530 - val_loss: 0.0283\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 97us/sample - loss: 0.0559 - val_loss: 0.0279\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 86us/sample - loss: 0.0580 - val_loss: 0.0274\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0555 - val_loss: 0.0269\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0512 - val_loss: 0.0265\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 89us/sample - loss: 0.0481 - val_loss: 0.0261\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 90us/sample - loss: 0.0523 - val_loss: 0.0258\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 98us/sample - loss: 0.0473 - val_loss: 0.0255\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0487 - val_loss: 0.0251\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.078 - 0s 98us/sample - loss: 0.0474 - val_loss: 0.0247\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 84us/sample - loss: 0.0488 - val_loss: 0.0242\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0495 - val_loss: 0.0239\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 97us/sample - loss: 0.0514 - val_loss: 0.0236\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 89us/sample - loss: 0.0472 - val_loss: 0.0234\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 99us/sample - loss: 0.0414 - val_loss: 0.0231\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0437 - val_loss: 0.0229\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 83us/sample - loss: 0.0437 - val_loss: 0.0226\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0439 - val_loss: 0.0224\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 92us/sample - loss: 0.0400 - val_loss: 0.0222\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 83us/sample - loss: 0.0431 - val_loss: 0.0220\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 86us/sample - loss: 0.0403 - val_loss: 0.0218\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 83us/sample - loss: 0.0428 - val_loss: 0.0215\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 90us/sample - loss: 0.0407 - val_loss: 0.0213\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 88us/sample - loss: 0.0397 - val_loss: 0.0211\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 79us/sample - loss: 0.0424 - val_loss: 0.0209\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 83us/sample - loss: 0.0367 - val_loss: 0.0207\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 85us/sample - loss: 0.0365 - val_loss: 0.0205\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 77us/sample - loss: 0.0414 - val_loss: 0.0203\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0342 - val_loss: 0.0201\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 83us/sample - loss: 0.0378 - val_loss: 0.0200\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 83us/sample - loss: 0.0382 - val_loss: 0.0198\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 81us/sample - loss: 0.0378 - val_loss: 0.0196\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 85us/sample - loss: 0.0363 - val_loss: 0.0194\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 84us/sample - loss: 0.0381 - val_loss: 0.0192\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 98us/sample - loss: 0.0366 - val_loss: 0.0190\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 92us/sample - loss: 0.0372 - val_loss: 0.0189\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 103us/sample - loss: 0.0380 - val_loss: 0.0187\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 96us/sample - loss: 0.0348 - val_loss: 0.0185\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0326 - val_loss: 0.0184\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0317 - val_loss: 0.0182\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0290 - val_loss: 0.0181\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0322 - val_loss: 0.0179\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0327 - val_loss: 0.0178\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0338 - val_loss: 0.0176\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 108us/sample - loss: 0.0312 - val_loss: 0.0175\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 117us/sample - loss: 0.0296 - val_loss: 0.0173\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 122us/sample - loss: 0.0307 - val_loss: 0.0172\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 129us/sample - loss: 0.0299 - val_loss: 0.0171\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 122us/sample - loss: 0.0316 - val_loss: 0.0170\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0330 - val_loss: 0.0168\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 112us/sample - loss: 0.0298 - val_loss: 0.0167\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0285 - val_loss: 0.0165\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 98us/sample - loss: 0.0324 - val_loss: 0.0164\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0288 - val_loss: 0.0163\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 81us/sample - loss: 0.0310 - val_loss: 0.0162\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0283 - val_loss: 0.0161\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 83us/sample - loss: 0.0312 - val_loss: 0.0160\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0305 - val_loss: 0.0158\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0265 - val_loss: 0.0157\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0283 - val_loss: 0.0156\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 87us/sample - loss: 0.0285 - val_loss: 0.0155\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 77us/sample - loss: 0.0286 - val_loss: 0.0154\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0318 - val_loss: 0.0153\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0292 - val_loss: 0.0152\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 82us/sample - loss: 0.0268 - val_loss: 0.0151\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0255 - val_loss: 0.0150\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0258 - val_loss: 0.0149\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0263 - val_loss: 0.0148\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 87us/sample - loss: 0.0265 - val_loss: 0.0148\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0238 - val_loss: 0.0147\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 87us/sample - loss: 0.0260 - val_loss: 0.0146\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0249 - val_loss: 0.0145\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 91us/sample - loss: 0.0230 - val_loss: 0.0144\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 89us/sample - loss: 0.0281 - val_loss: 0.0143\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0243 - val_loss: 0.0142\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0255 - val_loss: 0.0142\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 78us/sample - loss: 0.0252 - val_loss: 0.0141\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0226 - val_loss: 0.0140\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0250 - val_loss: 0.0139\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 110us/sample - loss: 0.0231 - val_loss: 0.0138\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0233 - val_loss: 0.0137\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0242 - val_loss: 0.0136\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 102us/sample - loss: 0.0228 - val_loss: 0.0135\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 96us/sample - loss: 0.0228 - val_loss: 0.0134\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 117us/sample - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0225 - val_loss: 0.0133\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 96us/sample - loss: 0.0231 - val_loss: 0.0132\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 128us/sample - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 117us/sample - loss: 0.0219 - val_loss: 0.0129\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0203 - val_loss: 0.0128\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0221 - val_loss: 0.0128\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0201 - val_loss: 0.0127\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 90us/sample - loss: 0.0221 - val_loss: 0.0126\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 102us/sample - loss: 0.0197 - val_loss: 0.0125\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0201 - val_loss: 0.0124\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0123\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 94us/sample - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 78us/sample - loss: 0.0199 - val_loss: 0.0121\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 80us/sample - loss: 0.0189 - val_loss: 0.0120\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 84us/sample - loss: 0.0217 - val_loss: 0.0119\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 82us/sample - loss: 0.0201 - val_loss: 0.0118\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 84us/sample - loss: 0.0211 - val_loss: 0.0118\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 81us/sample - loss: 0.0197 - val_loss: 0.0117\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0182 - val_loss: 0.0116\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0195 - val_loss: 0.0116\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 85us/sample - loss: 0.0207 - val_loss: 0.0114\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 80us/sample - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 82us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 87us/sample - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0177 - val_loss: 0.0110\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 84us/sample - loss: 0.0178 - val_loss: 0.0108\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 78us/sample - loss: 0.0179 - val_loss: 0.0107\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 91us/sample - loss: 0.0179 - val_loss: 0.0106\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0174 - val_loss: 0.0105\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0105\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0168 - val_loss: 0.0104\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0177 - val_loss: 0.0103\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0103\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 98us/sample - loss: 0.0168 - val_loss: 0.0103\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 81us/sample - loss: 0.0156 - val_loss: 0.0102\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0159 - val_loss: 0.0101\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 110us/sample - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 104us/sample - loss: 0.0160 - val_loss: 0.0099\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 107us/sample - loss: 0.0164 - val_loss: 0.0098\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0149 - val_loss: 0.0097\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 89us/sample - loss: 0.0163 - val_loss: 0.0095\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0094\n",
      "Epoch 187/300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/408 [==============================] - 0s 90us/sample - loss: 0.0744 - val_loss: 0.0371\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 95us/sample - loss: 0.0742 - val_loss: 0.0333\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 89us/sample - loss: 0.0626 - val_loss: 0.0302\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 92us/sample - loss: 0.0699 - val_loss: 0.0275\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 125us/sample - loss: 0.0594 - val_loss: 0.0252\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 117us/sample - loss: 0.0625 - val_loss: 0.0233\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 123us/sample - loss: 0.0579 - val_loss: 0.0217\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0521 - val_loss: 0.0202\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 100us/sample - loss: 0.0573 - val_loss: 0.0191\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 111us/sample - loss: 0.0581 - val_loss: 0.0182\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 115us/sample - loss: 0.0604 - val_loss: 0.0175\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.0474 - val_loss: 0.0168\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 105us/sample - loss: 0.0465 - val_loss: 0.0163\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 108us/sample - loss: 0.0517 - val_loss: 0.0159\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 91us/sample - loss: 0.0478 - val_loss: 0.0154\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 127us/sample - loss: 0.0456 - val_loss: 0.0150\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 94us/sample - loss: 0.0462 - val_loss: 0.0147\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 100us/sample - loss: 0.0437 - val_loss: 0.0144\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0408 - val_loss: 0.0141\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 106us/sample - loss: 0.0416 - val_loss: 0.0138\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 110us/sample - loss: 0.0435 - val_loss: 0.0136\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 105us/sample - loss: 0.0404 - val_loss: 0.0134\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 95us/sample - loss: 0.0427 - val_loss: 0.0132\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0388 - val_loss: 0.0130\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 79us/sample - loss: 0.0402 - val_loss: 0.0128\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 88us/sample - loss: 0.0338 - val_loss: 0.0126\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 87us/sample - loss: 0.0359 - val_loss: 0.0124\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 89us/sample - loss: 0.0375 - val_loss: 0.0122\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 88us/sample - loss: 0.0363 - val_loss: 0.0120\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 99us/sample - loss: 0.0338 - val_loss: 0.0119\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0361 - val_loss: 0.0117\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 86us/sample - loss: 0.0378 - val_loss: 0.0116\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0315 - val_loss: 0.0114\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 90us/sample - loss: 0.0324 - val_loss: 0.0113\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0311 - val_loss: 0.0112\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0312 - val_loss: 0.0111\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 86us/sample - loss: 0.0279 - val_loss: 0.0109\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0309 - val_loss: 0.0108\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 91us/sample - loss: 0.0285 - val_loss: 0.0107\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 81us/sample - loss: 0.0335 - val_loss: 0.0106\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0301 - val_loss: 0.0105\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 86us/sample - loss: 0.0297 - val_loss: 0.0104\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0298 - val_loss: 0.0103\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0308 - val_loss: 0.0102\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0274 - val_loss: 0.0101\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0279 - val_loss: 0.0101\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0288 - val_loss: 0.0100\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 102us/sample - loss: 0.0282 - val_loss: 0.0099\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/sample - loss: 0.0269 - val_loss: 0.0099\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0253 - val_loss: 0.0098\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0246 - val_loss: 0.0098\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0266 - val_loss: 0.0097\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 108us/sample - loss: 0.0260 - val_loss: 0.0097\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 107us/sample - loss: 0.0241 - val_loss: 0.0096\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 105us/sample - loss: 0.0229 - val_loss: 0.0096\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 121us/sample - loss: 0.0216 - val_loss: 0.0096\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0246 - val_loss: 0.0096\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 115us/sample - loss: 0.0242 - val_loss: 0.0095\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0212 - val_loss: 0.0095\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/sample - loss: 0.0219 - val_loss: 0.0094\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0213 - val_loss: 0.0094\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0208 - val_loss: 0.0094\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0200 - val_loss: 0.0094\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0204 - val_loss: 0.0093\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 105us/sample - loss: 0.0214 - val_loss: 0.0093\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 106us/sample - loss: 0.0192 - val_loss: 0.0093\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 112us/sample - loss: 0.0209 - val_loss: 0.0093\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 85us/sample - loss: 0.0204 - val_loss: 0.0092\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0207 - val_loss: 0.0092\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 100us/sample - loss: 0.0186 - val_loss: 0.0092\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0205 - val_loss: 0.0091\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0187 - val_loss: 0.0091\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0191 - val_loss: 0.0091\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 112us/sample - loss: 0.0179 - val_loss: 0.0091\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 110us/sample - loss: 0.0202 - val_loss: 0.0090\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0193 - val_loss: 0.0090\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 101us/sample - loss: 0.0164 - val_loss: 0.0090\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 110us/sample - loss: 0.0175 - val_loss: 0.0090\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0179 - val_loss: 0.0090\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 127us/sample - loss: 0.0187 - val_loss: 0.0090\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0169 - val_loss: 0.0090\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 84us/sample - loss: 0.0168 - val_loss: 0.0090\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0173 - val_loss: 0.0089\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0168 - val_loss: 0.0089\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0191 - val_loss: 0.0089\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 80us/sample - loss: 0.0179 - val_loss: 0.0088\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 79us/sample - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0168 - val_loss: 0.0088\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 89us/sample - loss: 0.0166 - val_loss: 0.0088\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 109us/sample - loss: 0.0151 - val_loss: 0.0088\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 111us/sample - loss: 0.0148 - val_loss: 0.0087\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 108us/sample - loss: 0.0175 - val_loss: 0.0087\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0146 - val_loss: 0.0087\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0174 - val_loss: 0.0087\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 107us/sample - loss: 0.0158 - val_loss: 0.0086\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 111us/sample - loss: 0.0144 - val_loss: 0.0086\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0159 - val_loss: 0.0086\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0160 - val_loss: 0.0086\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0148 - val_loss: 0.0085\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 106us/sample - loss: 0.0147 - val_loss: 0.0085\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 104us/sample - loss: 0.0151 - val_loss: 0.0085\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0139 - val_loss: 0.0085\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 113us/sample - loss: 0.0157 - val_loss: 0.0084\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 96us/sample - loss: 0.0141 - val_loss: 0.0084\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 102us/sample - loss: 0.0153 - val_loss: 0.0084\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0132 - val_loss: 0.0083\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0145 - val_loss: 0.0083\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 109us/sample - loss: 0.0139 - val_loss: 0.0083\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 101us/sample - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0083\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0082\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 109us/sample - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 82us/sample - loss: 0.0120 - val_loss: 0.0080\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 113us/sample - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 107us/sample - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0113 - val_loss: 0.0080\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 87us/sample - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 117us/sample - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 111us/sample - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 115us/sample - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 129us/sample - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 125us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 106us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 76us/sample - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 107us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 107us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 84us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 79us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 125us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 75us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 111us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 124us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 89us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.233 - 0s 1ms/sample - loss: 0.2605 - val_loss: 0.2284\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.179 - 0s 115us/sample - loss: 0.2529 - val_loss: 0.2060\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.224 - 0s 108us/sample - loss: 0.2218 - val_loss: 0.1853\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.229 - 0s 107us/sample - loss: 0.2053 - val_loss: 0.1668\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.186 - 0s 109us/sample - loss: 0.2031 - val_loss: 0.1499\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.244 - 0s 110us/sample - loss: 0.1820 - val_loss: 0.1347\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.160 - 0s 106us/sample - loss: 0.1636 - val_loss: 0.1206\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.131 - 0s 104us/sample - loss: 0.1399 - val_loss: 0.1088\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 95us/sample - loss: 0.1363 - val_loss: 0.0977\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 94us/sample - loss: 0.1246 - val_loss: 0.0882\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 90us/sample - loss: 0.1090 - val_loss: 0.0802\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 98us/sample - loss: 0.1134 - val_loss: 0.0724\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.129 - 0s 95us/sample - loss: 0.1131 - val_loss: 0.0655\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 98us/sample - loss: 0.0972 - val_loss: 0.0594\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 99us/sample - loss: 0.0901 - val_loss: 0.0542\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.078 - 0s 98us/sample - loss: 0.0888 - val_loss: 0.0496\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 103us/sample - loss: 0.0809 - val_loss: 0.0459\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 95us/sample - loss: 0.0893 - val_loss: 0.0422\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 98us/sample - loss: 0.0742 - val_loss: 0.0392\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 99us/sample - loss: 0.0771 - val_loss: 0.0361\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 85us/sample - loss: 0.0717 - val_loss: 0.0339\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 86us/sample - loss: 0.0669 - val_loss: 0.0318\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 88us/sample - loss: 0.0661 - val_loss: 0.0302\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 80us/sample - loss: 0.0644 - val_loss: 0.0289\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 90us/sample - loss: 0.0730 - val_loss: 0.0276\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 89us/sample - loss: 0.0708 - val_loss: 0.0265\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 89us/sample - loss: 0.0574 - val_loss: 0.0256\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 82us/sample - loss: 0.0670 - val_loss: 0.0248\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 81us/sample - loss: 0.0578 - val_loss: 0.0241\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 115us/sample - loss: 0.0609 - val_loss: 0.0236\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 105us/sample - loss: 0.0613 - val_loss: 0.0232\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 120us/sample - loss: 0.0531 - val_loss: 0.0228\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 127us/sample - loss: 0.0473 - val_loss: 0.0223\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 112us/sample - loss: 0.0541 - val_loss: 0.0219\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 103us/sample - loss: 0.0505 - val_loss: 0.0216\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 95us/sample - loss: 0.0530 - val_loss: 0.0213\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 96us/sample - loss: 0.0545 - val_loss: 0.0211\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 97us/sample - loss: 0.0473 - val_loss: 0.0209\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 102us/sample - loss: 0.0461 - val_loss: 0.0207\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 91us/sample - loss: 0.0466 - val_loss: 0.0206\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 90us/sample - loss: 0.0491 - val_loss: 0.0204\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 91us/sample - loss: 0.0479 - val_loss: 0.0201\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 93us/sample - loss: 0.0486 - val_loss: 0.0199\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 95us/sample - loss: 0.0479 - val_loss: 0.0196\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 100us/sample - loss: 0.0430 - val_loss: 0.0195\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.0413 - val_loss: 0.0193\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0471 - val_loss: 0.0191\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 93us/sample - loss: 0.0434 - val_loss: 0.0190\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 94us/sample - loss: 0.0413 - val_loss: 0.0189\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0411 - val_loss: 0.0187\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 87us/sample - loss: 0.0411 - val_loss: 0.0186\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 78us/sample - loss: 0.0406 - val_loss: 0.0184\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 83us/sample - loss: 0.0371 - val_loss: 0.0184\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 95us/sample - loss: 0.0392 - val_loss: 0.0183\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 81us/sample - loss: 0.0421 - val_loss: 0.0181\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 83us/sample - loss: 0.0359 - val_loss: 0.0180\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 92us/sample - loss: 0.0355 - val_loss: 0.0178\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 83us/sample - loss: 0.0375 - val_loss: 0.0176\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 83us/sample - loss: 0.0340 - val_loss: 0.0174\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 87us/sample - loss: 0.0373 - val_loss: 0.0173\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 113us/sample - loss: 0.0378 - val_loss: 0.0171\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0344 - val_loss: 0.0170\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0335 - val_loss: 0.0169\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 86us/sample - loss: 0.0363 - val_loss: 0.0168\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 81us/sample - loss: 0.0318 - val_loss: 0.0167\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0323 - val_loss: 0.0166\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0326 - val_loss: 0.0165\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0315 - val_loss: 0.0163\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 82us/sample - loss: 0.0316 - val_loss: 0.0162\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0321 - val_loss: 0.0160\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0299 - val_loss: 0.0159\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 93us/sample - loss: 0.0325 - val_loss: 0.0157\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0302 - val_loss: 0.0156\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 90us/sample - loss: 0.0291 - val_loss: 0.0155\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 107us/sample - loss: 0.0267 - val_loss: 0.0154\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0255 - val_loss: 0.0153\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 100us/sample - loss: 0.0280 - val_loss: 0.0152\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 98us/sample - loss: 0.0284 - val_loss: 0.0151\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0296 - val_loss: 0.0150\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 100us/sample - loss: 0.0284 - val_loss: 0.0149\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0274 - val_loss: 0.0148\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 102us/sample - loss: 0.0270 - val_loss: 0.0147\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 108us/sample - loss: 0.0252 - val_loss: 0.0145\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0220 - val_loss: 0.0144\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0230 - val_loss: 0.0144\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 90us/sample - loss: 0.0257 - val_loss: 0.0143\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 90us/sample - loss: 0.0266 - val_loss: 0.0142\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 86us/sample - loss: 0.0235 - val_loss: 0.0139\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0227 - val_loss: 0.0138\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 96us/sample - loss: 0.0248 - val_loss: 0.0136\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 117us/sample - loss: 0.0207 - val_loss: 0.0135\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0134\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0241 - val_loss: 0.0133\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0220 - val_loss: 0.0132\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 77us/sample - loss: 0.0208 - val_loss: 0.0131\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0190 - val_loss: 0.0129\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 84us/sample - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0214 - val_loss: 0.0127\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 85us/sample - loss: 0.0223 - val_loss: 0.0126\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 110us/sample - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0206 - val_loss: 0.0124\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 87us/sample - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 80us/sample - loss: 0.0204 - val_loss: 0.0123\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0231 - val_loss: 0.0122\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0204 - val_loss: 0.0121\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0193 - val_loss: 0.0118\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0188 - val_loss: 0.0118\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0163 - val_loss: 0.0114\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 107us/sample - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 107us/sample - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 87us/sample - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 121us/sample - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0108\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 122us/sample - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0153 - val_loss: 0.0101\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 97us/sample - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 82us/sample - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 82us/sample - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 85us/sample - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0137 - val_loss: 0.0094\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0139 - val_loss: 0.0093\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0125 - val_loss: 0.0093\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 109us/sample - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 92us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0122 - val_loss: 0.0090\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 110us/sample - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0107 - val_loss: 0.0086\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 82us/sample - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 115us/sample - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 99us/sample - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0091 - val_loss: 0.0082\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 107us/sample - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 127us/sample - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 78us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 81us/sample - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 79us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 134us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 79us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 99us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.724 - 0s 650us/sample - loss: 0.7786 - val_loss: 0.4600\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 1.152 - 0s 93us/sample - loss: 0.7206 - val_loss: 0.4274\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.619 - 0s 88us/sample - loss: 0.6795 - val_loss: 0.3972\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.709 - 0s 91us/sample - loss: 0.6544 - val_loss: 0.3683\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.408 - 0s 93us/sample - loss: 0.5765 - val_loss: 0.3422\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.618 - 0s 92us/sample - loss: 0.5144 - val_loss: 0.3189\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.403 - 0s 83us/sample - loss: 0.5220 - val_loss: 0.2967\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.688 - 0s 90us/sample - loss: 0.5328 - val_loss: 0.2750\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.282 - 0s 88us/sample - loss: 0.4952 - val_loss: 0.2551\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.352 - 0s 93us/sample - loss: 0.4577 - val_loss: 0.2366\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.344 - 0s 90us/sample - loss: 0.4306 - val_loss: 0.2194\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.556 - 0s 99us/sample - loss: 0.4088 - val_loss: 0.2036\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.710 - 0s 88us/sample - loss: 0.3945 - val_loss: 0.1895\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.407 - 0s 84us/sample - loss: 0.3628 - val_loss: 0.1766\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.529 - 0s 83us/sample - loss: 0.3547 - val_loss: 0.1639\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.217 - 0s 84us/sample - loss: 0.3300 - val_loss: 0.1524\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.273 - 0s 95us/sample - loss: 0.2820 - val_loss: 0.1425\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.411 - 0s 96us/sample - loss: 0.2903 - val_loss: 0.1331\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.234 - 0s 107us/sample - loss: 0.2813 - val_loss: 0.1247\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.248 - 0s 92us/sample - loss: 0.2876 - val_loss: 0.1158\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.197 - 0s 93us/sample - loss: 0.2614 - val_loss: 0.1077\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.320 - 0s 91us/sample - loss: 0.2430 - val_loss: 0.1007\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.249 - 0s 93us/sample - loss: 0.2406 - val_loss: 0.0941\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.362 - 0s 98us/sample - loss: 0.2396 - val_loss: 0.0877\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.310 - 0s 90us/sample - loss: 0.2105 - val_loss: 0.0822\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.198 - 0s 99us/sample - loss: 0.2124 - val_loss: 0.0774\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.187 - 0s 98us/sample - loss: 0.2035 - val_loss: 0.0726\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.149 - 0s 102us/sample - loss: 0.1765 - val_loss: 0.0687\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 105us/sample - loss: 0.1740 - val_loss: 0.0650\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.246 - 0s 105us/sample - loss: 0.1830 - val_loss: 0.0616\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.199 - 0s 108us/sample - loss: 0.1686 - val_loss: 0.0584\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.112 - 0s 103us/sample - loss: 0.1572 - val_loss: 0.0556\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.143 - 0s 144us/sample - loss: 0.1458 - val_loss: 0.0529\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 125us/sample - loss: 0.1465 - val_loss: 0.0505\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.154 - 0s 124us/sample - loss: 0.1435 - val_loss: 0.0484\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.162 - 0s 117us/sample - loss: 0.1373 - val_loss: 0.0465\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.191 - 0s 117us/sample - loss: 0.1516 - val_loss: 0.0448\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 117us/sample - loss: 0.1325 - val_loss: 0.0431\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 103us/sample - loss: 0.1444 - val_loss: 0.0415\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 105us/sample - loss: 0.1341 - val_loss: 0.0400\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 90us/sample - loss: 0.1065 - val_loss: 0.0389\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 100us/sample - loss: 0.1171 - val_loss: 0.0379\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 93us/sample - loss: 0.1155 - val_loss: 0.0370\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.167 - 0s 90us/sample - loss: 0.1133 - val_loss: 0.0362\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.114 - 0s 88us/sample - loss: 0.1132 - val_loss: 0.0354\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 93us/sample - loss: 0.1090 - val_loss: 0.0347\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 99us/sample - loss: 0.1020 - val_loss: 0.0342\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 99us/sample - loss: 0.0999 - val_loss: 0.0337\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 93us/sample - loss: 0.1046 - val_loss: 0.0332\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 93us/sample - loss: 0.1004 - val_loss: 0.0329\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 103us/sample - loss: 0.0978 - val_loss: 0.0326\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 98us/sample - loss: 0.0917 - val_loss: 0.0323\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 102us/sample - loss: 0.0900 - val_loss: 0.0321\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 93us/sample - loss: 0.0940 - val_loss: 0.0320\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.153 - 0s 97us/sample - loss: 0.0974 - val_loss: 0.0318\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 99us/sample - loss: 0.0879 - val_loss: 0.0317\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 98us/sample - loss: 0.0879 - val_loss: 0.0317\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 100us/sample - loss: 0.0899 - val_loss: 0.0316\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 98us/sample - loss: 0.0918 - val_loss: 0.0316\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 115us/sample - loss: 0.0800 - val_loss: 0.0315\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 95us/sample - loss: 0.0798 - val_loss: 0.0315\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 120us/sample - loss: 0.0843 - val_loss: 0.0314\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.123 - 0s 122us/sample - loss: 0.0825 - val_loss: 0.0314\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 110us/sample - loss: 0.0811 - val_loss: 0.0314\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 89us/sample - loss: 0.0871 - val_loss: 0.0314\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 88us/sample - loss: 0.0783 - val_loss: 0.0314\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 92us/sample - loss: 0.0776 - val_loss: 0.0314\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 95us/sample - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 117us/sample - loss: 0.0694 - val_loss: 0.0314\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 100us/sample - loss: 0.0754 - val_loss: 0.0314\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 89us/sample - loss: 0.0714 - val_loss: 0.0314\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 97us/sample - loss: 0.0732 - val_loss: 0.0314\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 83us/sample - loss: 0.0734 - val_loss: 0.0314\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 103us/sample - loss: 0.0740 - val_loss: 0.0315\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 90us/sample - loss: 0.0704 - val_loss: 0.0315\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 86us/sample - loss: 0.0760 - val_loss: 0.0314\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 94us/sample - loss: 0.0686 - val_loss: 0.0314\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 99us/sample - loss: 0.0702 - val_loss: 0.0314\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 98us/sample - loss: 0.0748 - val_loss: 0.0313\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 83us/sample - loss: 0.0681 - val_loss: 0.0312\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 78us/sample - loss: 0.0623 - val_loss: 0.0311\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 90us/sample - loss: 0.0679 - val_loss: 0.0311\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 87us/sample - loss: 0.0657 - val_loss: 0.0309\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 94us/sample - loss: 0.0638 - val_loss: 0.0307\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 86us/sample - loss: 0.0675 - val_loss: 0.0306\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 95us/sample - loss: 0.0641 - val_loss: 0.0305\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 94us/sample - loss: 0.0706 - val_loss: 0.0303\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.080 - 0s 88us/sample - loss: 0.0616 - val_loss: 0.0302\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 86us/sample - loss: 0.0621 - val_loss: 0.0299\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 88us/sample - loss: 0.0605 - val_loss: 0.0296\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 87us/sample - loss: 0.0588 - val_loss: 0.0294\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 86us/sample - loss: 0.0650 - val_loss: 0.0292\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 87us/sample - loss: 0.0625 - val_loss: 0.0289\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 87us/sample - loss: 0.0601 - val_loss: 0.0287\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0627 - val_loss: 0.0285\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 91us/sample - loss: 0.0599 - val_loss: 0.0282\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 84us/sample - loss: 0.0631 - val_loss: 0.0280\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 95us/sample - loss: 0.0618 - val_loss: 0.0277\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 98us/sample - loss: 0.0625 - val_loss: 0.0275\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 88us/sample - loss: 0.0586 - val_loss: 0.0272\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0566 - val_loss: 0.0267\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 77us/sample - loss: 0.0534 - val_loss: 0.0263\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 86us/sample - loss: 0.0563 - val_loss: 0.0258\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 92us/sample - loss: 0.0534 - val_loss: 0.0255\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 84us/sample - loss: 0.0588 - val_loss: 0.0253\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 97us/sample - loss: 0.0546 - val_loss: 0.0250\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 95us/sample - loss: 0.0588 - val_loss: 0.0247\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 91us/sample - loss: 0.0525 - val_loss: 0.0244\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 103us/sample - loss: 0.0521 - val_loss: 0.0241\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 88us/sample - loss: 0.0536 - val_loss: 0.0238\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 93us/sample - loss: 0.0540 - val_loss: 0.0235\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 91us/sample - loss: 0.0522 - val_loss: 0.0233\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 94us/sample - loss: 0.0493 - val_loss: 0.0231\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 94us/sample - loss: 0.0493 - val_loss: 0.0228\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 95us/sample - loss: 0.0527 - val_loss: 0.0226\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0481 - val_loss: 0.0224\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 95us/sample - loss: 0.0471 - val_loss: 0.0221\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 88us/sample - loss: 0.0467 - val_loss: 0.0219\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 90us/sample - loss: 0.0464 - val_loss: 0.0218\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0443 - val_loss: 0.0216\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 89us/sample - loss: 0.0451 - val_loss: 0.0213\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 99us/sample - loss: 0.0419 - val_loss: 0.0211\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 98us/sample - loss: 0.0450 - val_loss: 0.0209\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 87us/sample - loss: 0.0448 - val_loss: 0.0208\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 85us/sample - loss: 0.0409 - val_loss: 0.0207\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 85us/sample - loss: 0.0401 - val_loss: 0.0205\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0412 - val_loss: 0.0203\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 86us/sample - loss: 0.0426 - val_loss: 0.0202\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0442 - val_loss: 0.0201\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 86us/sample - loss: 0.0434 - val_loss: 0.0200\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0438 - val_loss: 0.0199\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 103us/sample - loss: 0.0437 - val_loss: 0.0197\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 98us/sample - loss: 0.0428 - val_loss: 0.0195\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 83us/sample - loss: 0.0394 - val_loss: 0.0194\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 103us/sample - loss: 0.0405 - val_loss: 0.0192\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 102us/sample - loss: 0.0392 - val_loss: 0.0191\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0395 - val_loss: 0.0190\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 113us/sample - loss: 0.0383 - val_loss: 0.0188\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 81us/sample - loss: 0.0363 - val_loss: 0.0186\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 83us/sample - loss: 0.0346 - val_loss: 0.0185\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 90us/sample - loss: 0.0386 - val_loss: 0.0184\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 84us/sample - loss: 0.0363 - val_loss: 0.0183\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 94us/sample - loss: 0.0376 - val_loss: 0.0182\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 83us/sample - loss: 0.0364 - val_loss: 0.0180\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 87us/sample - loss: 0.0380 - val_loss: 0.0179\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 88us/sample - loss: 0.0356 - val_loss: 0.0178\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0309 - val_loss: 0.0176\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 112us/sample - loss: 0.0352 - val_loss: 0.0175\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 93us/sample - loss: 0.0355 - val_loss: 0.0173\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 101us/sample - loss: 0.0290 - val_loss: 0.0172\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 96us/sample - loss: 0.0325 - val_loss: 0.0171\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 90us/sample - loss: 0.0354 - val_loss: 0.0171\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 101us/sample - loss: 0.0368 - val_loss: 0.0171\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0346 - val_loss: 0.0170\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 107us/sample - loss: 0.0357 - val_loss: 0.0170\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0333 - val_loss: 0.0168\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 103us/sample - loss: 0.0339 - val_loss: 0.0167\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 105us/sample - loss: 0.0326 - val_loss: 0.0167\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 110us/sample - loss: 0.0323 - val_loss: 0.0165\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 102us/sample - loss: 0.0326 - val_loss: 0.0164\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 92us/sample - loss: 0.0321 - val_loss: 0.0163\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 86us/sample - loss: 0.0326 - val_loss: 0.0162\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 89us/sample - loss: 0.0300 - val_loss: 0.0161\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0319 - val_loss: 0.0160\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 98us/sample - loss: 0.0302 - val_loss: 0.0159\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0320 - val_loss: 0.0158\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0325 - val_loss: 0.0158\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0289 - val_loss: 0.0156\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 78us/sample - loss: 0.0312 - val_loss: 0.0155\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 82us/sample - loss: 0.0308 - val_loss: 0.0154\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 83us/sample - loss: 0.0296 - val_loss: 0.0152\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 85us/sample - loss: 0.0309 - val_loss: 0.0151\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 81us/sample - loss: 0.0310 - val_loss: 0.0151\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0316 - val_loss: 0.0150\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 114us/sample - loss: 0.0272 - val_loss: 0.0149\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 95us/sample - loss: 0.0300 - val_loss: 0.0149\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 85us/sample - loss: 0.0284 - val_loss: 0.0147\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0291 - val_loss: 0.0146\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0309 - val_loss: 0.0146\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 94us/sample - loss: 0.0260 - val_loss: 0.0145\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 89us/sample - loss: 0.0293 - val_loss: 0.0145\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 89us/sample - loss: 0.0266 - val_loss: 0.0143\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0285 - val_loss: 0.0143\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 89us/sample - loss: 0.0297 - val_loss: 0.0141\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 82us/sample - loss: 0.0271 - val_loss: 0.0139\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 91us/sample - loss: 0.0254 - val_loss: 0.0138\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0262 - val_loss: 0.0137\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0252 - val_loss: 0.0134\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0133\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 104us/sample - loss: 0.0246 - val_loss: 0.0132\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 94us/sample - loss: 0.0260 - val_loss: 0.0132\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0259 - val_loss: 0.0131\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 94us/sample - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 99us/sample - loss: 0.0254 - val_loss: 0.0129\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 100us/sample - loss: 0.0246 - val_loss: 0.0128\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 87us/sample - loss: 0.0228 - val_loss: 0.0127\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 98us/sample - loss: 0.0240 - val_loss: 0.0127\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0240 - val_loss: 0.0126\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0230 - val_loss: 0.0125\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 89us/sample - loss: 0.0229 - val_loss: 0.0123\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 98us/sample - loss: 0.0240 - val_loss: 0.0123\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 99us/sample - loss: 0.0248 - val_loss: 0.0122\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 110us/sample - loss: 0.0234 - val_loss: 0.0122\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0211 - val_loss: 0.0121\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 86us/sample - loss: 0.0223 - val_loss: 0.0120\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 119us/sample - loss: 0.0244 - val_loss: 0.0119\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0220 - val_loss: 0.0119\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0224 - val_loss: 0.0118\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 84us/sample - loss: 0.0222 - val_loss: 0.0117\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 78us/sample - loss: 0.0219 - val_loss: 0.0117\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0227 - val_loss: 0.0116\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0215 - val_loss: 0.0115\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0115\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 81us/sample - loss: 0.0218 - val_loss: 0.0113\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0212 - val_loss: 0.0113\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 78us/sample - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 91us/sample - loss: 0.0201 - val_loss: 0.0112\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0229 - val_loss: 0.0111\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0208 - val_loss: 0.0110\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 81us/sample - loss: 0.0209 - val_loss: 0.0110\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0109\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0180 - val_loss: 0.0109\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0202 - val_loss: 0.0108\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0189 - val_loss: 0.0108\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 84us/sample - loss: 0.0193 - val_loss: 0.0108\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0186 - val_loss: 0.0107\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 80us/sample - loss: 0.0205 - val_loss: 0.0107\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 82us/sample - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0178 - val_loss: 0.0106\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 82us/sample - loss: 0.0200 - val_loss: 0.0105\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0185 - val_loss: 0.0105\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0187 - val_loss: 0.0104\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0179 - val_loss: 0.0104\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0176 - val_loss: 0.0103\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 83us/sample - loss: 0.0183 - val_loss: 0.0103\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0181 - val_loss: 0.0102\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0173 - val_loss: 0.0102\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 125us/sample - loss: 0.0179 - val_loss: 0.0102\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0187 - val_loss: 0.0101\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 98us/sample - loss: 0.0182 - val_loss: 0.0100\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0172 - val_loss: 0.0099\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 96us/sample - loss: 0.0185 - val_loss: 0.0099\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0171 - val_loss: 0.0099\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 104us/sample - loss: 0.0162 - val_loss: 0.0098\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0170 - val_loss: 0.0098\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0176 - val_loss: 0.0097\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0173 - val_loss: 0.0097\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0176 - val_loss: 0.0097\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 102us/sample - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0170 - val_loss: 0.0096\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0155 - val_loss: 0.0096\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 89us/sample - loss: 0.0171 - val_loss: 0.0095\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0094\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0164 - val_loss: 0.0094\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0159 - val_loss: 0.0093\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0165 - val_loss: 0.0092\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 81us/sample - loss: 0.0150 - val_loss: 0.0091\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0163 - val_loss: 0.0091\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0145 - val_loss: 0.0091\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 106us/sample - loss: 0.0163 - val_loss: 0.0090\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0146 - val_loss: 0.0089\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 92us/sample - loss: 0.0140 - val_loss: 0.0088\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 110us/sample - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 118us/sample - loss: 0.0148 - val_loss: 0.0087\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 120us/sample - loss: 0.0149 - val_loss: 0.0087\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0139 - val_loss: 0.0086\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0139 - val_loss: 0.0086\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0144 - val_loss: 0.0086\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0141 - val_loss: 0.0086\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0131 - val_loss: 0.0085\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 102us/sample - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 87us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0109 - val_loss: 0.0083\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.319 - 0s 652us/sample - loss: 0.2398 - val_loss: 0.2198\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.178 - 0s 90us/sample - loss: 0.2230 - val_loss: 0.2001\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.250 - 0s 95us/sample - loss: 0.2048 - val_loss: 0.1844\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.149 - 0s 104us/sample - loss: 0.2091 - val_loss: 0.1718\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.301 - 0s 93us/sample - loss: 0.2083 - val_loss: 0.1618\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.204 - 0s 100us/sample - loss: 0.1904 - val_loss: 0.1531\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.127 - 0s 101us/sample - loss: 0.1828 - val_loss: 0.1441\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 105us/sample - loss: 0.1761 - val_loss: 0.1382\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.208 - 0s 93us/sample - loss: 0.1583 - val_loss: 0.1312\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.142 - 0s 95us/sample - loss: 0.1606 - val_loss: 0.1238\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 104us/sample - loss: 0.1568 - val_loss: 0.1208\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.186 - 0s 92us/sample - loss: 0.1682 - val_loss: 0.1163\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.181 - 0s 119us/sample - loss: 0.1395 - val_loss: 0.1128\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 100us/sample - loss: 0.1489 - val_loss: 0.1104\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.168 - 0s 91us/sample - loss: 0.1417 - val_loss: 0.1069\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 99us/sample - loss: 0.1381 - val_loss: 0.1038\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 88us/sample - loss: 0.1297 - val_loss: 0.1012\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 93us/sample - loss: 0.1355 - val_loss: 0.0994\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 93us/sample - loss: 0.1309 - val_loss: 0.0986\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 105us/sample - loss: 0.1193 - val_loss: 0.0959\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.142 - 0s 92us/sample - loss: 0.1277 - val_loss: 0.0941\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 95us/sample - loss: 0.1183 - val_loss: 0.0937\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 92us/sample - loss: 0.1134 - val_loss: 0.0941\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 92us/sample - loss: 0.1056 - val_loss: 0.0934\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 81us/sample - loss: 0.1138 - val_loss: 0.0911\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.104 - 0s 88us/sample - loss: 0.1220 - val_loss: 0.0906\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 109us/sample - loss: 0.1035 - val_loss: 0.0891\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 106us/sample - loss: 0.1071 - val_loss: 0.0873\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.148 - 0s 98us/sample - loss: 0.0939 - val_loss: 0.0876\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 78us/sample - loss: 0.0914 - val_loss: 0.0864\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 86us/sample - loss: 0.0959 - val_loss: 0.0858\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 83us/sample - loss: 0.0958 - val_loss: 0.0846\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 81us/sample - loss: 0.0862 - val_loss: 0.0825\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 79us/sample - loss: 0.0940 - val_loss: 0.0805\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 83us/sample - loss: 0.0841 - val_loss: 0.0794\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 91us/sample - loss: 0.0811 - val_loss: 0.0780\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 83us/sample - loss: 0.0855 - val_loss: 0.0767\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 86us/sample - loss: 0.0838 - val_loss: 0.0769\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 98us/sample - loss: 0.0759 - val_loss: 0.0754\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 88us/sample - loss: 0.0725 - val_loss: 0.0736\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 93us/sample - loss: 0.0757 - val_loss: 0.0727\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 88us/sample - loss: 0.0696 - val_loss: 0.0731\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 91us/sample - loss: 0.0650 - val_loss: 0.0722\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 91us/sample - loss: 0.0721 - val_loss: 0.0703\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 88us/sample - loss: 0.0680 - val_loss: 0.0689\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0652 - val_loss: 0.0679\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 95us/sample - loss: 0.0678 - val_loss: 0.0675\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 104us/sample - loss: 0.0646 - val_loss: 0.0675\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 98us/sample - loss: 0.0609 - val_loss: 0.0666\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 131us/sample - loss: 0.0544 - val_loss: 0.0657\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0550 - val_loss: 0.0644\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 99us/sample - loss: 0.0571 - val_loss: 0.0629\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 105us/sample - loss: 0.0533 - val_loss: 0.0618\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 95us/sample - loss: 0.0541 - val_loss: 0.0612\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 101us/sample - loss: 0.0529 - val_loss: 0.0608\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 103us/sample - loss: 0.0511 - val_loss: 0.0599\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 90us/sample - loss: 0.0507 - val_loss: 0.0590\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 95us/sample - loss: 0.0501 - val_loss: 0.0587\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0471 - val_loss: 0.0583\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 99us/sample - loss: 0.0410 - val_loss: 0.0576\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 93us/sample - loss: 0.0483 - val_loss: 0.0568\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 98us/sample - loss: 0.0487 - val_loss: 0.0562\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 106us/sample - loss: 0.0423 - val_loss: 0.0553\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0400 - val_loss: 0.0547\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 90us/sample - loss: 0.0413 - val_loss: 0.0540\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 102us/sample - loss: 0.0383 - val_loss: 0.0535\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0409 - val_loss: 0.0526\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0406 - val_loss: 0.0520\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 75us/sample - loss: 0.0417 - val_loss: 0.0508\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 82us/sample - loss: 0.0354 - val_loss: 0.0496\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 86us/sample - loss: 0.0379 - val_loss: 0.0481\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 99us/sample - loss: 0.0368 - val_loss: 0.0471\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 105us/sample - loss: 0.0332 - val_loss: 0.0463\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 93us/sample - loss: 0.0327 - val_loss: 0.0456\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0327 - val_loss: 0.0447\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 122us/sample - loss: 0.0319 - val_loss: 0.0439\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 105us/sample - loss: 0.0308 - val_loss: 0.0437\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 115us/sample - loss: 0.0348 - val_loss: 0.0431\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 105us/sample - loss: 0.0301 - val_loss: 0.0422\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 107us/sample - loss: 0.0308 - val_loss: 0.0415\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0286 - val_loss: 0.0409\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0287 - val_loss: 0.0398\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0294 - val_loss: 0.0394\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 128us/sample - loss: 0.0248 - val_loss: 0.0384\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 122us/sample - loss: 0.0276 - val_loss: 0.0378\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0273 - val_loss: 0.0375\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 89us/sample - loss: 0.0275 - val_loss: 0.0372\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0261 - val_loss: 0.0367\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 97us/sample - loss: 0.0264 - val_loss: 0.0361\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 124us/sample - loss: 0.0224 - val_loss: 0.0355\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 123us/sample - loss: 0.0233 - val_loss: 0.0347\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 125us/sample - loss: 0.0238 - val_loss: 0.0342\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0210 - val_loss: 0.0337\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 115us/sample - loss: 0.0240 - val_loss: 0.0330\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 111us/sample - loss: 0.0236 - val_loss: 0.0321\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 130us/sample - loss: 0.0212 - val_loss: 0.0317\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 122us/sample - loss: 0.0235 - val_loss: 0.0309\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 109us/sample - loss: 0.0215 - val_loss: 0.0303\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 117us/sample - loss: 0.0218 - val_loss: 0.0297\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 99us/sample - loss: 0.0195 - val_loss: 0.0293\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0222 - val_loss: 0.0288\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0212 - val_loss: 0.0281\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 107us/sample - loss: 0.0199 - val_loss: 0.0278\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0206 - val_loss: 0.0274\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 103us/sample - loss: 0.0204 - val_loss: 0.0269\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 110us/sample - loss: 0.0204 - val_loss: 0.0265\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0195 - val_loss: 0.0263\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0206 - val_loss: 0.0261\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0182 - val_loss: 0.0258\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0254\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0165 - val_loss: 0.0250\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 91us/sample - loss: 0.0177 - val_loss: 0.0246\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 92us/sample - loss: 0.0173 - val_loss: 0.0243\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 116us/sample - loss: 0.0188 - val_loss: 0.0241\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0236\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0172 - val_loss: 0.0232\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0179 - val_loss: 0.0229\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0162 - val_loss: 0.0226\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 94us/sample - loss: 0.0161 - val_loss: 0.0222\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0171 - val_loss: 0.0219\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0172 - val_loss: 0.0217\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0152 - val_loss: 0.0215\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 78us/sample - loss: 0.0167 - val_loss: 0.0210\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0152 - val_loss: 0.0210\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 82us/sample - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 82us/sample - loss: 0.0154 - val_loss: 0.0206\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0135 - val_loss: 0.0203\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0145 - val_loss: 0.0200\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0151 - val_loss: 0.0199\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0150 - val_loss: 0.0198\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0147 - val_loss: 0.0196\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0152 - val_loss: 0.0194\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0138 - val_loss: 0.0191\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0140 - val_loss: 0.0187\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0146 - val_loss: 0.0184\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0142 - val_loss: 0.0183\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0132 - val_loss: 0.0178\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0151 - val_loss: 0.0175\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0143 - val_loss: 0.0174\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0131 - val_loss: 0.0169\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0129 - val_loss: 0.0167\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0139 - val_loss: 0.0164\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 109us/sample - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 137us/sample - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0117 - val_loss: 0.0154\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0115 - val_loss: 0.0146\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 80us/sample - loss: 0.0108 - val_loss: 0.0137\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 83us/sample - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 94us/sample - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 122us/sample - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 119us/sample - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 108us/sample - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 115us/sample - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0086 - val_loss: 0.0105\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 101us/sample - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 94us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0088 - val_loss: 0.0102\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 127us/sample - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 125us/sample - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 121us/sample - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 122us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 118us/sample - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 120us/sample - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 122us/sample - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0070 - val_loss: 0.0097\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 94us/sample - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0077 - val_loss: 0.0096\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 132us/sample - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 142us/sample - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 125us/sample - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0071 - val_loss: 0.0095\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0071 - val_loss: 0.0095\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 115us/sample - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 139us/sample - loss: 0.0070 - val_loss: 0.0094\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 134us/sample - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 134us/sample - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 111us/sample - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/sample - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 120us/sample - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 128us/sample - loss: 0.0065 - val_loss: 0.0093\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 87us/sample - loss: 0.0062 - val_loss: 0.0093\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0093\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 128us/sample - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/sample - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 111us/sample - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0091\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 2s - loss: 0.295 - 0s 836us/sample - loss: 0.2849 - val_loss: 0.2087\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.241 - 0s 101us/sample - loss: 0.2642 - val_loss: 0.1910\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.175 - 0s 90us/sample - loss: 0.2445 - val_loss: 0.1743\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.317 - 0s 94us/sample - loss: 0.2410 - val_loss: 0.1593\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.263 - 0s 95us/sample - loss: 0.2212 - val_loss: 0.1451\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.213 - 0s 95us/sample - loss: 0.2149 - val_loss: 0.1321\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.248 - 0s 114us/sample - loss: 0.2065 - val_loss: 0.1203\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.170 - 0s 122us/sample - loss: 0.1914 - val_loss: 0.1100\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 122us/sample - loss: 0.1779 - val_loss: 0.1008\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.167 - 0s 100us/sample - loss: 0.1650 - val_loss: 0.0925\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.152 - 0s 110us/sample - loss: 0.1541 - val_loss: 0.0851\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.243 - 0s 130us/sample - loss: 0.1515 - val_loss: 0.0782\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 120us/sample - loss: 0.1383 - val_loss: 0.0722\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 107us/sample - loss: 0.1378 - val_loss: 0.0666\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 111us/sample - loss: 0.1318 - val_loss: 0.0619\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.174 - 0s 112us/sample - loss: 0.1204 - val_loss: 0.0572\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 108us/sample - loss: 0.1175 - val_loss: 0.0533\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 113us/sample - loss: 0.1113 - val_loss: 0.0497\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 115us/sample - loss: 0.1107 - val_loss: 0.0465\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.078 - 0s 116us/sample - loss: 0.0998 - val_loss: 0.0436\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.136 - 0s 115us/sample - loss: 0.0964 - val_loss: 0.0411\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.117 - 0s 125us/sample - loss: 0.0944 - val_loss: 0.0388\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.087 - 0s 122us/sample - loss: 0.0937 - val_loss: 0.0365\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 130us/sample - loss: 0.0832 - val_loss: 0.0347\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 125us/sample - loss: 0.0870 - val_loss: 0.0331\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 108us/sample - loss: 0.0776 - val_loss: 0.0314\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 115us/sample - loss: 0.0837 - val_loss: 0.0301\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 114us/sample - loss: 0.0767 - val_loss: 0.0289\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 125us/sample - loss: 0.0747 - val_loss: 0.0278\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 117us/sample - loss: 0.0735 - val_loss: 0.0268\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 109us/sample - loss: 0.0745 - val_loss: 0.0258\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 88us/sample - loss: 0.0678 - val_loss: 0.0249\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 88us/sample - loss: 0.0683 - val_loss: 0.0241\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 105us/sample - loss: 0.0701 - val_loss: 0.0234\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 105us/sample - loss: 0.0673 - val_loss: 0.0227\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0601 - val_loss: 0.0221\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 94us/sample - loss: 0.0688 - val_loss: 0.0217\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 95us/sample - loss: 0.0601 - val_loss: 0.0212\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 94us/sample - loss: 0.0677 - val_loss: 0.0208\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 96us/sample - loss: 0.0619 - val_loss: 0.0205\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 95us/sample - loss: 0.0589 - val_loss: 0.0203\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 93us/sample - loss: 0.0547 - val_loss: 0.0201\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.073 - 0s 103us/sample - loss: 0.0603 - val_loss: 0.0198\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 100us/sample - loss: 0.0569 - val_loss: 0.0196\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 99us/sample - loss: 0.0522 - val_loss: 0.0195\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 100us/sample - loss: 0.0534 - val_loss: 0.0193\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 90us/sample - loss: 0.0526 - val_loss: 0.0192\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 95us/sample - loss: 0.0515 - val_loss: 0.0191\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 97us/sample - loss: 0.0517 - val_loss: 0.0190\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 98us/sample - loss: 0.0500 - val_loss: 0.0189\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 99us/sample - loss: 0.0479 - val_loss: 0.0188\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 117us/sample - loss: 0.0530 - val_loss: 0.0187\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 108us/sample - loss: 0.0494 - val_loss: 0.0186\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 116us/sample - loss: 0.0487 - val_loss: 0.0186\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 110us/sample - loss: 0.0461 - val_loss: 0.0185\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0488 - val_loss: 0.0185\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 109us/sample - loss: 0.0531 - val_loss: 0.0184\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 108us/sample - loss: 0.0491 - val_loss: 0.0184\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 112us/sample - loss: 0.0527 - val_loss: 0.0183\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 110us/sample - loss: 0.0501 - val_loss: 0.0183\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 146us/sample - loss: 0.0456 - val_loss: 0.0182\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 117us/sample - loss: 0.0452 - val_loss: 0.0182\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 112us/sample - loss: 0.0437 - val_loss: 0.0181\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 115us/sample - loss: 0.0455 - val_loss: 0.0181\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 110us/sample - loss: 0.0431 - val_loss: 0.0181\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 125us/sample - loss: 0.0444 - val_loss: 0.0180\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 110us/sample - loss: 0.0473 - val_loss: 0.0180\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 110us/sample - loss: 0.0423 - val_loss: 0.0180\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 117us/sample - loss: 0.0390 - val_loss: 0.0179\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 119us/sample - loss: 0.0453 - val_loss: 0.0178\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 95us/sample - loss: 0.0418 - val_loss: 0.0178\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0424 - val_loss: 0.0177\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 98us/sample - loss: 0.0449 - val_loss: 0.0177\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 96us/sample - loss: 0.0407 - val_loss: 0.0176\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 92us/sample - loss: 0.0394 - val_loss: 0.0176\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 109us/sample - loss: 0.0420 - val_loss: 0.0175\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 113us/sample - loss: 0.0393 - val_loss: 0.0174\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 115us/sample - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 120us/sample - loss: 0.0424 - val_loss: 0.0173\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 125us/sample - loss: 0.0387 - val_loss: 0.0172\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 126us/sample - loss: 0.0367 - val_loss: 0.0171\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 127us/sample - loss: 0.0384 - val_loss: 0.0170\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 125us/sample - loss: 0.0358 - val_loss: 0.0170\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 120us/sample - loss: 0.0365 - val_loss: 0.0169\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 117us/sample - loss: 0.0346 - val_loss: 0.0168\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 116us/sample - loss: 0.0356 - val_loss: 0.0167\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 120us/sample - loss: 0.0368 - val_loss: 0.0167\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 115us/sample - loss: 0.0326 - val_loss: 0.0166\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 108us/sample - loss: 0.0338 - val_loss: 0.0165\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 138us/sample - loss: 0.0344 - val_loss: 0.0165\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 138us/sample - loss: 0.0358 - val_loss: 0.0164\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 144us/sample - loss: 0.0316 - val_loss: 0.0163\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 130us/sample - loss: 0.0325 - val_loss: 0.0162\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 139us/sample - loss: 0.0342 - val_loss: 0.0161\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 137us/sample - loss: 0.0330 - val_loss: 0.0160\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 127us/sample - loss: 0.0321 - val_loss: 0.0160\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 137us/sample - loss: 0.0316 - val_loss: 0.0160\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 134us/sample - loss: 0.0311 - val_loss: 0.0159\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 134us/sample - loss: 0.0311 - val_loss: 0.0159\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 139us/sample - loss: 0.0288 - val_loss: 0.0158\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 128us/sample - loss: 0.0316 - val_loss: 0.0157\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 127us/sample - loss: 0.0289 - val_loss: 0.0157\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 134us/sample - loss: 0.0294 - val_loss: 0.0155\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 127us/sample - loss: 0.0298 - val_loss: 0.0155\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 127us/sample - loss: 0.0270 - val_loss: 0.0154\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 134us/sample - loss: 0.0288 - val_loss: 0.0153\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 115us/sample - loss: 0.0273 - val_loss: 0.0152\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 80us/sample - loss: 0.0254 - val_loss: 0.0152\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 95us/sample - loss: 0.0260 - val_loss: 0.0151\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0250 - val_loss: 0.0151\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 86us/sample - loss: 0.0271 - val_loss: 0.0150\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 101us/sample - loss: 0.0252 - val_loss: 0.0149\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0257 - val_loss: 0.0149\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0258 - val_loss: 0.0148\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0261 - val_loss: 0.0147\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0261 - val_loss: 0.0147\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0253 - val_loss: 0.0146\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 80us/sample - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 89us/sample - loss: 0.0247 - val_loss: 0.0146\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 90us/sample - loss: 0.0266 - val_loss: 0.0145\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 87us/sample - loss: 0.0241 - val_loss: 0.0145\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0234 - val_loss: 0.0143\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 86us/sample - loss: 0.0235 - val_loss: 0.0143\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 87us/sample - loss: 0.0235 - val_loss: 0.0142\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0215 - val_loss: 0.0142\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0225 - val_loss: 0.0141\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0225 - val_loss: 0.0141\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0230 - val_loss: 0.0141\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0140\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 109us/sample - loss: 0.0225 - val_loss: 0.0140\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 123us/sample - loss: 0.0209 - val_loss: 0.0139\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 92us/sample - loss: 0.0222 - val_loss: 0.0139\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0223 - val_loss: 0.0138\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0221 - val_loss: 0.0138\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 95us/sample - loss: 0.0216 - val_loss: 0.0137\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0191 - val_loss: 0.0136\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0204 - val_loss: 0.0135\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 111us/sample - loss: 0.0187 - val_loss: 0.0135\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0183 - val_loss: 0.0134\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0200 - val_loss: 0.0134\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 97us/sample - loss: 0.0199 - val_loss: 0.0133\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 102us/sample - loss: 0.0205 - val_loss: 0.0132\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 99us/sample - loss: 0.0201 - val_loss: 0.0132\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 104us/sample - loss: 0.0192 - val_loss: 0.0132\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0197 - val_loss: 0.0131\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0200 - val_loss: 0.0130\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0186 - val_loss: 0.0130\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0185 - val_loss: 0.0129\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 78us/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0179 - val_loss: 0.0128\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 104us/sample - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 94us/sample - loss: 0.0169 - val_loss: 0.0126\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0179 - val_loss: 0.0126\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0180 - val_loss: 0.0124\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0183 - val_loss: 0.0124\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 98us/sample - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0122\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 97us/sample - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 106us/sample - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0134 - val_loss: 0.0115\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 109us/sample - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0154 - val_loss: 0.0114\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0142 - val_loss: 0.0113\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0129 - val_loss: 0.0112\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0129 - val_loss: 0.0110\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 76us/sample - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 81us/sample - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 81us/sample - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 79us/sample - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0104\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 113us/sample - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 78us/sample - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 76us/sample - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0125 - val_loss: 0.0100\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 101us/sample - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0117 - val_loss: 0.0095\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 101us/sample - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 112us/sample - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 76us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 117us/sample - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 112us/sample - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 115us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 109us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 114us/sample - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 104us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 118us/sample - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/sample - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 123us/sample - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 109us/sample - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/sample - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/sample - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 96us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 79us/sample - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 126us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 79us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.137 - 0s 760us/sample - loss: 0.1309 - val_loss: 0.1053\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 90us/sample - loss: 0.1253 - val_loss: 0.1025\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 81us/sample - loss: 0.1223 - val_loss: 0.0999\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 86us/sample - loss: 0.1187 - val_loss: 0.0973\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.126 - 0s 91us/sample - loss: 0.1156 - val_loss: 0.0948\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 86us/sample - loss: 0.1121 - val_loss: 0.0923\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 123us/sample - loss: 0.1083 - val_loss: 0.0900\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 86us/sample - loss: 0.1064 - val_loss: 0.0877\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.128 - 0s 86us/sample - loss: 0.1014 - val_loss: 0.0855\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.097 - 0s 86us/sample - loss: 0.0992 - val_loss: 0.0833\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 86us/sample - loss: 0.0961 - val_loss: 0.0812\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 108us/sample - loss: 0.0929 - val_loss: 0.0792\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 105us/sample - loss: 0.0928 - val_loss: 0.0771\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 105us/sample - loss: 0.0879 - val_loss: 0.0751\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.068 - 0s 118us/sample - loss: 0.0846 - val_loss: 0.0731\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 99us/sample - loss: 0.0825 - val_loss: 0.0711\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.081 - 0s 122us/sample - loss: 0.0795 - val_loss: 0.0692\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 110us/sample - loss: 0.0765 - val_loss: 0.0674\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 107us/sample - loss: 0.0746 - val_loss: 0.0656\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 100us/sample - loss: 0.0715 - val_loss: 0.0638\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.069 - 0s 100us/sample - loss: 0.0694 - val_loss: 0.0620\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 99us/sample - loss: 0.0675 - val_loss: 0.0602\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 110us/sample - loss: 0.0647 - val_loss: 0.0584\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 97us/sample - loss: 0.0631 - val_loss: 0.0568\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 100us/sample - loss: 0.0599 - val_loss: 0.0550\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 95us/sample - loss: 0.0576 - val_loss: 0.0534\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 99us/sample - loss: 0.0564 - val_loss: 0.0518\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 112us/sample - loss: 0.0534 - val_loss: 0.0501\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0524 - val_loss: 0.0486\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 112us/sample - loss: 0.0516 - val_loss: 0.0471\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 112us/sample - loss: 0.0497 - val_loss: 0.0456\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 101us/sample - loss: 0.0475 - val_loss: 0.0442\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 80us/sample - loss: 0.0450 - val_loss: 0.0428\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 86us/sample - loss: 0.0432 - val_loss: 0.0414\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 86us/sample - loss: 0.0421 - val_loss: 0.0401\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0416 - val_loss: 0.0388\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0387 - val_loss: 0.0376\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 86us/sample - loss: 0.0371 - val_loss: 0.0363\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 93us/sample - loss: 0.0379 - val_loss: 0.0352\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 97us/sample - loss: 0.0363 - val_loss: 0.0341\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0345 - val_loss: 0.0330\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 103us/sample - loss: 0.0336 - val_loss: 0.0319\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 96us/sample - loss: 0.0320 - val_loss: 0.0309\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 97us/sample - loss: 0.0311 - val_loss: 0.0300\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 90us/sample - loss: 0.0313 - val_loss: 0.0291\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 100us/sample - loss: 0.0300 - val_loss: 0.0282\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 101us/sample - loss: 0.0302 - val_loss: 0.0274\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 104us/sample - loss: 0.0279 - val_loss: 0.0266\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0274 - val_loss: 0.0258\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 88us/sample - loss: 0.0274 - val_loss: 0.0251\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 97us/sample - loss: 0.0265 - val_loss: 0.0244\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 95us/sample - loss: 0.0262 - val_loss: 0.0237\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 95us/sample - loss: 0.0247 - val_loss: 0.0231\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 90us/sample - loss: 0.0260 - val_loss: 0.0225\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 106us/sample - loss: 0.0230 - val_loss: 0.0219\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 105us/sample - loss: 0.0218 - val_loss: 0.0208\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 103us/sample - loss: 0.0228 - val_loss: 0.0203\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 98us/sample - loss: 0.0218 - val_loss: 0.0199\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 103us/sample - loss: 0.0219 - val_loss: 0.0195\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0222 - val_loss: 0.0191\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 107us/sample - loss: 0.0236 - val_loss: 0.0187\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0220 - val_loss: 0.0184\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 105us/sample - loss: 0.0207 - val_loss: 0.0180\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0201 - val_loss: 0.0177\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 98us/sample - loss: 0.0210 - val_loss: 0.0174\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0211 - val_loss: 0.0172\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 96us/sample - loss: 0.0204 - val_loss: 0.0169\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 106us/sample - loss: 0.0221 - val_loss: 0.0167\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0224 - val_loss: 0.0164\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 111us/sample - loss: 0.0209 - val_loss: 0.0162\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0213 - val_loss: 0.0160\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0185 - val_loss: 0.0158\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 114us/sample - loss: 0.0194 - val_loss: 0.0156\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0208 - val_loss: 0.0155\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0153\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0196 - val_loss: 0.0151\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 88us/sample - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0200 - val_loss: 0.0148\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0173 - val_loss: 0.0147\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0191 - val_loss: 0.0145\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 95us/sample - loss: 0.0175 - val_loss: 0.0144\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0179 - val_loss: 0.0143\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0184 - val_loss: 0.0142\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 103us/sample - loss: 0.0183 - val_loss: 0.0141\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0176 - val_loss: 0.0140\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0176 - val_loss: 0.0139\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 90us/sample - loss: 0.0201 - val_loss: 0.0138\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0178 - val_loss: 0.0137\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 121us/sample - loss: 0.0170 - val_loss: 0.0136\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0179 - val_loss: 0.0135\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 114us/sample - loss: 0.0175 - val_loss: 0.0134\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 115us/sample - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 108us/sample - loss: 0.0160 - val_loss: 0.0131\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 127us/sample - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 112us/sample - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 130us/sample - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 132us/sample - loss: 0.0165 - val_loss: 0.0127\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 122us/sample - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 115us/sample - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 119us/sample - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 114us/sample - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 127us/sample - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 115us/sample - loss: 0.0154 - val_loss: 0.0122\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 112us/sample - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 113us/sample - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 114us/sample - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 120us/sample - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 110us/sample - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 119us/sample - loss: 0.0155 - val_loss: 0.0115\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0151 - val_loss: 0.0115\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 104us/sample - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 87us/sample - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0105\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 87us/sample - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 102us/sample - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 103us/sample - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 94us/sample - loss: 0.0121 - val_loss: 0.0099\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 117us/sample - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 104us/sample - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 99us/sample - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 104us/sample - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 115us/sample - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 110us/sample - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 101us/sample - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 113us/sample - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 100us/sample - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 87us/sample - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 91us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 84us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 122us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 101us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 107us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 104us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 109us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 104us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 99us/sample - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 79us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 89us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0054 - val_loss: 0.0068\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.135 - 0s 811us/sample - loss: 0.1272 - val_loss: 0.1104\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.102 - 0s 117us/sample - loss: 0.1021 - val_loss: 0.1006\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.115 - 0s 96us/sample - loss: 0.1026 - val_loss: 0.0926\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 81us/sample - loss: 0.0961 - val_loss: 0.0867\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.108 - 0s 78us/sample - loss: 0.0864 - val_loss: 0.0805\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.101 - 0s 86us/sample - loss: 0.0876 - val_loss: 0.0751\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 90us/sample - loss: 0.0788 - val_loss: 0.0708\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.098 - 0s 84us/sample - loss: 0.0781 - val_loss: 0.0662\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 86us/sample - loss: 0.0731 - val_loss: 0.0627\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 92us/sample - loss: 0.0801 - val_loss: 0.0599\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 93us/sample - loss: 0.0760 - val_loss: 0.0567\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 99us/sample - loss: 0.0706 - val_loss: 0.0538\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 89us/sample - loss: 0.0675 - val_loss: 0.0513\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 95us/sample - loss: 0.0677 - val_loss: 0.0486\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 93us/sample - loss: 0.0661 - val_loss: 0.0463\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 91us/sample - loss: 0.0665 - val_loss: 0.0442\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0588 - val_loss: 0.0425\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 86us/sample - loss: 0.0523 - val_loss: 0.0408\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 88us/sample - loss: 0.0545 - val_loss: 0.0392\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 86us/sample - loss: 0.0552 - val_loss: 0.0375\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 93us/sample - loss: 0.0533 - val_loss: 0.0360\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 86us/sample - loss: 0.0507 - val_loss: 0.0346\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 81us/sample - loss: 0.0511 - val_loss: 0.0334\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 83us/sample - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 88us/sample - loss: 0.0417 - val_loss: 0.0314\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 94us/sample - loss: 0.0472 - val_loss: 0.0306\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 108us/sample - loss: 0.0468 - val_loss: 0.0298\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 103us/sample - loss: 0.0479 - val_loss: 0.0290\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 111us/sample - loss: 0.0415 - val_loss: 0.0281\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 112us/sample - loss: 0.0402 - val_loss: 0.0274\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.052 - 0s 105us/sample - loss: 0.0397 - val_loss: 0.0268\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 92us/sample - loss: 0.0364 - val_loss: 0.0262\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0359 - val_loss: 0.0254\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 97us/sample - loss: 0.0373 - val_loss: 0.0247\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0375 - val_loss: 0.0241\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 95us/sample - loss: 0.0332 - val_loss: 0.0235\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 99us/sample - loss: 0.0362 - val_loss: 0.0229\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 103us/sample - loss: 0.0323 - val_loss: 0.0226\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 108us/sample - loss: 0.0341 - val_loss: 0.0223\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 105us/sample - loss: 0.0398 - val_loss: 0.0218\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0332 - val_loss: 0.0214\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0310 - val_loss: 0.0209\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 96us/sample - loss: 0.0364 - val_loss: 0.0208\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 99us/sample - loss: 0.0343 - val_loss: 0.0204\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0345 - val_loss: 0.0201\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 112us/sample - loss: 0.0312 - val_loss: 0.0198\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0304 - val_loss: 0.0195\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 95us/sample - loss: 0.0306 - val_loss: 0.0193\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 88us/sample - loss: 0.0299 - val_loss: 0.0190\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0285 - val_loss: 0.0188\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 84us/sample - loss: 0.0278 - val_loss: 0.0185\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0257 - val_loss: 0.0182\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0280 - val_loss: 0.0179\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 81us/sample - loss: 0.0280 - val_loss: 0.0176\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 80us/sample - loss: 0.0286 - val_loss: 0.0171\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0244 - val_loss: 0.0169\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 83us/sample - loss: 0.0282 - val_loss: 0.0167\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0228 - val_loss: 0.0165\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 79us/sample - loss: 0.0235 - val_loss: 0.0165\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 85us/sample - loss: 0.0241 - val_loss: 0.0163\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0237 - val_loss: 0.0162\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0238 - val_loss: 0.0160\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0260 - val_loss: 0.0158\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 87us/sample - loss: 0.0247 - val_loss: 0.0156\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0263 - val_loss: 0.0153\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 95us/sample - loss: 0.0228 - val_loss: 0.0150\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0227 - val_loss: 0.0149\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0231 - val_loss: 0.0147\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0218 - val_loss: 0.0146\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 96us/sample - loss: 0.0218 - val_loss: 0.0145\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 99us/sample - loss: 0.0209 - val_loss: 0.0143\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 99us/sample - loss: 0.0217 - val_loss: 0.0143\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0187 - val_loss: 0.0142\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 99us/sample - loss: 0.0183 - val_loss: 0.0142\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0203 - val_loss: 0.0141\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 89us/sample - loss: 0.0216 - val_loss: 0.0139\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 99us/sample - loss: 0.0205 - val_loss: 0.0138\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0185 - val_loss: 0.0138\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 107us/sample - loss: 0.0192 - val_loss: 0.0137\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0188 - val_loss: 0.0137\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0199 - val_loss: 0.0136\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 88us/sample - loss: 0.0175 - val_loss: 0.0135\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 87us/sample - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0178 - val_loss: 0.0133\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0132\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 94us/sample - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 97us/sample - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 89us/sample - loss: 0.0159 - val_loss: 0.0130\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 81us/sample - loss: 0.0168 - val_loss: 0.0129\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 77us/sample - loss: 0.0173 - val_loss: 0.0129\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0165 - val_loss: 0.0127\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 87us/sample - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 92us/sample - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 88us/sample - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 91us/sample - loss: 0.0173 - val_loss: 0.0122\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 83us/sample - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0147 - val_loss: 0.0119\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0157 - val_loss: 0.0119\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 87us/sample - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0115\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 90us/sample - loss: 0.0138 - val_loss: 0.0114\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0138 - val_loss: 0.0113\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 110us/sample - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 130us/sample - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 125us/sample - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 129us/sample - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 124us/sample - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 127us/sample - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 120us/sample - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 110us/sample - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 109us/sample - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 115us/sample - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 115us/sample - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 102us/sample - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 94us/sample - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 99us/sample - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 94us/sample - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 84us/sample - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 99us/sample - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 99us/sample - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 129us/sample - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 105us/sample - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 102us/sample - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 91us/sample - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 78us/sample - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/sample - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 96us/sample - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 78us/sample - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 99us/sample - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 80us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 92us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 82us/sample - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0056 - val_loss: 0.0070\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.241 - 0s 665us/sample - loss: 0.3524 - val_loss: 0.5010\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.376 - 0s 120us/sample - loss: 0.3344 - val_loss: 0.4705\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.205 - 0s 103us/sample - loss: 0.2992 - val_loss: 0.4426\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.270 - 0s 86us/sample - loss: 0.2665 - val_loss: 0.4175\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.208 - 0s 86us/sample - loss: 0.2645 - val_loss: 0.3936\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.252 - 0s 91us/sample - loss: 0.2338 - val_loss: 0.3709\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.160 - 0s 86us/sample - loss: 0.2164 - val_loss: 0.3495\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.137 - 0s 99us/sample - loss: 0.2152 - val_loss: 0.3297\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.322 - 0s 87us/sample - loss: 0.2009 - val_loss: 0.3106\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.191 - 0s 93us/sample - loss: 0.1838 - val_loss: 0.2936\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.225 - 0s 93us/sample - loss: 0.1871 - val_loss: 0.2773\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.156 - 0s 90us/sample - loss: 0.1713 - val_loss: 0.2614\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.171 - 0s 96us/sample - loss: 0.1626 - val_loss: 0.2463\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.146 - 0s 86us/sample - loss: 0.1525 - val_loss: 0.2326\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.144 - 0s 92us/sample - loss: 0.1499 - val_loss: 0.2195\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 94us/sample - loss: 0.1434 - val_loss: 0.2066\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.136 - 0s 95us/sample - loss: 0.1239 - val_loss: 0.1955\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 92us/sample - loss: 0.1303 - val_loss: 0.1842\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 91us/sample - loss: 0.1215 - val_loss: 0.1738\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.110 - 0s 93us/sample - loss: 0.1142 - val_loss: 0.1640\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.151 - 0s 96us/sample - loss: 0.1041 - val_loss: 0.1552\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.127 - 0s 100us/sample - loss: 0.0998 - val_loss: 0.1466\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.176 - 0s 109us/sample - loss: 0.1005 - val_loss: 0.1381\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 98us/sample - loss: 0.0914 - val_loss: 0.1304\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 96us/sample - loss: 0.0871 - val_loss: 0.1232\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 100us/sample - loss: 0.0824 - val_loss: 0.1163\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 89us/sample - loss: 0.0788 - val_loss: 0.1099\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 93us/sample - loss: 0.0758 - val_loss: 0.1034\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 83us/sample - loss: 0.0667 - val_loss: 0.0976\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.085 - 0s 86us/sample - loss: 0.0693 - val_loss: 0.0921\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 87us/sample - loss: 0.0644 - val_loss: 0.0868\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 95us/sample - loss: 0.0634 - val_loss: 0.0819\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 93us/sample - loss: 0.0596 - val_loss: 0.0768\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 90us/sample - loss: 0.0553 - val_loss: 0.0721\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 90us/sample - loss: 0.0539 - val_loss: 0.0678\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 93us/sample - loss: 0.0524 - val_loss: 0.0638\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.076 - 0s 100us/sample - loss: 0.0511 - val_loss: 0.0599\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 94us/sample - loss: 0.0471 - val_loss: 0.0565\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 93us/sample - loss: 0.0473 - val_loss: 0.0533\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 77us/sample - loss: 0.0413 - val_loss: 0.0503\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 83us/sample - loss: 0.0420 - val_loss: 0.0472\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.075 - 0s 94us/sample - loss: 0.0404 - val_loss: 0.0443\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 88us/sample - loss: 0.0396 - val_loss: 0.0418\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 81us/sample - loss: 0.0381 - val_loss: 0.0395\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.079 - 0s 78us/sample - loss: 0.0400 - val_loss: 0.0373\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 94us/sample - loss: 0.0338 - val_loss: 0.0352\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 82us/sample - loss: 0.0334 - val_loss: 0.0333\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0327 - val_loss: 0.0315\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0302 - val_loss: 0.0299\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 82us/sample - loss: 0.0313 - val_loss: 0.0279\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 84us/sample - loss: 0.0319 - val_loss: 0.0265\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 86us/sample - loss: 0.0292 - val_loss: 0.0252\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 109us/sample - loss: 0.0281 - val_loss: 0.0240\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0278 - val_loss: 0.0230\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 100us/sample - loss: 0.0291 - val_loss: 0.0220\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0279 - val_loss: 0.0210\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0288 - val_loss: 0.0202\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0263 - val_loss: 0.0194\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 93us/sample - loss: 0.0254 - val_loss: 0.0188\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 92us/sample - loss: 0.0267 - val_loss: 0.0182\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 95us/sample - loss: 0.0243 - val_loss: 0.0177\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 105us/sample - loss: 0.0239 - val_loss: 0.0172\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 93us/sample - loss: 0.0221 - val_loss: 0.0168\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0212 - val_loss: 0.0165\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0255 - val_loss: 0.0162\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 93us/sample - loss: 0.0241 - val_loss: 0.0160\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 95us/sample - loss: 0.0271 - val_loss: 0.0157\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 94us/sample - loss: 0.0249 - val_loss: 0.0154\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 92us/sample - loss: 0.0233 - val_loss: 0.0152\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 93us/sample - loss: 0.0248 - val_loss: 0.0150\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 91us/sample - loss: 0.0253 - val_loss: 0.0148\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 103us/sample - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 98us/sample - loss: 0.0245 - val_loss: 0.0143\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0228 - val_loss: 0.0142\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 104us/sample - loss: 0.0221 - val_loss: 0.0141\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 84us/sample - loss: 0.0222 - val_loss: 0.0139\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 90us/sample - loss: 0.0226 - val_loss: 0.0138\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 81us/sample - loss: 0.0241 - val_loss: 0.0137\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 88us/sample - loss: 0.0194 - val_loss: 0.0135\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0201 - val_loss: 0.0135\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0134\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0234 - val_loss: 0.0133\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 94us/sample - loss: 0.0233 - val_loss: 0.0132\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 87us/sample - loss: 0.0209 - val_loss: 0.0131\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0228 - val_loss: 0.0129\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 86us/sample - loss: 0.0208 - val_loss: 0.0128\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0207 - val_loss: 0.0126\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0197 - val_loss: 0.0125\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0199 - val_loss: 0.0125\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 87us/sample - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0206 - val_loss: 0.0121\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 99us/sample - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0177 - val_loss: 0.0119\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0119\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 95us/sample - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 103us/sample - loss: 0.0199 - val_loss: 0.0117\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 115us/sample - loss: 0.0184 - val_loss: 0.0116\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 97us/sample - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 96us/sample - loss: 0.0184 - val_loss: 0.0113\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 96us/sample - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0187 - val_loss: 0.0112\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 98us/sample - loss: 0.0177 - val_loss: 0.0111\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 94us/sample - loss: 0.0181 - val_loss: 0.0111\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 101us/sample - loss: 0.0196 - val_loss: 0.0110\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 90us/sample - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 78us/sample - loss: 0.0192 - val_loss: 0.0109\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 79us/sample - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 84us/sample - loss: 0.0167 - val_loss: 0.0108\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 82us/sample - loss: 0.0162 - val_loss: 0.0107\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0172 - val_loss: 0.0106\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0176 - val_loss: 0.0106\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 80us/sample - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0163 - val_loss: 0.0105\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 80us/sample - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0166 - val_loss: 0.0103\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0165 - val_loss: 0.0102\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 88us/sample - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0154 - val_loss: 0.0100\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0149 - val_loss: 0.0100\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 110us/sample - loss: 0.0150 - val_loss: 0.0097\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 99us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0159 - val_loss: 0.0095\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0140 - val_loss: 0.0094\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 133us/sample - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 118us/sample - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 117us/sample - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 124us/sample - loss: 0.0139 - val_loss: 0.0093\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 123us/sample - loss: 0.0119 - val_loss: 0.0093\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 97us/sample - loss: 0.0123 - val_loss: 0.0093\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 146us/sample - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0131 - val_loss: 0.0092\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 94us/sample - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 100us/sample - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 98us/sample - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0118 - val_loss: 0.0091\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 108us/sample - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 97us/sample - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 110us/sample - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 112us/sample - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 105us/sample - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 99us/sample - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0110 - val_loss: 0.0085\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 97us/sample - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0107 - val_loss: 0.0085\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 106us/sample - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 96us/sample - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 100us/sample - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 81us/sample - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 83us/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 82us/sample - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 82us/sample - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 94us/sample - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 91us/sample - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 80us/sample - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 77us/sample - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 84us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 80us/sample - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 84us/sample - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 77us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 100us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 106us/sample - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 94us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 111us/sample - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0064 - val_loss: 0.0076\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.462 - 0s 789us/sample - loss: 0.4682 - val_loss: 0.4662\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.675 - 0s 104us/sample - loss: 0.4631 - val_loss: 0.4358\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.403 - 0s 107us/sample - loss: 0.4305 - val_loss: 0.4068\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.498 - 0s 103us/sample - loss: 0.3991 - val_loss: 0.3799\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.430 - 0s 105us/sample - loss: 0.3535 - val_loss: 0.3547\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.352 - 0s 105us/sample - loss: 0.3329 - val_loss: 0.3316\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.349 - 0s 100us/sample - loss: 0.3117 - val_loss: 0.3099\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.251 - 0s 90us/sample - loss: 0.3136 - val_loss: 0.2890\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.289 - 0s 100us/sample - loss: 0.2761 - val_loss: 0.2694\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.205 - 0s 91us/sample - loss: 0.2536 - val_loss: 0.2512\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.273 - 0s 93us/sample - loss: 0.2493 - val_loss: 0.2342\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.335 - 0s 96us/sample - loss: 0.2191 - val_loss: 0.2188\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.255 - 0s 84us/sample - loss: 0.2112 - val_loss: 0.2037\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.240 - 0s 108us/sample - loss: 0.2020 - val_loss: 0.1895\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.305 - 0s 98us/sample - loss: 0.1896 - val_loss: 0.1765\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.156 - 0s 100us/sample - loss: 0.1822 - val_loss: 0.1643\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.177 - 0s 85us/sample - loss: 0.1748 - val_loss: 0.1529\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.156 - 0s 84us/sample - loss: 0.1531 - val_loss: 0.1423\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.149 - 0s 89us/sample - loss: 0.1460 - val_loss: 0.1323\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.121 - 0s 87us/sample - loss: 0.1371 - val_loss: 0.1230\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.131 - 0s 89us/sample - loss: 0.1247 - val_loss: 0.1145\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 89us/sample - loss: 0.1301 - val_loss: 0.1066\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.114 - 0s 88us/sample - loss: 0.1103 - val_loss: 0.0995\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.133 - 0s 88us/sample - loss: 0.1088 - val_loss: 0.0926\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 83us/sample - loss: 0.1021 - val_loss: 0.0863\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.105 - 0s 86us/sample - loss: 0.1003 - val_loss: 0.0807\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 85us/sample - loss: 0.0792 - val_loss: 0.0755\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 93us/sample - loss: 0.0885 - val_loss: 0.0708\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.094 - 0s 83us/sample - loss: 0.0902 - val_loss: 0.0661\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 86us/sample - loss: 0.0840 - val_loss: 0.0619\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.095 - 0s 86us/sample - loss: 0.0860 - val_loss: 0.0579\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 85us/sample - loss: 0.0744 - val_loss: 0.0544\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 81us/sample - loss: 0.0707 - val_loss: 0.0513\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 105us/sample - loss: 0.0720 - val_loss: 0.0484\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 95us/sample - loss: 0.0669 - val_loss: 0.0456\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 84us/sample - loss: 0.0663 - val_loss: 0.0431\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.091 - 0s 78us/sample - loss: 0.0582 - val_loss: 0.0407\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 84us/sample - loss: 0.0557 - val_loss: 0.0386\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 88us/sample - loss: 0.0567 - val_loss: 0.0366\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 81us/sample - loss: 0.0507 - val_loss: 0.0347\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 89us/sample - loss: 0.0509 - val_loss: 0.0330\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.048 - 0s 98us/sample - loss: 0.0551 - val_loss: 0.0313\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 105us/sample - loss: 0.0493 - val_loss: 0.0298\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 97us/sample - loss: 0.0569 - val_loss: 0.0283\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 97us/sample - loss: 0.0507 - val_loss: 0.0270\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0473 - val_loss: 0.0260\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 100us/sample - loss: 0.0465 - val_loss: 0.0249\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 96us/sample - loss: 0.0484 - val_loss: 0.0239\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 95us/sample - loss: 0.0460 - val_loss: 0.0231\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 115us/sample - loss: 0.0509 - val_loss: 0.0223\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 130us/sample - loss: 0.0408 - val_loss: 0.0215\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 124us/sample - loss: 0.0405 - val_loss: 0.0209\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 110us/sample - loss: 0.0395 - val_loss: 0.0202\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 93us/sample - loss: 0.0467 - val_loss: 0.0197\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 113us/sample - loss: 0.0425 - val_loss: 0.0190\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 122us/sample - loss: 0.0416 - val_loss: 0.0186\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 152us/sample - loss: 0.0416 - val_loss: 0.0181\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 105us/sample - loss: 0.0379 - val_loss: 0.0176\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 94us/sample - loss: 0.0368 - val_loss: 0.0172\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 102us/sample - loss: 0.0376 - val_loss: 0.0169\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 74us/sample - loss: 0.0385 - val_loss: 0.0166\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 99us/sample - loss: 0.0379 - val_loss: 0.0163\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 104us/sample - loss: 0.0394 - val_loss: 0.0160\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 101us/sample - loss: 0.0362 - val_loss: 0.0157\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 93us/sample - loss: 0.0332 - val_loss: 0.0156\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 86us/sample - loss: 0.0335 - val_loss: 0.0153\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 78us/sample - loss: 0.0390 - val_loss: 0.0151\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 85us/sample - loss: 0.0377 - val_loss: 0.0149\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0364 - val_loss: 0.0147\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 88us/sample - loss: 0.0345 - val_loss: 0.0145\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 108us/sample - loss: 0.0335 - val_loss: 0.0144\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 130us/sample - loss: 0.0321 - val_loss: 0.0143\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 119us/sample - loss: 0.0322 - val_loss: 0.0141\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 98us/sample - loss: 0.0308 - val_loss: 0.0139\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 90us/sample - loss: 0.0344 - val_loss: 0.0138\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0314 - val_loss: 0.0137\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 95us/sample - loss: 0.0325 - val_loss: 0.0136\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 93us/sample - loss: 0.0343 - val_loss: 0.0134\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 88us/sample - loss: 0.0322 - val_loss: 0.0133\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0328 - val_loss: 0.0132\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 75us/sample - loss: 0.0311 - val_loss: 0.0131\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 99us/sample - loss: 0.0321 - val_loss: 0.0129\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 126us/sample - loss: 0.0306 - val_loss: 0.0128\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 123us/sample - loss: 0.0278 - val_loss: 0.0127\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 112us/sample - loss: 0.0291 - val_loss: 0.0126\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0303 - val_loss: 0.0125\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 90us/sample - loss: 0.0298 - val_loss: 0.0124\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0310 - val_loss: 0.0123\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0295 - val_loss: 0.0122\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 90us/sample - loss: 0.0285 - val_loss: 0.0121\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 98us/sample - loss: 0.0261 - val_loss: 0.0121\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 106us/sample - loss: 0.0281 - val_loss: 0.0120\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 132us/sample - loss: 0.0263 - val_loss: 0.0119\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 122us/sample - loss: 0.0281 - val_loss: 0.0119\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 114us/sample - loss: 0.0252 - val_loss: 0.0118\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 89us/sample - loss: 0.0233 - val_loss: 0.0117\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 88us/sample - loss: 0.0259 - val_loss: 0.0116\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 93us/sample - loss: 0.0281 - val_loss: 0.0115\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0228 - val_loss: 0.0114\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 94us/sample - loss: 0.0257 - val_loss: 0.0114\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 100us/sample - loss: 0.0246 - val_loss: 0.0113\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 112us/sample - loss: 0.0236 - val_loss: 0.0112\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0223 - val_loss: 0.0112\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 85us/sample - loss: 0.0257 - val_loss: 0.0111\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 114us/sample - loss: 0.0232 - val_loss: 0.0110\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 115us/sample - loss: 0.0259 - val_loss: 0.0109\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 103us/sample - loss: 0.0231 - val_loss: 0.0109\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0242 - val_loss: 0.0108\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0231 - val_loss: 0.0108\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0234 - val_loss: 0.0107\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 109us/sample - loss: 0.0219 - val_loss: 0.0106\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 113us/sample - loss: 0.0248 - val_loss: 0.0106\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 102us/sample - loss: 0.0222 - val_loss: 0.0105\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0222 - val_loss: 0.0104\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 80us/sample - loss: 0.0223 - val_loss: 0.0104\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0209 - val_loss: 0.0103\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 85us/sample - loss: 0.0225 - val_loss: 0.0102\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 121us/sample - loss: 0.0221 - val_loss: 0.0102\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 104us/sample - loss: 0.0200 - val_loss: 0.0101\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 102us/sample - loss: 0.0226 - val_loss: 0.0101\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 95us/sample - loss: 0.0217 - val_loss: 0.0101\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 87us/sample - loss: 0.0199 - val_loss: 0.0100\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 91us/sample - loss: 0.0207 - val_loss: 0.0100\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 88us/sample - loss: 0.0219 - val_loss: 0.0099\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 103us/sample - loss: 0.0192 - val_loss: 0.0099\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0210 - val_loss: 0.0098\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 129us/sample - loss: 0.0213 - val_loss: 0.0098\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 123us/sample - loss: 0.0184 - val_loss: 0.0098\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0190 - val_loss: 0.0097\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0182 - val_loss: 0.0097\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 105us/sample - loss: 0.0191 - val_loss: 0.0096\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 123us/sample - loss: 0.0187 - val_loss: 0.0096\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 122us/sample - loss: 0.0168 - val_loss: 0.0096\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/sample - loss: 0.0174 - val_loss: 0.0095\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 98us/sample - loss: 0.0172 - val_loss: 0.0095\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 88us/sample - loss: 0.0186 - val_loss: 0.0095\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0184 - val_loss: 0.0094\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 117us/sample - loss: 0.0185 - val_loss: 0.0094\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 115us/sample - loss: 0.0193 - val_loss: 0.0093\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 116us/sample - loss: 0.0181 - val_loss: 0.0093\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 93us/sample - loss: 0.0179 - val_loss: 0.0093\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 94us/sample - loss: 0.0161 - val_loss: 0.0092\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0163 - val_loss: 0.0092\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0162 - val_loss: 0.0091\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 80us/sample - loss: 0.0159 - val_loss: 0.0091\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 78us/sample - loss: 0.0179 - val_loss: 0.0091\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 100us/sample - loss: 0.0158 - val_loss: 0.0090\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 115us/sample - loss: 0.0161 - val_loss: 0.0090\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0147 - val_loss: 0.0090\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0172 - val_loss: 0.0089\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0167 - val_loss: 0.0089\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 91us/sample - loss: 0.0154 - val_loss: 0.0089\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0150 - val_loss: 0.0088\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 98us/sample - loss: 0.0139 - val_loss: 0.0088\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 103us/sample - loss: 0.0145 - val_loss: 0.0088\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 104us/sample - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0150 - val_loss: 0.0087\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 122us/sample - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 95us/sample - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 84us/sample - loss: 0.0140 - val_loss: 0.0086\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0143 - val_loss: 0.0085\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 93us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 107us/sample - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 120us/sample - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 117us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 112us/sample - loss: 0.0139 - val_loss: 0.0084\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 105us/sample - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 130us/sample - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 109us/sample - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 104us/sample - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 113us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 113us/sample - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 106us/sample - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 102us/sample - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 109us/sample - loss: 0.0147 - val_loss: 0.0081\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 108us/sample - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 117us/sample - loss: 0.0125 - val_loss: 0.0080\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 121us/sample - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 144us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 129us/sample - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 120us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 108us/sample - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 107us/sample - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 96us/sample - loss: 0.0103 - val_loss: 0.0079\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 108us/sample - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 95us/sample - loss: 0.0111 - val_loss: 0.0077\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 98us/sample - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 120us/sample - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 114us/sample - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 117us/sample - loss: 0.0100 - val_loss: 0.0076\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0100 - val_loss: 0.0076\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 120us/sample - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 107us/sample - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 103us/sample - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 83us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 101us/sample - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 117us/sample - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 105us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 101us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 91us/sample - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 89us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 96us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 102us/sample - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 124us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 107us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 101us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 106us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 92us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 100us/sample - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 77us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 99us/sample - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 97us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.216 - 0s 636us/sample - loss: 0.2551 - val_loss: 0.2779\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.288 - 0s 92us/sample - loss: 0.2222 - val_loss: 0.2498\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.232 - 0s 88us/sample - loss: 0.1870 - val_loss: 0.2247\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.303 - 0s 85us/sample - loss: 0.1954 - val_loss: 0.2016\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.125 - 0s 87us/sample - loss: 0.1712 - val_loss: 0.1813\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.138 - 0s 82us/sample - loss: 0.1530 - val_loss: 0.1633\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.139 - 0s 86us/sample - loss: 0.1473 - val_loss: 0.1470\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.142 - 0s 86us/sample - loss: 0.1397 - val_loss: 0.1324\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 83us/sample - loss: 0.1249 - val_loss: 0.1197\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.111 - 0s 86us/sample - loss: 0.1089 - val_loss: 0.1099\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.143 - 0s 100us/sample - loss: 0.1033 - val_loss: 0.1008\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.123 - 0s 101us/sample - loss: 0.0960 - val_loss: 0.0922\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.100 - 0s 112us/sample - loss: 0.0965 - val_loss: 0.0850\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 103us/sample - loss: 0.0970 - val_loss: 0.0785\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 93us/sample - loss: 0.0838 - val_loss: 0.0732\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 89us/sample - loss: 0.0736 - val_loss: 0.0692\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 112us/sample - loss: 0.0762 - val_loss: 0.0653\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 95us/sample - loss: 0.0783 - val_loss: 0.0619\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 93us/sample - loss: 0.0706 - val_loss: 0.0588\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 117us/sample - loss: 0.0695 - val_loss: 0.0563\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.088 - 0s 107us/sample - loss: 0.0655 - val_loss: 0.0536\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 103us/sample - loss: 0.0641 - val_loss: 0.0514\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.083 - 0s 95us/sample - loss: 0.0717 - val_loss: 0.0494\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 102us/sample - loss: 0.0628 - val_loss: 0.0476\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 96us/sample - loss: 0.0618 - val_loss: 0.0462\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 87us/sample - loss: 0.0622 - val_loss: 0.0448\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.077 - 0s 93us/sample - loss: 0.0589 - val_loss: 0.0432\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 90us/sample - loss: 0.0569 - val_loss: 0.0424\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 96us/sample - loss: 0.0583 - val_loss: 0.0413\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 101us/sample - loss: 0.0496 - val_loss: 0.0403\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 86us/sample - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 85us/sample - loss: 0.0482 - val_loss: 0.0390\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 81us/sample - loss: 0.0483 - val_loss: 0.0383\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 81us/sample - loss: 0.0488 - val_loss: 0.0373\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 83us/sample - loss: 0.0467 - val_loss: 0.0364\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 86us/sample - loss: 0.0472 - val_loss: 0.0355\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0488 - val_loss: 0.0347\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 86us/sample - loss: 0.0444 - val_loss: 0.0340\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 87us/sample - loss: 0.0430 - val_loss: 0.0334\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 88us/sample - loss: 0.0502 - val_loss: 0.0327\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 92us/sample - loss: 0.0427 - val_loss: 0.0319\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 86us/sample - loss: 0.0379 - val_loss: 0.0311\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 86us/sample - loss: 0.0419 - val_loss: 0.0306\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 83us/sample - loss: 0.0392 - val_loss: 0.0299\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 86us/sample - loss: 0.0370 - val_loss: 0.0294\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.044 - 0s 85us/sample - loss: 0.0382 - val_loss: 0.0289\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.040 - 0s 86us/sample - loss: 0.0398 - val_loss: 0.0284\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 84us/sample - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 85us/sample - loss: 0.0351 - val_loss: 0.0272\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 105us/sample - loss: 0.0323 - val_loss: 0.0265\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 100us/sample - loss: 0.0317 - val_loss: 0.0259\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0322 - val_loss: 0.0254\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 77us/sample - loss: 0.0315 - val_loss: 0.0250\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 81us/sample - loss: 0.0334 - val_loss: 0.0243\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 87us/sample - loss: 0.0305 - val_loss: 0.0237\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 90us/sample - loss: 0.0337 - val_loss: 0.0231\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 100us/sample - loss: 0.0302 - val_loss: 0.0225\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 98us/sample - loss: 0.0317 - val_loss: 0.0220\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0279 - val_loss: 0.0215\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0269 - val_loss: 0.0211\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 97us/sample - loss: 0.0296 - val_loss: 0.0206\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 90us/sample - loss: 0.0252 - val_loss: 0.0201\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 95us/sample - loss: 0.0307 - val_loss: 0.0197\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 87us/sample - loss: 0.0270 - val_loss: 0.0192\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 97us/sample - loss: 0.0251 - val_loss: 0.0188\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.051 - 0s 90us/sample - loss: 0.0256 - val_loss: 0.0185\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 96us/sample - loss: 0.0256 - val_loss: 0.0182\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 95us/sample - loss: 0.0257 - val_loss: 0.0179\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0232 - val_loss: 0.0176\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 102us/sample - loss: 0.0257 - val_loss: 0.0173\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 89us/sample - loss: 0.0252 - val_loss: 0.0169\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 102us/sample - loss: 0.0237 - val_loss: 0.0166\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 92us/sample - loss: 0.0205 - val_loss: 0.0161\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 99us/sample - loss: 0.0234 - val_loss: 0.0159\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 118us/sample - loss: 0.0226 - val_loss: 0.0156\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 107us/sample - loss: 0.0234 - val_loss: 0.0153\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0233 - val_loss: 0.0151\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 98us/sample - loss: 0.0199 - val_loss: 0.0148\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 83us/sample - loss: 0.0198 - val_loss: 0.0146\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 78us/sample - loss: 0.0209 - val_loss: 0.0143\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 102us/sample - loss: 0.0198 - val_loss: 0.0142\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 108us/sample - loss: 0.0204 - val_loss: 0.0140\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 96us/sample - loss: 0.0200 - val_loss: 0.0138\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 89us/sample - loss: 0.0197 - val_loss: 0.0135\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 81us/sample - loss: 0.0194 - val_loss: 0.0133\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 82us/sample - loss: 0.0179 - val_loss: 0.0131\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 78us/sample - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0201 - val_loss: 0.0129\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 103us/sample - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 99us/sample - loss: 0.0195 - val_loss: 0.0127\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 97us/sample - loss: 0.0194 - val_loss: 0.0123\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 81us/sample - loss: 0.0187 - val_loss: 0.0122\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 97us/sample - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 98us/sample - loss: 0.0180 - val_loss: 0.0118\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0181 - val_loss: 0.0118\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0164 - val_loss: 0.0117\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 127us/sample - loss: 0.0184 - val_loss: 0.0116\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 117us/sample - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0175 - val_loss: 0.0113\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 86us/sample - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 96us/sample - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 112us/sample - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 108us/sample - loss: 0.0155 - val_loss: 0.0105\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 117us/sample - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 92us/sample - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 103us/sample - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 87us/sample - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 85us/sample - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 99us/sample - loss: 0.0149 - val_loss: 0.0099\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 105us/sample - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0148 - val_loss: 0.0098\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 106us/sample - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 96us/sample - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 95us/sample - loss: 0.0150 - val_loss: 0.0095\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 81us/sample - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 85us/sample - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0138 - val_loss: 0.0094\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0141 - val_loss: 0.0093\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0137 - val_loss: 0.0090\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 110us/sample - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 122us/sample - loss: 0.0141 - val_loss: 0.0089\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 101us/sample - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 80us/sample - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 97us/sample - loss: 0.0126 - val_loss: 0.0087\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 110us/sample - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 95us/sample - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 100us/sample - loss: 0.0132 - val_loss: 0.0085\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 117us/sample - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 115us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 92us/sample - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 112us/sample - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 113us/sample - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 115us/sample - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 103us/sample - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 90us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 82us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 81us/sample - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 85us/sample - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 85us/sample - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 83us/sample - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 86us/sample - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 117us/sample - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 101us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 120us/sample - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 97us/sample - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 78us/sample - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 82us/sample - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 84us/sample - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 95us/sample - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 117us/sample - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 97us/sample - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 117us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 115us/sample - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 112us/sample - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 110us/sample - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/sample - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 107us/sample - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 110us/sample - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/sample - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 112us/sample - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 108us/sample - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 103us/sample - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 78us/sample - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 82us/sample - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 110us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 89us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 92us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 91us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 101us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 86us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 88us/sample - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 77us/sample - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 92us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 100us/sample - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 103us/sample - loss: 0.0061 - val_loss: 0.0068\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.094 - 0s 716us/sample - loss: 0.0997 - val_loss: 0.0864\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 105us/sample - loss: 0.0953 - val_loss: 0.0803\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.092 - 0s 97us/sample - loss: 0.0885 - val_loss: 0.0743\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.093 - 0s 98us/sample - loss: 0.0843 - val_loss: 0.0690\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.072 - 0s 106us/sample - loss: 0.0799 - val_loss: 0.0640\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.099 - 0s 100us/sample - loss: 0.0742 - val_loss: 0.0593\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 113us/sample - loss: 0.0718 - val_loss: 0.0550\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.067 - 0s 108us/sample - loss: 0.0692 - val_loss: 0.0511\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 121us/sample - loss: 0.0676 - val_loss: 0.0473\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 110us/sample - loss: 0.0669 - val_loss: 0.0445\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.103 - 0s 109us/sample - loss: 0.0647 - val_loss: 0.0423\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 114us/sample - loss: 0.0636 - val_loss: 0.0397\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.070 - 0s 132us/sample - loss: 0.0583 - val_loss: 0.0370\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.055 - 0s 101us/sample - loss: 0.0570 - val_loss: 0.0349\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.054 - 0s 99us/sample - loss: 0.0577 - val_loss: 0.0330\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 85us/sample - loss: 0.0508 - val_loss: 0.0313\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 81us/sample - loss: 0.0563 - val_loss: 0.0298\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 85us/sample - loss: 0.0492 - val_loss: 0.0284\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 82us/sample - loss: 0.0530 - val_loss: 0.0271\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 80us/sample - loss: 0.0480 - val_loss: 0.0262\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 84us/sample - loss: 0.0470 - val_loss: 0.0252\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0520 - val_loss: 0.0243\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 86us/sample - loss: 0.0489 - val_loss: 0.0235\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 83us/sample - loss: 0.0433 - val_loss: 0.0231\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 87us/sample - loss: 0.0460 - val_loss: 0.0227\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0452 - val_loss: 0.0222\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 87us/sample - loss: 0.0438 - val_loss: 0.0218\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 91us/sample - loss: 0.0433 - val_loss: 0.0215\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 87us/sample - loss: 0.0432 - val_loss: 0.0210\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 92us/sample - loss: 0.0415 - val_loss: 0.0206\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 88us/sample - loss: 0.0437 - val_loss: 0.0203\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0384 - val_loss: 0.0199\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 90us/sample - loss: 0.0401 - val_loss: 0.0196\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.034 - 0s 86us/sample - loss: 0.0396 - val_loss: 0.0193\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 94us/sample - loss: 0.0400 - val_loss: 0.0190\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 88us/sample - loss: 0.0354 - val_loss: 0.0188\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0370 - val_loss: 0.0186\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 99us/sample - loss: 0.0371 - val_loss: 0.0184\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 102us/sample - loss: 0.0372 - val_loss: 0.0182\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 105us/sample - loss: 0.0369 - val_loss: 0.0179\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 100us/sample - loss: 0.0366 - val_loss: 0.0177\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 98us/sample - loss: 0.0380 - val_loss: 0.0175\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.036 - 0s 98us/sample - loss: 0.0325 - val_loss: 0.0173\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 92us/sample - loss: 0.0362 - val_loss: 0.0171\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 93us/sample - loss: 0.0325 - val_loss: 0.0170\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0340 - val_loss: 0.0168\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 102us/sample - loss: 0.0339 - val_loss: 0.0166\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.049 - 0s 100us/sample - loss: 0.0338 - val_loss: 0.0164\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 93us/sample - loss: 0.0337 - val_loss: 0.0163\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 95us/sample - loss: 0.0325 - val_loss: 0.0162\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 100us/sample - loss: 0.0320 - val_loss: 0.0160\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 115us/sample - loss: 0.0294 - val_loss: 0.0158\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 100us/sample - loss: 0.0324 - val_loss: 0.0157\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 89us/sample - loss: 0.0323 - val_loss: 0.0156\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0310 - val_loss: 0.0155\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 90us/sample - loss: 0.0285 - val_loss: 0.0154\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0313 - val_loss: 0.0153\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 92us/sample - loss: 0.0302 - val_loss: 0.0151\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 83us/sample - loss: 0.0265 - val_loss: 0.0151\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 81us/sample - loss: 0.0276 - val_loss: 0.0150\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 93us/sample - loss: 0.0289 - val_loss: 0.0148\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0260 - val_loss: 0.0148\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 90us/sample - loss: 0.0278 - val_loss: 0.0147\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 82us/sample - loss: 0.0272 - val_loss: 0.0147\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 89us/sample - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 81us/sample - loss: 0.0283 - val_loss: 0.0144\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 85us/sample - loss: 0.0257 - val_loss: 0.0142\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 88us/sample - loss: 0.0267 - val_loss: 0.0142\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0265 - val_loss: 0.0141\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0243 - val_loss: 0.0139\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 88us/sample - loss: 0.0254 - val_loss: 0.0139\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 83us/sample - loss: 0.0243 - val_loss: 0.0138\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 91us/sample - loss: 0.0260 - val_loss: 0.0136\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 80us/sample - loss: 0.0243 - val_loss: 0.0135\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 85us/sample - loss: 0.0242 - val_loss: 0.0134\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 82us/sample - loss: 0.0247 - val_loss: 0.0133\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 95us/sample - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 99us/sample - loss: 0.0221 - val_loss: 0.0133\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 100us/sample - loss: 0.0230 - val_loss: 0.0133\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 85us/sample - loss: 0.0219 - val_loss: 0.0133\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0239 - val_loss: 0.0132\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 104us/sample - loss: 0.0218 - val_loss: 0.0132\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 90us/sample - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 108us/sample - loss: 0.0221 - val_loss: 0.0130\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 92us/sample - loss: 0.0218 - val_loss: 0.0129\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0228 - val_loss: 0.0129\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 95us/sample - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 88us/sample - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 93us/sample - loss: 0.0214 - val_loss: 0.0127\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 100us/sample - loss: 0.0213 - val_loss: 0.0126\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 98us/sample - loss: 0.0200 - val_loss: 0.0125\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 97us/sample - loss: 0.0200 - val_loss: 0.0125\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 94us/sample - loss: 0.0210 - val_loss: 0.0125\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 125us/sample - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 105us/sample - loss: 0.0187 - val_loss: 0.0125\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0191 - val_loss: 0.0124\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0205 - val_loss: 0.0122\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 90us/sample - loss: 0.0194 - val_loss: 0.0122\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 90us/sample - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0175 - val_loss: 0.0120\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0180 - val_loss: 0.0118\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 87us/sample - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 92us/sample - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 87us/sample - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 83us/sample - loss: 0.0175 - val_loss: 0.0114\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 89us/sample - loss: 0.0164 - val_loss: 0.0113\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 117us/sample - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0168 - val_loss: 0.0111\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 76us/sample - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 83us/sample - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 81us/sample - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 87us/sample - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0169 - val_loss: 0.0108\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 105us/sample - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 100us/sample - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 100us/sample - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 112us/sample - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 103us/sample - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 108us/sample - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 103us/sample - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 109us/sample - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 117us/sample - loss: 0.0130 - val_loss: 0.0103\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 93us/sample - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 100us/sample - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 91us/sample - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 94us/sample - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 109us/sample - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 98us/sample - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 105us/sample - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 110us/sample - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 81us/sample - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 89us/sample - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 86us/sample - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 91us/sample - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 93us/sample - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 90us/sample - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 85us/sample - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 91us/sample - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 94us/sample - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 103us/sample - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 90us/sample - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 137us/sample - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 98us/sample - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 93us/sample - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 91us/sample - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 108us/sample - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 93us/sample - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 95us/sample - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 92us/sample - loss: 0.0084 - val_loss: 0.0091\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 89us/sample - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0082 - val_loss: 0.0091\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 102us/sample - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 80us/sample - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 84us/sample - loss: 0.0078 - val_loss: 0.0090\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 85us/sample - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 88us/sample - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 84us/sample - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 80us/sample - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 83us/sample - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 80us/sample - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 83us/sample - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 84us/sample - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 102us/sample - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 93us/sample - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 100us/sample - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0064 - val_loss: 0.0086\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 99us/sample - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 116us/sample - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0086\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 112us/sample - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0085\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 82us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 80us/sample - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 100us/sample - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 81us/sample - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 120us/sample - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 110us/sample - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 109us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 115us/sample - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 117us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 144us/sample - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 107us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 122us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/sample - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 102us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 100us/sample - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 108us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/sample - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 88us/sample - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 88us/sample - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 78us/sample - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 83us/sample - loss: 0.0057 - val_loss: 0.0076\n",
      "Train on 408 samples, validate on 175 samples\n",
      "Epoch 1/300\n",
      "408/408 [==============================] - ETA: 1s - loss: 0.152 - 0s 640us/sample - loss: 0.1354 - val_loss: 0.0262\n",
      "Epoch 2/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.127 - 0s 91us/sample - loss: 0.1316 - val_loss: 0.0235\n",
      "Epoch 3/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.107 - 0s 100us/sample - loss: 0.1230 - val_loss: 0.0214\n",
      "Epoch 4/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.141 - 0s 86us/sample - loss: 0.1212 - val_loss: 0.0202\n",
      "Epoch 5/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.129 - 0s 80us/sample - loss: 0.1231 - val_loss: 0.0191\n",
      "Epoch 6/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.136 - 0s 93us/sample - loss: 0.1222 - val_loss: 0.0183\n",
      "Epoch 7/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.137 - 0s 83us/sample - loss: 0.0999 - val_loss: 0.0176\n",
      "Epoch 8/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.130 - 0s 86us/sample - loss: 0.1145 - val_loss: 0.0171\n",
      "Epoch 9/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 88us/sample - loss: 0.1001 - val_loss: 0.0167\n",
      "Epoch 10/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.074 - 0s 83us/sample - loss: 0.0977 - val_loss: 0.0164\n",
      "Epoch 11/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 88us/sample - loss: 0.0943 - val_loss: 0.0162\n",
      "Epoch 12/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 96us/sample - loss: 0.0940 - val_loss: 0.0161\n",
      "Epoch 13/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.090 - 0s 88us/sample - loss: 0.0819 - val_loss: 0.0160\n",
      "Epoch 14/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 87us/sample - loss: 0.0891 - val_loss: 0.0159\n",
      "Epoch 15/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 86us/sample - loss: 0.0844 - val_loss: 0.0159\n",
      "Epoch 16/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.063 - 0s 91us/sample - loss: 0.0784 - val_loss: 0.0159\n",
      "Epoch 17/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.109 - 0s 93us/sample - loss: 0.0837 - val_loss: 0.0158\n",
      "Epoch 18/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.082 - 0s 88us/sample - loss: 0.0778 - val_loss: 0.0158\n",
      "Epoch 19/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 88us/sample - loss: 0.0829 - val_loss: 0.0157\n",
      "Epoch 20/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.135 - 0s 92us/sample - loss: 0.0752 - val_loss: 0.0156\n",
      "Epoch 21/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 99us/sample - loss: 0.0708 - val_loss: 0.0157\n",
      "Epoch 22/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 105us/sample - loss: 0.0741 - val_loss: 0.0157\n",
      "Epoch 23/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.124 - 0s 93us/sample - loss: 0.0775 - val_loss: 0.0155\n",
      "Epoch 24/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.089 - 0s 89us/sample - loss: 0.0773 - val_loss: 0.0154\n",
      "Epoch 25/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.071 - 0s 95us/sample - loss: 0.0688 - val_loss: 0.0153\n",
      "Epoch 26/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0618 - val_loss: 0.0153\n",
      "Epoch 27/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 95us/sample - loss: 0.0647 - val_loss: 0.0153\n",
      "Epoch 28/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.059 - 0s 90us/sample - loss: 0.0623 - val_loss: 0.0152\n",
      "Epoch 29/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.053 - 0s 88us/sample - loss: 0.0665 - val_loss: 0.0152\n",
      "Epoch 30/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.096 - 0s 103us/sample - loss: 0.0672 - val_loss: 0.0152\n",
      "Epoch 31/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.057 - 0s 103us/sample - loss: 0.0648 - val_loss: 0.0151\n",
      "Epoch 32/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 93us/sample - loss: 0.0574 - val_loss: 0.0149\n",
      "Epoch 33/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 88us/sample - loss: 0.0553 - val_loss: 0.0148\n",
      "Epoch 34/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 88us/sample - loss: 0.0593 - val_loss: 0.0147\n",
      "Epoch 35/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 90us/sample - loss: 0.0566 - val_loss: 0.0147\n",
      "Epoch 36/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 108us/sample - loss: 0.0557 - val_loss: 0.0146\n",
      "Epoch 37/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.064 - 0s 109us/sample - loss: 0.0542 - val_loss: 0.0145\n",
      "Epoch 38/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0556 - val_loss: 0.0145\n",
      "Epoch 39/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.065 - 0s 95us/sample - loss: 0.0561 - val_loss: 0.0145\n",
      "Epoch 40/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.086 - 0s 90us/sample - loss: 0.0512 - val_loss: 0.0145\n",
      "Epoch 41/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.058 - 0s 86us/sample - loss: 0.0533 - val_loss: 0.0145\n",
      "Epoch 42/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.046 - 0s 81us/sample - loss: 0.0468 - val_loss: 0.0144\n",
      "Epoch 43/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.039 - 0s 81us/sample - loss: 0.0497 - val_loss: 0.0142\n",
      "Epoch 44/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.084 - 0s 81us/sample - loss: 0.0592 - val_loss: 0.0140\n",
      "Epoch 45/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 80us/sample - loss: 0.0455 - val_loss: 0.0139\n",
      "Epoch 46/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 85us/sample - loss: 0.0416 - val_loss: 0.0139\n",
      "Epoch 47/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.047 - 0s 93us/sample - loss: 0.0477 - val_loss: 0.0138\n",
      "Epoch 48/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 99us/sample - loss: 0.0461 - val_loss: 0.0137\n",
      "Epoch 49/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 90us/sample - loss: 0.0405 - val_loss: 0.0137\n",
      "Epoch 50/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 93us/sample - loss: 0.0457 - val_loss: 0.0136\n",
      "Epoch 51/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.050 - 0s 95us/sample - loss: 0.0368 - val_loss: 0.0136\n",
      "Epoch 52/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0401 - val_loss: 0.0135\n",
      "Epoch 53/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.045 - 0s 103us/sample - loss: 0.0381 - val_loss: 0.0135\n",
      "Epoch 54/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.060 - 0s 95us/sample - loss: 0.0407 - val_loss: 0.0135\n",
      "Epoch 55/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.061 - 0s 96us/sample - loss: 0.0388 - val_loss: 0.0134\n",
      "Epoch 56/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.028 - 0s 87us/sample - loss: 0.0369 - val_loss: 0.0133\n",
      "Epoch 57/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 87us/sample - loss: 0.0434 - val_loss: 0.0132\n",
      "Epoch 58/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 98us/sample - loss: 0.0365 - val_loss: 0.0132\n",
      "Epoch 59/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 87us/sample - loss: 0.0347 - val_loss: 0.0132\n",
      "Epoch 60/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.056 - 0s 90us/sample - loss: 0.0403 - val_loss: 0.0131\n",
      "Epoch 61/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.041 - 0s 92us/sample - loss: 0.0330 - val_loss: 0.0130\n",
      "Epoch 62/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 85us/sample - loss: 0.0354 - val_loss: 0.0129\n",
      "Epoch 63/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.032 - 0s 89us/sample - loss: 0.0342 - val_loss: 0.0127\n",
      "Epoch 64/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 88us/sample - loss: 0.0371 - val_loss: 0.0126\n",
      "Epoch 65/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.066 - 0s 100us/sample - loss: 0.0320 - val_loss: 0.0125\n",
      "Epoch 66/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0309 - val_loss: 0.0125\n",
      "Epoch 67/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 98us/sample - loss: 0.0331 - val_loss: 0.0124\n",
      "Epoch 68/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 103us/sample - loss: 0.0322 - val_loss: 0.0124\n",
      "Epoch 69/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 108us/sample - loss: 0.0334 - val_loss: 0.0123\n",
      "Epoch 70/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.062 - 0s 112us/sample - loss: 0.0373 - val_loss: 0.0122\n",
      "Epoch 71/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 105us/sample - loss: 0.0311 - val_loss: 0.0120\n",
      "Epoch 72/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 98us/sample - loss: 0.0303 - val_loss: 0.0120\n",
      "Epoch 73/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 97us/sample - loss: 0.0272 - val_loss: 0.0119\n",
      "Epoch 74/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.033 - 0s 100us/sample - loss: 0.0300 - val_loss: 0.0118\n",
      "Epoch 75/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.030 - 0s 91us/sample - loss: 0.0264 - val_loss: 0.0118\n",
      "Epoch 76/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.037 - 0s 89us/sample - loss: 0.0290 - val_loss: 0.0118\n",
      "Epoch 77/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 98us/sample - loss: 0.0298 - val_loss: 0.0117\n",
      "Epoch 78/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 107us/sample - loss: 0.0288 - val_loss: 0.0116\n",
      "Epoch 79/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.027 - 0s 93us/sample - loss: 0.0291 - val_loss: 0.0115\n",
      "Epoch 80/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.043 - 0s 93us/sample - loss: 0.0298 - val_loss: 0.0114\n",
      "Epoch 81/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 88us/sample - loss: 0.0259 - val_loss: 0.0114\n",
      "Epoch 82/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.035 - 0s 90us/sample - loss: 0.0247 - val_loss: 0.0113\n",
      "Epoch 83/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 97us/sample - loss: 0.0217 - val_loss: 0.0114\n",
      "Epoch 84/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 96us/sample - loss: 0.0273 - val_loss: 0.0113\n",
      "Epoch 85/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.025 - 0s 88us/sample - loss: 0.0244 - val_loss: 0.0112\n",
      "Epoch 86/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 79us/sample - loss: 0.0227 - val_loss: 0.0113\n",
      "Epoch 87/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 83us/sample - loss: 0.0240 - val_loss: 0.0112\n",
      "Epoch 88/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.038 - 0s 86us/sample - loss: 0.0253 - val_loss: 0.0111\n",
      "Epoch 89/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 90us/sample - loss: 0.0249 - val_loss: 0.0111\n",
      "Epoch 90/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 91us/sample - loss: 0.0241 - val_loss: 0.0110\n",
      "Epoch 91/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.042 - 0s 86us/sample - loss: 0.0230 - val_loss: 0.0110\n",
      "Epoch 92/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 84us/sample - loss: 0.0230 - val_loss: 0.0109\n",
      "Epoch 93/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 86us/sample - loss: 0.0204 - val_loss: 0.0108\n",
      "Epoch 94/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 87us/sample - loss: 0.0197 - val_loss: 0.0108\n",
      "Epoch 95/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.023 - 0s 86us/sample - loss: 0.0212 - val_loss: 0.0108\n",
      "Epoch 96/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 81us/sample - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 97/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 93us/sample - loss: 0.0201 - val_loss: 0.0107\n",
      "Epoch 98/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 91us/sample - loss: 0.0192 - val_loss: 0.0106\n",
      "Epoch 99/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 100us/sample - loss: 0.0204 - val_loss: 0.0106\n",
      "Epoch 100/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.022 - 0s 86us/sample - loss: 0.0194 - val_loss: 0.0105\n",
      "Epoch 101/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 90us/sample - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 102/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 86us/sample - loss: 0.0187 - val_loss: 0.0104\n",
      "Epoch 103/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 84us/sample - loss: 0.0186 - val_loss: 0.0103\n",
      "Epoch 104/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.029 - 0s 88us/sample - loss: 0.0173 - val_loss: 0.0103\n",
      "Epoch 105/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.026 - 0s 95us/sample - loss: 0.0190 - val_loss: 0.0103\n",
      "Epoch 106/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 93us/sample - loss: 0.0183 - val_loss: 0.0102\n",
      "Epoch 107/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 87us/sample - loss: 0.0184 - val_loss: 0.0101\n",
      "Epoch 108/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 109us/sample - loss: 0.0190 - val_loss: 0.0100\n",
      "Epoch 109/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 114us/sample - loss: 0.0194 - val_loss: 0.0100\n",
      "Epoch 110/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0177 - val_loss: 0.0099\n",
      "Epoch 111/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 88us/sample - loss: 0.0176 - val_loss: 0.0099\n",
      "Epoch 112/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 91us/sample - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 113/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 93us/sample - loss: 0.0187 - val_loss: 0.0098\n",
      "Epoch 114/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 99us/sample - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 115/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0167 - val_loss: 0.0097\n",
      "Epoch 116/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 100us/sample - loss: 0.0171 - val_loss: 0.0096\n",
      "Epoch 117/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.015 - 0s 95us/sample - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 118/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.020 - 0s 98us/sample - loss: 0.0179 - val_loss: 0.0095\n",
      "Epoch 119/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 98us/sample - loss: 0.0187 - val_loss: 0.0095\n",
      "Epoch 120/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 100us/sample - loss: 0.0159 - val_loss: 0.0094\n",
      "Epoch 121/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 97us/sample - loss: 0.0157 - val_loss: 0.0094\n",
      "Epoch 122/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.031 - 0s 95us/sample - loss: 0.0156 - val_loss: 0.0093\n",
      "Epoch 123/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 86us/sample - loss: 0.0156 - val_loss: 0.0093\n",
      "Epoch 124/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 91us/sample - loss: 0.0168 - val_loss: 0.0092\n",
      "Epoch 125/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.017 - 0s 95us/sample - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 126/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 93us/sample - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 127/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.019 - 0s 91us/sample - loss: 0.0147 - val_loss: 0.0091\n",
      "Epoch 128/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 122us/sample - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 129/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 95us/sample - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 130/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 83us/sample - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 131/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 86us/sample - loss: 0.0148 - val_loss: 0.0089\n",
      "Epoch 132/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 133/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 134/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 135/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 88us/sample - loss: 0.0131 - val_loss: 0.0088\n",
      "Epoch 136/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.021 - 0s 91us/sample - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 137/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 91us/sample - loss: 0.0146 - val_loss: 0.0087\n",
      "Epoch 138/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.024 - 0s 88us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 139/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 140/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 97us/sample - loss: 0.0139 - val_loss: 0.0086\n",
      "Epoch 141/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 81us/sample - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 142/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 81us/sample - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 143/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 89us/sample - loss: 0.0130 - val_loss: 0.0085\n",
      "Epoch 144/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 94us/sample - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 145/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 94us/sample - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 146/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 86us/sample - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 147/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 92us/sample - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 148/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 80us/sample - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 149/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 81us/sample - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 150/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 86us/sample - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 151/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 87us/sample - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 152/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 153/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 88us/sample - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 154/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 99us/sample - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 155/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 105us/sample - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 156/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 157/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 158/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 93us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 159/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 97us/sample - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 160/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 92us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 161/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 162/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 163/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 164/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 96us/sample - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 165/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 166/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 167/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 168/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 169/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 98us/sample - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 170/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 108us/sample - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 171/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 172/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 103us/sample - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 173/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 125us/sample - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 174/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.018 - 0s 107us/sample - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 175/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 88us/sample - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 176/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 76us/sample - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 177/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 78us/sample - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 178/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 90us/sample - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 179/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 180/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 105us/sample - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 181/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 182/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 83us/sample - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 183/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 86us/sample - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 184/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 84us/sample - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 185/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.016 - 0s 90us/sample - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 186/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 84us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 187/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 188/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 84us/sample - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 189/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 190/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 191/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 192/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 92us/sample - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 193/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 194/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 93us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 195/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 196/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 197/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 83us/sample - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 198/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 94us/sample - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 199/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 200/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 97us/sample - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 201/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 100us/sample - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 202/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 90us/sample - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 203/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 110us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 204/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 205/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 95us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 206/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.012 - 0s 93us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 207/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 208/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 209/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 106us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 210/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 106us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 211/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 103us/sample - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 212/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 108us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 213/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 105us/sample - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 214/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 105us/sample - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 215/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 216/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.013 - 0s 84us/sample - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 217/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 96us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 218/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.014 - 0s 95us/sample - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 219/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 220/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 78us/sample - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 221/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 78us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 222/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 105us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 223/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 94us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 224/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 88us/sample - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 225/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 86us/sample - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 226/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 227/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 81us/sample - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 228/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 82us/sample - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 229/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 78us/sample - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 230/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 231/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 83us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 232/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 76us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 233/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 83us/sample - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 234/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 79us/sample - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 235/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 85us/sample - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 236/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 77us/sample - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 237/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 87us/sample - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 238/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 239/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 240/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 89us/sample - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 241/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 242/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 81us/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 243/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 85us/sample - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 244/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 245/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 100us/sample - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 246/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 95us/sample - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 247/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 104us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 248/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 249/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 97us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 250/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 96us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 251/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 93us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 252/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 111us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 253/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 116us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 254/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 255/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 92us/sample - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 256/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 85us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 257/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 106us/sample - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 258/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 96us/sample - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 259/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 92us/sample - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 260/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 95us/sample - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 261/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 90us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 262/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 263/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 98us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 264/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 95us/sample - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 265/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 266/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 267/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 86us/sample - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 268/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 86us/sample - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 269/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 90us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 270/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 90us/sample - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 271/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 95us/sample - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 272/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 133us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 273/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 274/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 84us/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 275/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 98us/sample - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 276/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 89us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 277/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 90us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 278/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 279/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.011 - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 280/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 91us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 281/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 85us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 282/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 86us/sample - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 283/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.009 - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 284/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 285/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 88us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 286/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 94us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 287/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 87us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 288/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.002 - 0s 81us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 289/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 290/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.010 - 0s 98us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 291/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 96us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 292/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 111us/sample - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 293/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 103us/sample - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 294/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/sample - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 295/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.006 - 0s 98us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 296/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.003 - 0s 93us/sample - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 297/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.005 - 0s 108us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 298/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.008 - 0s 95us/sample - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 299/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.004 - 0s 93us/sample - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 300/300\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.007 - 0s 90us/sample - loss: 0.0057 - val_loss: 0.0069\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(testFeature).reshape(testTarget.shape[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25126ab6a08>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result)\n",
    "plt.plot(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28842394623905415"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.308259995845649"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2906719046923477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTarget.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
